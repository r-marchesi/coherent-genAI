{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54202742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# --- SECTION 1: HELPER FUNCTIONS ---\n",
    "\n",
    "def to_survival_structured_array(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Converts a DataFrame with OS and OS.time into a structured array for scikit-survival.\"\"\"\n",
    "    event_indicator = df['OS'].astype(bool)\n",
    "    event_time = df['OS.time'].astype(float)\n",
    "    structured_array = np.array(\n",
    "        list(zip(event_indicator, event_time)),\n",
    "        dtype=[('event', bool), ('time', float)]\n",
    "    )\n",
    "    return structured_array\n",
    "\n",
    "def load_and_prepare_pancancer_survival_data(labels_dir: str, data_dir: str, surv_dir: str):\n",
    "    \"\"\"Loads and aligns all data for a pan-cancer survival analysis.\"\"\"\n",
    "    print(\"--- Loading and preparing all pan-cancer data for survival analysis... ---\")\n",
    "    \n",
    "    X_train_orig = pd.read_csv(os.path.join(data_dir, \"real_data_train.csv\"), index_col=0)\n",
    "    X_test_orig = pd.read_csv(os.path.join(data_dir, \"test_data.csv\"), index_col=0)\n",
    "\n",
    "    train_type_df = pd.read_csv(os.path.join(labels_dir, \"train_cancer_type.csv\"), index_col=0)\n",
    "    test_type_df = pd.read_csv(os.path.join(labels_dir, \"test_cancer_type.csv\"), index_col=0)\n",
    "\n",
    "    all_surv_files = [f for f in os.listdir(surv_dir) if f.endswith('.survival.tsv')]\n",
    "    surv_dfs = []\n",
    "    for fn in all_surv_files:\n",
    "        cancer_surv = pd.read_csv(os.path.join(surv_dir, fn), sep=\"\\t\")\n",
    "        cancer_surv = (cancer_surv\n",
    "                       .rename(columns={\"sample\": \"sample_id\"})\n",
    "                       .assign(sample_id=lambda df: df.sample_id.str[:-1])\n",
    "                       .set_index(\"sample_id\")\n",
    "                       .drop(columns=[\"_PATIENT\"], errors='ignore'))\n",
    "        cancer_surv = cancer_surv[~cancer_surv.index.duplicated(keep=\"first\")]\n",
    "        surv_dfs.append(cancer_surv)\n",
    "    pan_surv = pd.concat(surv_dfs)\n",
    "    pan_surv.dropna(subset=['OS', 'OS.time'], inplace=True)\n",
    "\n",
    "    train_common_idx = train_type_df.index.intersection(X_train_orig.index).intersection(pan_surv.index)\n",
    "    test_common_idx = test_type_df.index.intersection(X_test_orig.index).intersection(pan_surv.index)\n",
    "\n",
    "    X_train = X_train_orig.loc[train_common_idx].sort_index()\n",
    "    train_surv = pan_surv.loc[train_common_idx].sort_index()\n",
    "    train_types = train_type_df.loc[train_common_idx, 'cancertype'].sort_index()\n",
    "    \n",
    "    X_test = X_test_orig.loc[test_common_idx].sort_index()\n",
    "    test_surv = pan_surv.loc[test_common_idx].sort_index()\n",
    "    test_types = test_type_df.loc[test_common_idx, 'cancertype'].sort_index()\n",
    "\n",
    "    y_train = to_survival_structured_array(train_surv)\n",
    "    y_test = to_survival_structured_array(test_surv)\n",
    "    \n",
    "    print(f\"  Found {len(X_train)} training samples and {len(X_test)} test samples with survival data.\")\n",
    "    \n",
    "    train_cancer_dummies = pd.get_dummies(train_types, prefix='cancer')\n",
    "    test_cancer_dummies = pd.get_dummies(test_types, prefix='cancer')\n",
    "    train_cancer_dummies, test_cancer_dummies = train_cancer_dummies.align(test_cancer_dummies, join='outer', axis=1, fill_value=0)\n",
    "    \n",
    "    X_train_final = pd.concat([X_train, train_cancer_dummies], axis=1)\n",
    "    X_test_final = pd.concat([X_test, test_cancer_dummies], axis=1)\n",
    "    \n",
    "    return X_train_final, y_train, X_test_final, y_test\n",
    "\n",
    "\n",
    "# --- SECTION 2: MAIN ANALYSIS PIPELINE (WITH OPTIMIZED MODEL) ---\n",
    "\n",
    "def run_pancancer_survival_modality_analysis(random_seed: int):\n",
    "    \"\"\"\n",
    "    Trains a single, optimized pan-cancer Random Survival Forest and evaluates its robustness.\n",
    "    \"\"\"\n",
    "    X_train, y_train, X_test, y_test = load_and_prepare_pancancer_survival_data(\n",
    "        \"../../datasets_TCGA/downstream_labels\",\n",
    "        \"./data_task_02\",\n",
    "        \"../../datasets_TCGA/downstream_labels/survival\"\n",
    "    )\n",
    "\n",
    "    # --- NEW: Optimized Hyperparameters for speed ---\n",
    "    # You can tune these values to find the best speed/performance trade-off.\n",
    "    rsf_params = {\n",
    "        'n_estimators': 30,      # Reduced from 100. Big speed-up.\n",
    "        'max_depth': 12,         # Prevents overly complex trees.\n",
    "        'max_features': 'sqrt',  # Considers a smaller subset of features at each split.\n",
    "        'n_jobs': -1,            # Uses all available CPU cores.\n",
    "        'random_state': random_seed\n",
    "    }\n",
    "\n",
    "    print(f\"\\n--- Training pan-cancer Random Survival Forest with random_state={random_seed}... ---\")\n",
    "    print(f\"  Using optimized parameters: { {k:v for k,v in rsf_params.items() if k != 'random_state'} }\")\n",
    "    rsf = RandomSurvivalForest(**rsf_params)\n",
    "    rsf.fit(X_train, y_train)\n",
    "    \n",
    "    all_prefixes = {col.split('_')[0] for col in X_test.columns if '_' in col}\n",
    "    possible_modalities = ['cna', 'rnaseq', 'rppa', 'wsi'] \n",
    "    available_modalities = sorted([m for m in possible_modalities if m in all_prefixes])\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(\"\\n--- Processing Test Condition: full_data ---\")\n",
    "    risk_scores_full = rsf.predict(X_test)\n",
    "    c_index_full = concordance_index_censored(y_test[\"event\"], y_test[\"time\"], risk_scores_full)[0]\n",
    "    results.append({'test_condition': 'full_data', 'c_index': c_index_full})\n",
    "\n",
    "    for r in range(1, len(available_modalities) + 1):\n",
    "        for combo in combinations(available_modalities, r):\n",
    "            if len(combo) == len(available_modalities):\n",
    "                condition_name = \"cancer_label_only\"\n",
    "            else:\n",
    "                condition_name = f\"no_{'_'.join(combo)}\"\n",
    "            \n",
    "            print(f\"--- Processing Test Condition: {condition_name} ---\")\n",
    "\n",
    "            cols_to_nullify = [col for mod in combo for col in X_test.columns if col.startswith(mod + '_')]\n",
    "            X_test_ablated = X_test.copy()\n",
    "            X_test_ablated[cols_to_nullify] = np.nan\n",
    "            \n",
    "            risk_scores_ablated = rsf.predict(X_test_ablated)\n",
    "            c_index_ablated = concordance_index_censored(y_test[\"event\"], y_test[\"time\"], risk_scores_ablated)[0]\n",
    "            results.append({'test_condition': condition_name, 'c_index': c_index_ablated})\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --- SECTION 3: MAIN EXECUTION AND VISUALIZATION ---\n",
    "if __name__ == '__main__':\n",
    "    N_RUNS = 5 \n",
    "    all_results_dfs = []\n",
    "    \n",
    "    for i in range(N_RUNS):\n",
    "        print(f\"\\n==================== Starting Run {i+1}/{N_RUNS} ====================\")\n",
    "        results_df = run_pancancer_survival_modality_analysis(random_seed=i)\n",
    "        \n",
    "        if results_df is not None:\n",
    "            results_df['run'] = i + 1\n",
    "            all_results_dfs.append(results_df)\n",
    "\n",
    "    if all_results_dfs:\n",
    "        final_results_all_runs = pd.concat(all_results_dfs, ignore_index=True)\n",
    "\n",
    "        print(\"\\n\\n===== SUMMARY STATISTICS (C-INDEX) ACROSS ALL RUNS =====\")\n",
    "        summary_stats = final_results_all_runs.groupby('test_condition')['c_index'].agg(\n",
    "            ['mean', 'std', 'median', 'min', 'max']\n",
    "        ).sort_values(by='mean', ascending=False)\n",
    "        \n",
    "        summary_stats['n_removed'] = summary_stats.index.map(\n",
    "            lambda x: 0 if x == 'full_data' else (99 if x == 'cancer_label_only' else x.count('_') + 1)\n",
    "        )\n",
    "        print(summary_stats.sort_values(by='n_removed').drop(columns='n_removed').to_string())\n",
    "\n",
    "        print(\"\\n\\n--- Generating plot to visualize performance and variance ---\")\n",
    "\n",
    "        plot_order = summary_stats.sort_values(by='n_removed').index.tolist()\n",
    "        \n",
    "        plt.figure(figsize=(14, 8))\n",
    "        ax = sns.boxplot(data=final_results_all_runs, x='test_condition', y='c_index', order=plot_order, showfliers=False)\n",
    "        sns.stripplot(data=final_results_all_runs, x='test_condition', y='c_index', order=plot_order, jitter=True, alpha=0.6, color='black')\n",
    "        \n",
    "        ax.set_title('Pan-Cancer Survival Model Performance (C-Index) with Missing Modalities', fontsize=16)\n",
    "        ax.set_xlabel('Test Data Condition', fontsize=12)\n",
    "        ax.set_ylabel('Concordance Index (C-Index)', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91d3641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "try:\n",
    "    import sksurv\n",
    "except ImportError:\n",
    "    print(\"sksurv not found. Installing...\")\n",
    "    install_package(\"scikit-survival\")\n",
    "    import sksurv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations, permutations\n",
    "import warnings\n",
    "import torch\n",
    "import json\n",
    "import pathlib\n",
    "from types import SimpleNamespace\n",
    "import sys\n",
    "\n",
    "# --- NEW: Survival Analysis and Standard Imputation Imports ---\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "# --- Suppress warnings ---\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# --- Add your custom library path ---\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) \n",
    "from lib.test import coherent_test_cos_rejection, test_model\n",
    "from lib.config import modalities_list\n",
    "from lib.get_models import get_diffusion_model\n",
    "from lib.diffusion_models import GaussianDiffusion\n",
    "\n",
    "# ====================================================================================\n",
    "# SECTION 1: HELPER FUNCTIONS\n",
    "# ====================================================================================\n",
    "\n",
    "def to_survival_structured_array(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Converts a DataFrame with OS and OS.time into a structured array for scikit-survival.\"\"\"\n",
    "    event_indicator = df['OS'].astype(bool)\n",
    "    event_time = df['OS.time'].astype(float)\n",
    "    structured_array = np.array(\n",
    "        list(zip(event_indicator, event_time)),\n",
    "        dtype=[('event', bool), ('time', float)]\n",
    "    )\n",
    "    return structured_array\n",
    "\n",
    "def load_and_prepare_pancancer_survival_data(labels_dir: str, data_dir: str, surv_dir: str):\n",
    "    \"\"\"Loads and aligns all data for a pan-cancer survival analysis.\"\"\"\n",
    "    print(\"--- Loading and preparing all pan-cancer data for survival analysis... ---\")\n",
    "    \n",
    "    X_train_orig = pd.read_csv(os.path.join(data_dir, \"real_data_train.csv\"), index_col=0)\n",
    "    X_test_orig = pd.read_csv(os.path.join(data_dir, \"test_data.csv\"), index_col=0)\n",
    "\n",
    "    train_type_df = pd.read_csv(os.path.join(labels_dir, \"train_cancer_type.csv\"), index_col=0)\n",
    "    test_type_df = pd.read_csv(os.path.join(labels_dir, \"test_cancer_type.csv\"), index_col=0)\n",
    "\n",
    "    all_surv_files = [f for f in os.listdir(surv_dir) if f.endswith('.survival.tsv')]\n",
    "    surv_dfs = []\n",
    "    for fn in all_surv_files:\n",
    "        cancer_surv = pd.read_csv(os.path.join(surv_dir, fn), sep=\"\\t\")\n",
    "        cancer_surv = (cancer_surv.rename(columns={\"sample\": \"sample_id\"})\n",
    "                       .assign(sample_id=lambda df: df.sample_id.str[:-1])\n",
    "                       .set_index(\"sample_id\").drop(columns=[\"_PATIENT\"], errors='ignore'))\n",
    "        cancer_surv = cancer_surv[~cancer_surv.index.duplicated(keep=\"first\")]\n",
    "        surv_dfs.append(cancer_surv)\n",
    "    pan_surv = pd.concat(surv_dfs).dropna(subset=['OS', 'OS.time'])\n",
    "\n",
    "    train_common_idx = train_type_df.index.intersection(X_train_orig.index).intersection(pan_surv.index)\n",
    "    test_common_idx = test_type_df.index.intersection(X_test_orig.index).intersection(pan_surv.index)\n",
    "\n",
    "    X_train = X_train_orig.loc[train_common_idx].sort_index()\n",
    "    train_surv = pan_surv.loc[train_common_idx].sort_index()\n",
    "    train_types = train_type_df.loc[train_common_idx, 'cancertype'].sort_index()\n",
    "    \n",
    "    X_test = X_test_orig.loc[test_common_idx].sort_index()\n",
    "    test_surv = pan_surv.loc[test_common_idx].sort_index()\n",
    "    test_types = test_type_df.loc[test_common_idx, 'cancertype'].sort_index()\n",
    "\n",
    "    y_train = to_survival_structured_array(train_surv)\n",
    "    y_test = to_survival_structured_array(test_surv)\n",
    "    \n",
    "    print(f\"  Found {len(X_train)} training samples and {len(X_test)} test samples with survival data.\")\n",
    "    \n",
    "    train_cancer_dummies = pd.get_dummies(train_types, prefix='cancer')\n",
    "    test_cancer_dummies = pd.get_dummies(test_types, prefix='cancer')\n",
    "    train_cancer_dummies, test_cancer_dummies = train_cancer_dummies.align(test_cancer_dummies, join='outer', axis=1, fill_value=0)\n",
    "    \n",
    "    X_train_final = pd.concat([X_train, train_cancer_dummies], axis=1)\n",
    "    X_test_final = pd.concat([X_test, test_cancer_dummies], axis=1)\n",
    "    \n",
    "    return X_train_final, y_train, X_test_final, y_test\n",
    "\n",
    "# --- Generative model helper functions (unchanged) ---\n",
    "def load_single_model(target_mod, cond_mod, diffusion, config_args, device):\n",
    "    path = pathlib.Path(f'../../{config_args.folder}/{config_args.dim}/{target_mod}_from_{cond_mod}')\n",
    "    ckpt_path = path / f'train/best_by_{config_args.metric}.pth'\n",
    "    if not ckpt_path.exists(): raise FileNotFoundError(f\"Checkpoint not found for single model: {ckpt_path}\")\n",
    "    ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "    config = SimpleNamespace(**ckpt[\"config\"])\n",
    "    x_dim = config_args.modality_dims[target_mod]\n",
    "    cond_dim = config_args.modality_dims[cond_mod]\n",
    "    model = get_diffusion_model(config.architecture, diffusion, config, x_dim=x_dim, cond_dims=cond_dim).to(device)\n",
    "    model.load_state_dict(ckpt[f\"best_model_{config_args.metric}\"])\n",
    "    model.eval()\n",
    "    return model, config, ckpt['best_loss']\n",
    "\n",
    "def load_multi_model(target_mod, diffusion, config_args, device):\n",
    "    base_dir = pathlib.Path(f\"../../{config_args.folder}/{config_args.dim}/{target_mod}_from_multi{'_masked' if config_args.mask else ''}\")\n",
    "    ckpt_path = base_dir / 'train' / f'best_by_{config_args.metric}.pth'\n",
    "    if not ckpt_path.exists(): raise FileNotFoundError(f\"Checkpoint not found for multi model: {ckpt_path}\")\n",
    "    with open(base_dir / 'cond_order.json', 'r') as f: cond_order = json.load(f)\n",
    "    ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "    config = SimpleNamespace(**ckpt['config'])\n",
    "    x_dim = config_args.modality_dims[target_mod]\n",
    "    cond_dim_list = [config_args.modality_dims[c] for c in cond_order]\n",
    "    model = get_diffusion_model(config.architecture, diffusion, config, x_dim=x_dim, cond_dims=cond_dim_list).to(device)\n",
    "    model.load_state_dict(ckpt[f'best_model_{config_args.metric}'])\n",
    "    model.eval()\n",
    "    return model, config, cond_order\n",
    "\n",
    "def impute_missing_modalities_generative(X_test_with_nan, modalities_to_impute, available_modalities, gen_mode, config_args, diffusion, device):\n",
    "    X_imputed = X_test_with_nan.copy()\n",
    "    generation_order = sorted(modalities_to_impute)\n",
    "    conditioning_modalities = [m for m in available_modalities if m not in modalities_to_impute]\n",
    "    for i, target_mod in enumerate(generation_order):\n",
    "        print(f\"    Imputing '{target_mod}' (step {i+1}/{len(generation_order)}) with '{gen_mode}' model...\")\n",
    "        current_conds = conditioning_modalities + generation_order[:i]\n",
    "        cond_data_list = [X_imputed[[c for c in X_imputed.columns if c.startswith(cond_mod + '_')]] for cond_mod in current_conds]\n",
    "\n",
    "        if gen_mode == 'coherent':\n",
    "            models = [load_single_model(target_mod, c, diffusion, config_args, device)[0] for c in current_conds]\n",
    "            weights = [load_single_model(target_mod, c, diffusion, config_args, device)[2] for c in current_conds]\n",
    "            _, generated_df, _ = coherent_test_cos_rejection(pd.DataFrame(np.zeros((X_imputed.shape[0], config_args.modality_dims[target_mod]))), cond_data_list, models, diffusion, test_iterations=1, max_retries=10, device=device, weights_list=weights)\n",
    "        elif gen_mode == 'multi':\n",
    "            model, _, cond_order = load_multi_model(target_mod, diffusion, config_args, device)\n",
    "            final_cond_list = []\n",
    "            for c_name in cond_order:\n",
    "                if c_name in current_conds:\n",
    "                    final_cond_list.append(X_imputed[[c for c in X_imputed.columns if c.startswith(c_name + '_')]])\n",
    "                else:\n",
    "                    final_cond_list.append(pd.DataFrame(np.zeros((X_imputed.shape[0], config_args.modality_dims[c_name]))))\n",
    "            _, generated_df = test_model(pd.DataFrame(np.zeros((X_imputed.shape[0], config_args.modality_dims[target_mod]))), final_cond_list, model, diffusion, test_iterations=1, device=device)\n",
    "        \n",
    "        target_cols = [c for c in X_imputed.columns if c.startswith(target_mod + '_')]\n",
    "        generated_df.columns = target_cols\n",
    "        generated_df.index = X_imputed.index\n",
    "        X_imputed[target_cols] = generated_df\n",
    "    return X_imputed\n",
    "\n",
    "# ====================================================================================\n",
    "# SECTION 2: MAIN ANALYSIS PIPELINE\n",
    "# ====================================================================================\n",
    "\n",
    "def run_pancancer_survival_analysis_with_all_imputations(random_seed: int, config_args, diffusion, device):\n",
    "    \"\"\"\n",
    "    The master function for the survival analysis experiment.\n",
    "    \"\"\"\n",
    "    X_train, y_train, X_test, y_test = load_and_prepare_pancancer_survival_data(\n",
    "        config_args.labels_dir, config_args.data_dir, config_args.surv_dir\n",
    "    )\n",
    "\n",
    "    rsf_params = {'n_estimators': 30, 'max_depth': 12, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': random_seed}\n",
    "    print(f\"\\n--- Training pan-cancer Random Survival Forest with random_state={random_seed}... ---\")\n",
    "    rsf = RandomSurvivalForest(**rsf_params)\n",
    "    rsf.fit(X_train, y_train)\n",
    "    \n",
    "    all_prefixes = {col.split('_')[0] for col in X_test.columns if '_' in col}\n",
    "    available_modalities = sorted([m for m in ['cna', 'rnaseq', 'rppa', 'wsi'] if m in all_prefixes])\n",
    "    print(f\"  Available modalities: {available_modalities}\")\n",
    "\n",
    "    all_results = []\n",
    "    \n",
    "    # Evaluate on the full, unmodified test set first\n",
    "    print(\"\\n--- Processing Test Condition: full_data ---\")\n",
    "    risk_scores_full = rsf.predict(X_test)\n",
    "    c_index_full = concordance_index_censored(y_test[\"event\"], y_test[\"time\"], risk_scores_full)[0]\n",
    "    all_results.append({'test_condition': 'full_data', 'test_type': 'full_data', 'c_index': c_index_full})\n",
    "\n",
    "    # Loop through combinations of modalities to remove/impute\n",
    "    for r in range(1, len(available_modalities) + 1):\n",
    "        for combo in combinations(available_modalities, r):\n",
    "            condition_name = \"cancer_label_only\" if len(combo) == len(available_modalities) else f\"no_{'_'.join(combo)}\"\n",
    "            modalities_to_process = list(combo)\n",
    "            print(f\"\\n--- Processing Test Condition: {condition_name} ---\")\n",
    "\n",
    "            # Create the ablated (NaN) test set\n",
    "            X_test_ablated = X_test.copy()\n",
    "            cols_to_nullify = [col for mod in modalities_to_process for col in X_test.columns if col.startswith(mod + '_')]\n",
    "            X_test_ablated[cols_to_nullify] = np.nan\n",
    "            \n",
    "            # --- Define all imputation strategies for this condition ---\n",
    "            imputation_strategies = {'ablation': X_test_ablated}\n",
    "\n",
    "            # --- Standard Imputers ---\n",
    "            print(\"    Imputing with 'mean' and 'knn'...\")\n",
    "            mean_imputer = SimpleImputer(strategy='mean').fit(X_train)\n",
    "            X_test_imputed_mean_np = mean_imputer.transform(X_test_ablated)\n",
    "            imputation_strategies['imputed_mean'] = pd.DataFrame(X_test_imputed_mean_np, index=X_test.index, columns=X_test.columns)\n",
    "\n",
    "            knn_imputer = KNNImputer(n_neighbors=5).fit(X_train)\n",
    "            X_test_imputed_knn_np = knn_imputer.transform(X_test_ablated)\n",
    "            imputation_strategies['imputed_knn'] = pd.DataFrame(X_test_imputed_knn_np, index=X_test.index, columns=X_test.columns)\n",
    "\n",
    "            # --- Generative Imputers (if applicable) ---\n",
    "            if len(modalities_to_process) < len(available_modalities):\n",
    "                imputation_strategies['imputed_multi'] = impute_missing_modalities_generative(X_test_ablated, modalities_to_process, available_modalities, 'multi', config_args, diffusion, device)\n",
    "                imputation_strategies['imputed_coherent'] = impute_missing_modalities_generative(X_test_ablated, modalities_to_process, available_modalities, 'coherent', config_args, diffusion, device)\n",
    "            else:\n",
    "                print(\"    Skipping generative imputation: no conditioning data available.\")\n",
    "\n",
    "            # --- Evaluate each strategy ---\n",
    "            for test_type, X_test_current in imputation_strategies.items():\n",
    "                risk_scores = rsf.predict(X_test_current)\n",
    "                c_index = concordance_index_censored(y_test[\"event\"], y_test[\"time\"], risk_scores)[0]\n",
    "                all_results.append({'test_condition': condition_name, 'test_type': test_type, 'c_index': c_index})\n",
    "                \n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "# ====================================================================================\n",
    "# SECTION 3: MAIN EXECUTION AND VISUALIZATION\n",
    "# ====================================================================================\n",
    "\n",
    "def create_survival_summary_plot(data: pd.DataFrame, metric: str, title: str):\n",
    "    print(f\"\\n--- Generating final comparison plot for: {metric} ---\")\n",
    "    \n",
    "    condition_to_exclude = (data['test_condition'] == 'cancer_label_only') & (data['test_type'] != 'ablation')\n",
    "    plot_data = data[~condition_to_exclude].copy()\n",
    "\n",
    "    plot_data['n_removed'] = plot_data['test_condition'].apply(lambda x: 0 if x == 'full_data' else (99 if x == 'cancer_label_only' else x.count('_') + 1))\n",
    "    plot_order = plot_data.sort_values(by=['n_removed', 'test_condition']).test_condition.unique()\n",
    "    \n",
    "    palette = {'full_data': '#4C72B0', 'ablation': '#A9A9A9', 'imputed_mean': '#8DEEEE', 'imputed_knn': '#00CED1', 'imputed_multi': '#FFB6C1', 'imputed_coherent': '#DC143C'}\n",
    "    hue_order = ['full_data', 'ablation', 'imputed_mean', 'imputed_knn', 'imputed_multi', 'imputed_coherent']\n",
    "    plot_data_hue_order = [h for h in hue_order if h in plot_data['test_type'].unique()]\n",
    "\n",
    "    g = sns.catplot(data=plot_data, x='test_condition', y=metric, hue='test_type', order=plot_order, hue_order=plot_data_hue_order, kind='bar', height=7, aspect=2.2, palette=palette, errorbar='sd')\n",
    "    sns.move_legend(g, \"center right\", bbox_to_anchor=(1.1, 0.5), frameon=True, title='Test Type')\n",
    "    g.fig.suptitle(title, y=1.03, fontsize=18)\n",
    "    g.set_axis_labels(\"Test Condition (Modalities Removed)\", \"Mean Concordance Index (C-Index)\", fontsize=14)\n",
    "    g.set_xticklabels(rotation=45, ha='right')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    config_args = SimpleNamespace(\n",
    "        folder='results', metric='mse', dim='32', mask=False,\n",
    "        labels_dir=\"../../datasets_TCGA/downstream_labels\",\n",
    "        data_dir=\"./data_task_02\",\n",
    "        surv_dir=\"../../datasets_TCGA/downstream_labels/survival\",\n",
    "        modality_dims={'cna': 32, 'rnaseq': 32, 'rppa': 32, 'wsi': 32}\n",
    "    )\n",
    "    device = torch.device(f\"cuda:{torch.cuda.current_device()}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    diffusion = GaussianDiffusion(num_timesteps=1000).to(device)\n",
    "    \n",
    "    N_RUNS = 5\n",
    "    all_run_dfs = []\n",
    "\n",
    "    for i in range(N_RUNS):\n",
    "        print(f\"\\n{'='*25} Starting Run {i+1}/{N_RUNS} {'='*25}\")\n",
    "        results_df = run_pancancer_survival_analysis_with_all_imputations(\n",
    "            random_seed=i, config_args=config_args, diffusion=diffusion, device=device\n",
    "        )\n",
    "        if results_df is not None:\n",
    "            results_df['run'] = i + 1\n",
    "            all_run_dfs.append(results_df)\n",
    "\n",
    "    if all_run_dfs:\n",
    "        final_results = pd.concat(all_run_dfs, ignore_index=True)\n",
    "        \n",
    "        results_path = '../../results/downstream/task_06_imputing_test_set_surv/all_imputations_results.csv'\n",
    "        # Ensure the results directory exists\n",
    "        os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "        final_results.to_csv(results_path, index=False)\n",
    "        print(\"Results saved successfully\")\n",
    "\n",
    "        print(\"\\n\\n===== SUMMARY STATISTICS (C-INDEX) ACROSS ALL RUNS =====\")\n",
    "        summary_stats = final_results.groupby(['test_condition', 'test_type'])['c_index'].agg(['mean', 'std', 'median'])\n",
    "        summary_stats['n_removed'] = summary_stats.index.get_level_values('test_condition').map(lambda x: 0 if x == 'full_data' else (99 if x == 'cancer_label_only' else x.count('_') + 1))\n",
    "        print(summary_stats.sort_values(by=['n_removed', ('c_index', 'mean')], ascending=[True, False]).drop(columns='n_removed').to_string())\n",
    "\n",
    "        create_survival_summary_plot(final_results, 'c_index', 'Final Comparison of All Imputation Strategies for Survival Analysis (C-Index)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = pd.concat(all_run_dfs, ignore_index=True)\n",
    "\n",
    "results_path = '../../results/downstream/task_06_imputing_test_set_surv/'\n",
    "# Ensure the results directory exists\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "final_results.to_csv(f'{results_path}all_imputations_results.csv', index=False)\n",
    "print(\"Results saved successfully\")\n",
    "\n",
    "print(\"\\n\\n===== SUMMARY STATISTICS (C-INDEX) ACROSS ALL RUNS =====\")\n",
    "summary_stats = final_results.groupby(['test_condition', 'test_type'])['c_index'].agg(['mean', 'std', 'median'])\n",
    "summary_stats['n_removed'] = summary_stats.index.get_level_values('test_condition').map(lambda x: 0 if x == 'full_data' else (99 if x == 'cancer_label_only' else x.count('_') + 1))\n",
    "print(summary_stats.sort_values(by=['n_removed', ('c_index', 'mean')], ascending=[True, False]).drop(columns='n_removed').to_string())\n",
    "\n",
    "create_survival_summary_plot(final_results, 'c_index', 'Final Comparison of All Imputation Strategies for Survival Analysis (C-Index)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ade7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7afc0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
