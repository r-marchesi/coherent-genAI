{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db79e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CONFIGURATION\n",
    "# =============================================================================\n",
    "# Define all modalities available in the dataset\n",
    "ALL_MODALITIES = ['cna', 'rna', 'rppa', 'wsi']\n",
    "\n",
    "# --- Main Setting ---\n",
    "# Define which modalities to treat as \"missing\" or \"ablated\" for the analysis.\n",
    "# This can be a single modality, e.g., ('rna',) or multiple, e.g., ('rna', 'wsi')\n",
    "ABLATED_MODALITIES = ('rna',)\n",
    "\n",
    "# Mapping from the ablated modalities tuple to the corresponding generated data file.\n",
    "# This allows the script to pick the correct file for the counterfactual analysis.\n",
    "gen_path = '../../results/32/'\n",
    "\n",
    "GENERATED_DATA_MAPPING_coh = {\n",
    "    ('rna',): f'{gen_path}rnaseq_from_coherent/test/generated_samples_from_cna_rppa_wsi_best_mse.csv',\n",
    "    ('wsi',): f'{gen_path}wsi_from_coherent/test/generated_samples_from_cna_rnaseq_rppa_best_mse.csv',\n",
    "}\n",
    "\n",
    "GENERATED_DATA_MAPPING_multi = {\n",
    "    ('rna',): f'{gen_path}rnaseq_from_multi/test/generated_samples_from_cna_rppa_wsi_best_mse.csv',\n",
    "    ('wsi',): f'{gen_path}wsi_from_multi/test/generated_samples_from_cna_rnaseq_rppa_best_mse.csv',\n",
    "}\n",
    "\n",
    "# --- Experiment Parameters ---\n",
    "# Number of iterations for statistical significance in random experiments\n",
    "N_ITERATIONS = 30\n",
    "# Steps for the progressive ablation plot (from 0% to 100% of samples ablated)\n",
    "ABLATION_STEPS = np.arange(0, 1.05, 0.05)\n",
    "# Number of neighbors for the k-NN baseline\n",
    "K_NEIGHBORS = 10\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. DATA LOADING AND PREPARATION\n",
    "# =============================================================================\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# Load raw training and testing data\n",
    "train_path = '../../datasets_TCGA/07_normalized/32/'\n",
    "train_raw = {\n",
    "    'cna': pd.read_csv(f'{train_path}cna_train.csv', sep=','),\n",
    "    'rna': pd.read_csv(f'{train_path}rnaseq_train.csv', sep=','),\n",
    "    'rppa': pd.read_csv(f'{train_path}rppa_train.csv', sep=','),\n",
    "    'wsi': pd.read_csv(f'{train_path}wsi_train.csv', sep=','),\n",
    "}\n",
    "\n",
    "test_path = '../../datasets_TCGA/07_normalized/32/'\n",
    "test_raw = {\n",
    "    'cna': pd.read_csv(f'{train_path}cna_test.csv', sep=','),\n",
    "    'rna': pd.read_csv(f'{train_path}rnaseq_test.csv', sep=','),\n",
    "    'rppa': pd.read_csv(f'{train_path}rppa_test.csv', sep=','),\n",
    "    'wsi': pd.read_csv(f'{train_path}wsi_test.csv', sep=','),\n",
    "}\n",
    "\n",
    "labels_path = '../../datasets_TCGA/downstream_labels/'\n",
    "train_stage = pd.read_csv(f'{labels_path}train_stage.csv')\n",
    "test_stage = pd.read_csv(f'{labels_path}test_stage.csv')\n",
    "\n",
    "\n",
    "def clean_and_unify_tables(df_dict, modalities):\n",
    "    \"\"\"\n",
    "    Unifies multiple modality-specific dataframes into a single dataframe.\n",
    "    - Verifies sample order consistency.\n",
    "    - Adds modality prefixes to column names.\n",
    "    \"\"\"\n",
    "    sample_ids = df_dict[modalities[0]]['sample_id'].values\n",
    "    for m in modalities:\n",
    "        assert np.all(df_dict[m]['sample_id'].values == sample_ids), f\"Sample IDs for {m} do not match.\"\n",
    "\n",
    "    processed_dfs = []\n",
    "    for m in modalities:\n",
    "        df = df_dict[m].drop(columns=['sample_id'])\n",
    "        df.columns = [f'{m}_{i+1}' for i in range(df.shape[1])]\n",
    "        processed_dfs.append(df)\n",
    "        \n",
    "    return pd.concat(processed_dfs, axis=1)\n",
    "\n",
    "print(\"Processing and unifying tables...\")\n",
    "train_full = clean_and_unify_tables(train_raw, ALL_MODALITIES)\n",
    "test_full = clean_and_unify_tables(test_raw, ALL_MODALITIES)\n",
    "\n",
    "print(f\"Train data shape: {train_full.shape}\")\n",
    "print(f\"Test data shape: {test_full.shape}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3. LOAD GENERATED DATA FOR COUNTERFACTUALS\n",
    "# =============================================================================\n",
    "generated_file_key = ABLATED_MODALITIES\n",
    "if generated_file_key not in GENERATED_DATA_MAPPING_coh:\n",
    "    raise ValueError(f\"No generated data file specified for the modality combination: {generated_file_key}\")\n",
    "\n",
    "\n",
    "generated_file_name_coh = GENERATED_DATA_MAPPING_coh[generated_file_key]\n",
    "generated_file_name_multi = GENERATED_DATA_MAPPING_multi[generated_file_key]\n",
    "\n",
    "# Load the generated data for the ablated modalities\n",
    "try:\n",
    "    gen_data_long_coh = {\n",
    "        mod: pd.read_csv(generated_file_name_coh, sep=',')\n",
    "        for mod in ABLATED_MODALITIES\n",
    "    }\n",
    "    gen_data_long_multi = {\n",
    "        mod: pd.read_csv(generated_file_name_multi, sep=',')\n",
    "        for mod in ABLATED_MODALITIES\n",
    "    }\n",
    "except FileNotFoundError:\n",
    "     print(f\"Error: The generated data file '{generated_file_name_coh}' was not found.\")\n",
    "     exit()\n",
    "\n",
    "# Reshape generated data: from long format to a list of dataframes (10 candidates per sample)\n",
    "n_test_samples = len(test_full)\n",
    "assert all(len(df) == n_test_samples * K_NEIGHBORS for df in gen_data_long_coh.values()), \"Generated data size mismatch.\"\n",
    "\n",
    "generated_candidates_coh = {mod: [] for mod in ABLATED_MODALITIES}\n",
    "generated_candidates_multi = {mod: [] for mod in ABLATED_MODALITIES}\n",
    "for mod in ABLATED_MODALITIES:\n",
    "    for i in range(n_test_samples):\n",
    "        gather_indices = np.arange(K_NEIGHBORS) * n_test_samples + i\n",
    "        generated_candidates_coh[mod].append(gen_data_long_coh[mod].iloc[gather_indices])\n",
    "        generated_candidates_multi[mod].append(gen_data_long_multi[mod].iloc[gather_indices])\n",
    "\n",
    "print(f\"Reshaped generated data for {len(generated_candidates_coh[ABLATED_MODALITIES[0]])} test samples.\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. MODEL TRAINING AND BASELINE EVALUATION\n",
    "# =============================================================================\n",
    "print(\"\\n--- Training and Baseline Evaluation ---\")\n",
    "\n",
    "# Filter data to include only samples with known cancer stage labels\n",
    "train_mask = ~train_stage['stage'].isna()\n",
    "train_data = train_full[train_mask]\n",
    "train_labels_filtered = train_stage['stage'][train_mask]\n",
    "\n",
    "test_mask = ~test_stage['stage'].isna()\n",
    "test_data = test_full[test_mask].reset_index(drop=True)\n",
    "test_labels_filtered = test_stage['stage'][test_mask].reset_index(drop=True)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels = le.fit_transform(train_labels_filtered)\n",
    "test_labels = le.transform(test_labels_filtered)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, oob_score=True)\n",
    "print(\"Training Random Forest model...\")\n",
    "rf.fit(train_data.values, train_labels)\n",
    "\n",
    "# --- Baseline Performance ---\n",
    "test_predictions = rf.predict(test_data.values)\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "print(f\"Baseline F1-Score on Test Set (all modalities present): {test_f1:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 6. PROGRESSIVE ABLATION ANALYSIS\n",
    "# =============================================================================\n",
    "print(\"\\n--- Generating Progressive Ablation Comparison ---\")\n",
    "ablated_cols = [c for c in test_data.columns if c.split('_')[0] in ABLATED_MODALITIES]\n",
    "\n",
    "# --- 6a. Selective Ablation (Generative Model) ---\n",
    "print(\"Calculating selective ablation scores (Generative Model)...\")\n",
    "# Filter generated data to align with the filtered test set\n",
    "original_indices = test_mask[test_mask].index\n",
    "filtered_gen_candidates_coh = {\n",
    "    mod: [generated_candidates_coh[mod][i] for i in original_indices]\n",
    "    for mod in ABLATED_MODALITIES\n",
    "}\n",
    "filtered_gen_candidates_multi = {\n",
    "    mod: [generated_candidates_multi[mod][i] for i in original_indices]\n",
    "    for mod in ABLATED_MODALITIES\n",
    "}    \n",
    "\n",
    "prediction_variances_gen_coh = []\n",
    "prediction_variances_gen_multi = []\n",
    "for i in range(len(test_data)):\n",
    "    original_sample = test_data.iloc[[i]]\n",
    "    ablated_sample = original_sample.copy()\n",
    "    ablated_sample[ablated_cols] = np.nan\n",
    "    ablated_prediction = rf.predict(ablated_sample.values)[0]\n",
    "    \n",
    "    prediction_input_coh = pd.concat([original_sample] * K_NEIGHBORS, ignore_index=True)\n",
    "    prediction_input_multi = pd.concat([original_sample] * K_NEIGHBORS, ignore_index=True)\n",
    "    for mod in ABLATED_MODALITIES:\n",
    "        mod_cols = [c for c in test_data.columns if c.startswith(f'{mod}_')]\n",
    "        prediction_input_coh[mod_cols] = filtered_gen_candidates_coh[mod][i].values\n",
    "        prediction_input_multi[mod_cols] = filtered_gen_candidates_multi[mod][i].values\n",
    "    \n",
    "    generated_predictions_coh = rf.predict(prediction_input_coh.values)\n",
    "    generated_predictions_multi = rf.predict(prediction_input_multi.values)\n",
    "\n",
    "    avg_variance_coh = np.mean((generated_predictions_coh != ablated_prediction))\n",
    "    avg_variance_multi = np.mean((generated_predictions_multi != ablated_prediction))\n",
    "\n",
    "    prediction_variances_gen_coh.append(avg_variance_coh)\n",
    "    prediction_variances_gen_multi.append(avg_variance_multi)\n",
    "    \n",
    "variance_df_gen_coh = pd.DataFrame({\n",
    "    'variance': prediction_variances_gen_coh,\n",
    "    'original_index': test_data.index\n",
    "}).sort_values(by='variance', ascending=True)\n",
    "\n",
    "variance_df_gen_multi = pd.DataFrame({\n",
    "    'variance': prediction_variances_gen_multi,\n",
    "    'original_index': test_data.index\n",
    "}).sort_values(by='variance', ascending=True)\n",
    "\n",
    "gen_selective_f1_scores_coh = []\n",
    "for ratio in ABLATION_STEPS:\n",
    "    data_for_pred = test_data.copy()\n",
    "    n_to_ablate = int(len(data_for_pred) * ratio)\n",
    "    ablation_indices = variance_df_gen_coh.head(n_to_ablate)['original_index'].values\n",
    "    if len(ablation_indices) > 0:\n",
    "        data_for_pred.loc[ablation_indices, ablated_cols] = np.nan\n",
    "    preds = rf.predict(data_for_pred.values)\n",
    "    gen_selective_f1_scores_coh.append(f1_score(test_labels, preds, average='weighted', zero_division=0))\n",
    "\n",
    "gen_selective_f1_scores_multi = []\n",
    "for ratio in ABLATION_STEPS:\n",
    "    data_for_pred = test_data.copy()\n",
    "    n_to_ablate = int(len(data_for_pred) * ratio)\n",
    "    ablation_indices = variance_df_gen_multi.head(n_to_ablate)['original_index'].values\n",
    "    if len(ablation_indices) > 0:\n",
    "        data_for_pred.loc[ablation_indices, ablated_cols] = np.nan\n",
    "    preds = rf.predict(data_for_pred.values)\n",
    "    gen_selective_f1_scores_multi.append(f1_score(test_labels, preds, average='weighted', zero_division=0))\n",
    "\n",
    "\n",
    "\n",
    "# --- 6c. Random Progressive Ablation ---\n",
    "print(\"Calculating random progressive ablation scores...\")\n",
    "random_ablation_f1_scores = []\n",
    "for ratio in ABLATION_STEPS:\n",
    "    iter_scores = []\n",
    "    for _ in range(N_ITERATIONS):\n",
    "        data_for_pred = test_data.copy()\n",
    "        n_to_ablate = int(len(data_for_pred) * ratio)\n",
    "        ablation_indices = np.random.choice(data_for_pred.index, size=n_to_ablate, replace=False)\n",
    "        if len(ablation_indices) > 0:\n",
    "            data_for_pred.loc[ablation_indices, ablated_cols] = np.nan\n",
    "        preds = rf.predict(data_for_pred.values)\n",
    "        iter_scores.append(f1_score(test_labels, preds, average='weighted', zero_division=0))\n",
    "    random_ablation_f1_scores.append(np.mean(iter_scores))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 7. PLOTTING RESULTS\n",
    "# =============================================================================\n",
    "print(\"Plotting results...\")\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot all three results\n",
    "plt.plot(ABLATION_STEPS, random_ablation_f1_scores, marker='^', linestyle=':', linewidth=2, label='Random Ablation')\n",
    "plt.plot(ABLATION_STEPS, gen_selective_f1_scores_coh, marker='o', linestyle='--', linewidth=2, label='Selective Ablation (Coherent)')\n",
    "plt.plot(ABLATION_STEPS, gen_selective_f1_scores_multi, marker='s', linestyle='-', linewidth=2, label='Selective Ablation (Multi)')\n",
    "\n",
    "\n",
    "plt.title(f\"Impact of Ablating {', '.join(ABLATED_MODALITIES).upper()}: Random vs. Counterfactual Inference\", fontsize=16)\n",
    "plt.xlabel('Ratio of Samples with Ablated Modalities', fontsize=12)\n",
    "plt.ylabel('Stage Prediction F1-Score', fontsize=12)\n",
    "plt.xticks(ABLATION_STEPS, rotation=45)\n",
    "plt.xlim(-0.02, 1.02)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf21e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 7. PLOTTING RESULTS\n",
    "# =============================================================================\n",
    "print(\"Plotting results...\")\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Invert x-axis values (1 - x)\n",
    "inverted_steps = [1 - x for x in ABLATION_STEPS]\n",
    "\n",
    "# Plot all three results with inverted x-axis\n",
    "plt.plot(inverted_steps, random_ablation_f1_scores, marker='^', linestyle=':', linewidth=2, label='Random Prioritization')\n",
    "plt.plot(inverted_steps, gen_selective_f1_scores_coh, marker='o', linestyle='--', linewidth=2, label='Informed Prioritization (Coherent)')\n",
    "plt.plot(inverted_steps, gen_selective_f1_scores_multi, marker='s', linestyle='-', linewidth=2, label='Informed Prioritization (Multi)')\n",
    "\n",
    "\n",
    "plt.title(f\"Impact of Observing {', '.join(ABLATED_MODALITIES).upper()}: Random Prioritization vs. Counterfactual Inference\", fontsize=16)\n",
    "plt.xlabel('Ratio of Samples with Observed Modalities', fontsize=12)\n",
    "plt.ylabel('Stage Prediction F1-Score', fontsize=12)\n",
    "plt.xticks(inverted_steps, rotation=45)\n",
    "plt.xlim(-0.02, 1.02)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e4d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3076c2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b3de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d0d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CONFIGURATION\n",
    "# =============================================================================\n",
    "# Define all modalities available in the dataset\n",
    "ALL_MODALITIES = ['cna', 'rna', 'rppa', 'wsi']\n",
    "\n",
    "# --- Main Setting ---\n",
    "# Define which modalities to treat as \"missing\" or \"ablated\" for the analysis.\n",
    "ABLATED_MODALITIES = ('rna',)\n",
    "\n",
    "# Mapping from the ablated modalities tuple to the corresponding generated data file.\n",
    "gen_path = '../../results/32/'\n",
    "\n",
    "GENERATED_DATA_MAPPING_coh = {\n",
    "    ('rna',): f'{gen_path}rnaseq_from_coherent/test/generated_samples_from_cna_rppa_wsi_best_mse.csv',\n",
    "    ('wsi',): f'{gen_path}wsi_from_coherent/test/generated_samples_from_cna_rnaseq_rppa_best_mse.csv',\n",
    "}\n",
    "\n",
    "GENERATED_DATA_MAPPING_multi = {\n",
    "    ('rna',): f'{gen_path}rnaseq_from_multi/test/generated_samples_from_cna_rppa_wsi_best_mse.csv',\n",
    "    ('wsi',): f'{gen_path}wsi_from_multi/test/generated_samples_from_cna_rnaseq_rppa_best_mse.csv',\n",
    "}\n",
    "\n",
    "# --- Experiment Parameters ---\n",
    "# MODIFICATION: Number of full experiment repeats to calculate standard deviation\n",
    "N_EXPERIMENT_REPEATS = 10 \n",
    "# Number of iterations for the random ablation baseline (within each experiment)\n",
    "N_ITERATIONS = 30\n",
    "# Steps for the progressive ablation plot (from 0% to 100% of samples ablated)\n",
    "ABLATION_STEPS = np.arange(0, 1.05, 0.05)\n",
    "# Number of neighbors for the k-NN baseline\n",
    "K_NEIGHBORS = 10\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. DATA LOADING AND PREPARATION\n",
    "# =============================================================================\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# Load raw training and testing data using your specified paths\n",
    "train_path = '../../datasets_TCGA/07_normalized/32/'\n",
    "train_raw = {\n",
    "    'cna': pd.read_csv(f'{train_path}cna_train.csv', sep=','),\n",
    "    'rna': pd.read_csv(f'{train_path}rnaseq_train.csv', sep=','),\n",
    "    'rppa': pd.read_csv(f'{train_path}rppa_train.csv', sep=','),\n",
    "    'wsi': pd.read_csv(f'{train_path}wsi_train.csv', sep=','),\n",
    "}\n",
    "\n",
    "test_path = '../../datasets_TCGA/07_normalized/32/'\n",
    "test_raw = {\n",
    "    'cna': pd.read_csv(f'{train_path}cna_test.csv', sep=','),\n",
    "    'rna': pd.read_csv(f'{train_path}rnaseq_test.csv', sep=','),\n",
    "    'rppa': pd.read_csv(f'{train_path}rppa_test.csv', sep=','),\n",
    "    'wsi': pd.read_csv(f'{train_path}wsi_test.csv', sep=','),\n",
    "}\n",
    "\n",
    "labels_path = '../../datasets_TCGA/downstream_labels/'\n",
    "train_stage = pd.read_csv(f'{labels_path}train_stage.csv')\n",
    "test_stage = pd.read_csv(f'{labels_path}test_stage.csv')\n",
    "\n",
    "\n",
    "def clean_and_unify_tables(df_dict, modalities):\n",
    "    \"\"\"\n",
    "    Unifies multiple modality-specific dataframes into a single dataframe.\n",
    "    \"\"\"\n",
    "    sample_ids = df_dict[modalities[0]]['sample_id'].values\n",
    "    for m in modalities:\n",
    "        assert np.all(df_dict[m]['sample_id'].values == sample_ids), f\"Sample IDs for {m} do not match.\"\n",
    "\n",
    "    processed_dfs = []\n",
    "    for m in modalities:\n",
    "        df = df_dict[m].drop(columns=['sample_id'])\n",
    "        df.columns = [f'{m}_{i+1}' for i in range(df.shape[1])]\n",
    "        processed_dfs.append(df)\n",
    "        \n",
    "    return pd.concat(processed_dfs, axis=1)\n",
    "\n",
    "print(\"Processing and unifying tables...\")\n",
    "train_full = clean_and_unify_tables(train_raw, ALL_MODALITIES)\n",
    "test_full = clean_and_unify_tables(test_raw, ALL_MODALITIES)\n",
    "\n",
    "print(f\"Train data shape: {train_full.shape}\")\n",
    "print(f\"Test data shape: {test_full.shape}\")\n",
    "\n",
    "# Data filtering and label encoding (done once before the main loop)\n",
    "train_mask = ~train_stage['stage'].isna()\n",
    "train_data = train_full[train_mask]\n",
    "train_labels_filtered = train_stage['stage'][train_mask]\n",
    "\n",
    "test_mask = ~test_stage['stage'].isna()\n",
    "test_data_full = test_full[test_mask].reset_index(drop=True)\n",
    "test_labels_filtered = test_stage['stage'][test_mask].reset_index(drop=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_labels = le.fit_transform(train_labels_filtered)\n",
    "test_labels = le.transform(test_labels_filtered)\n",
    "\n",
    "# This section for loading generated data is kept as is from your original code\n",
    "generated_file_key = ABLATED_MODALITIES\n",
    "if generated_file_key not in GENERATED_DATA_MAPPING_coh:\n",
    "    raise ValueError(f\"No generated data file specified for the modality combination: {generated_file_key}\")\n",
    "\n",
    "generated_file_name_coh = GENERATED_DATA_MAPPING_coh[generated_file_key]\n",
    "generated_file_name_multi = GENERATED_DATA_MAPPING_multi[generated_file_key]\n",
    "\n",
    "try:\n",
    "    gen_data_long_coh = {mod: pd.read_csv(generated_file_name_coh, sep=',') for mod in ABLATED_MODALITIES}\n",
    "    gen_data_long_multi = {mod: pd.read_csv(generated_file_name_multi, sep=',') for mod in ABLATED_MODALITIES}\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: A generated data file was not found. Please check paths.\")\n",
    "    exit()\n",
    "\n",
    "# =============================================================================\n",
    "# 3. FULL EXPERIMENT LOOP\n",
    "# =============================================================================\n",
    "# MODIFICATION: Create master lists to store results from all runs\n",
    "all_runs_gen_coh = []\n",
    "all_runs_gen_multi = []\n",
    "all_runs_random = []\n",
    "\n",
    "for run in range(N_EXPERIMENT_REPEATS):\n",
    "    print(f\"\\n{'='*20} STARTING EXPERIMENT RUN {run + 1}/{N_EXPERIMENT_REPEATS} {'='*20}\")\n",
    "    \n",
    "    # --- 3a. Model Training (inside the loop) ---\n",
    "    # MODIFICATION: A new model is trained in each run with a different random_state\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42 + run, oob_score=True)\n",
    "    print(f\"Run {run+1}: Training Random Forest model with random_state={42+run}...\")\n",
    "    rf.fit(train_data.values, train_labels)\n",
    "\n",
    "    # --- 3b. Progressive Ablation Analysis (inside the loop) ---\n",
    "    print(f\"Run {run+1}: Calculating progressive ablation scores...\")\n",
    "    \n",
    "    # Use a clean copy of the test data for each run\n",
    "    test_data = test_data_full.copy()\n",
    "    ablated_cols = [c for c in test_data.columns if c.split('_')[0] in ABLATED_MODALITIES]\n",
    "    \n",
    "    # The variance of predictions now depends on the specific model trained in this run.\n",
    "    # Therefore, this calculation must be inside the loop.\n",
    "    print(f\"Run {run+1}: Calculating selective ablation variances...\")\n",
    "    \n",
    "    # The logic for reshaping generated data and getting candidates is kept from your code\n",
    "    n_test_samples = len(test_full)\n",
    "    generated_candidates_coh = {mod: [] for mod in ABLATED_MODALITIES}\n",
    "    generated_candidates_multi = {mod: [] for mod in ABLATED_MODALITIES}\n",
    "    for mod in ABLATED_MODALITIES:\n",
    "        for i in range(n_test_samples):\n",
    "            gather_indices = np.arange(K_NEIGHBORS) * n_test_samples + i\n",
    "            generated_candidates_coh[mod].append(gen_data_long_coh[mod].iloc[gather_indices])\n",
    "            generated_candidates_multi[mod].append(gen_data_long_multi[mod].iloc[gather_indices])\n",
    "    \n",
    "    original_indices = test_mask[test_mask].index\n",
    "    filtered_gen_candidates_coh = {mod: [generated_candidates_coh[mod][i] for i in original_indices] for mod in ABLATED_MODALITIES}\n",
    "    filtered_gen_candidates_multi = {mod: [generated_candidates_multi[mod][i] for i in original_indices] for mod in ABLATED_MODALITIES}\n",
    "    \n",
    "    # Re-calculate prediction variances for the current model\n",
    "    prediction_variances_gen_coh, prediction_variances_gen_multi = [], []\n",
    "    for i in range(len(test_data)):\n",
    "        original_sample = test_data.iloc[[i]]\n",
    "        ablated_sample = original_sample.copy()\n",
    "        ablated_sample[ablated_cols] = np.nan\n",
    "        ablated_prediction = rf.predict(ablated_sample.values)[0]\n",
    "        \n",
    "        prediction_input_coh = pd.concat([original_sample] * K_NEIGHBORS, ignore_index=True)\n",
    "        prediction_input_multi = pd.concat([original_sample] * K_NEIGHBORS, ignore_index=True)\n",
    "        for mod in ABLATED_MODALITIES:\n",
    "            mod_cols = [c for c in test_data.columns if c.startswith(f'{mod}_')]\n",
    "            prediction_input_coh[mod_cols] = filtered_gen_candidates_coh[mod][i].values\n",
    "            prediction_input_multi[mod_cols] = filtered_gen_candidates_multi[mod][i].values\n",
    "            \n",
    "        generated_predictions_coh = rf.predict(prediction_input_coh.values)\n",
    "        generated_predictions_multi = rf.predict(prediction_input_multi.values)\n",
    "        prediction_variances_gen_coh.append(np.mean((generated_predictions_coh != ablated_prediction)))\n",
    "        prediction_variances_gen_multi.append(np.mean((generated_predictions_multi != ablated_prediction)))\n",
    "        \n",
    "    variance_df_gen_coh = pd.DataFrame({'variance': prediction_variances_gen_coh, 'original_index': test_data.index}).sort_values(by='variance', ascending=True)\n",
    "    variance_df_gen_multi = pd.DataFrame({'variance': prediction_variances_gen_multi, 'original_index': test_data.index}).sort_values(by='variance', ascending=True)\n",
    "\n",
    "    # Calculate F1 scores for all methods for the current model\n",
    "    gen_selective_f1_scores_coh, gen_selective_f1_scores_multi, random_ablation_f1_scores = [], [], []\n",
    "\n",
    "    for ratio in ABLATION_STEPS:\n",
    "        # Selective Ablation (Coherent)\n",
    "        data_for_pred_coh = test_data.copy()\n",
    "        n_to_ablate_coh = int(len(data_for_pred_coh) * ratio)\n",
    "        ablation_indices_coh = variance_df_gen_coh.head(n_to_ablate_coh)['original_index'].values\n",
    "        if len(ablation_indices_coh) > 0:\n",
    "            data_for_pred_coh.loc[ablation_indices_coh, ablated_cols] = np.nan\n",
    "        preds_coh = rf.predict(data_for_pred_coh.values)\n",
    "        gen_selective_f1_scores_coh.append(f1_score(test_labels, preds_coh, average='weighted', zero_division=0))\n",
    "\n",
    "        # Selective Ablation (Multi)\n",
    "        data_for_pred_multi = test_data.copy()\n",
    "        n_to_ablate_multi = int(len(data_for_pred_multi) * ratio)\n",
    "        ablation_indices_multi = variance_df_gen_multi.head(n_to_ablate_multi)['original_index'].values\n",
    "        if len(ablation_indices_multi) > 0:\n",
    "            data_for_pred_multi.loc[ablation_indices_multi, ablated_cols] = np.nan\n",
    "        preds_multi = rf.predict(data_for_pred_multi.values)\n",
    "        gen_selective_f1_scores_multi.append(f1_score(test_labels, preds_multi, average='weighted', zero_division=0))\n",
    "\n",
    "        # Random Ablation\n",
    "        iter_scores = []\n",
    "        for _ in range(N_ITERATIONS):\n",
    "            data_for_pred_rand = test_data.copy()\n",
    "            n_to_ablate_rand = int(len(data_for_pred_rand) * ratio)\n",
    "            ablation_indices_rand = np.random.choice(data_for_pred_rand.index, size=n_to_ablate_rand, replace=False)\n",
    "            if len(ablation_indices_rand) > 0:\n",
    "                data_for_pred_rand.loc[ablation_indices_rand, ablated_cols] = np.nan\n",
    "            preds_rand = rf.predict(data_for_pred_rand.values)\n",
    "            iter_scores.append(f1_score(test_labels, preds_rand, average='weighted', zero_division=0))\n",
    "        random_ablation_f1_scores.append(np.mean(iter_scores))\n",
    "\n",
    "    # --- Store the results of the current run ---\n",
    "    all_runs_gen_coh.append(gen_selective_f1_scores_coh)\n",
    "    all_runs_gen_multi.append(gen_selective_f1_scores_multi)\n",
    "    all_runs_random.append(random_ablation_f1_scores)\n",
    "\n",
    "print(f\"\\n{'='*20} ALL EXPERIMENT RUNS COMPLETED {'='*20}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. AGGREGATE RESULTS AND CALCULATE STATISTICS\n",
    "# =============================================================================\n",
    "print(\"\\nAggregating results and calculating statistics...\")\n",
    "\n",
    "# Calculate mean and standard deviation across the experiment runs (axis=0)\n",
    "mean_gen_coh = np.mean(all_runs_gen_coh, axis=0)\n",
    "std_gen_coh = np.std(all_runs_gen_coh, axis=0)\n",
    "\n",
    "mean_gen_multi = np.mean(all_runs_gen_multi, axis=0)\n",
    "std_gen_multi = np.std(all_runs_gen_multi, axis=0)\n",
    "\n",
    "mean_random = np.mean(all_runs_random, axis=0)\n",
    "std_random = np.std(all_runs_random, axis=0)\n",
    "\n",
    "# =============================================================================\n",
    "# 5. PLOTTING RESULTS\n",
    "# =============================================================================\n",
    "print(\"Plotting aggregated results...\")\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# --- Plot 1: Ablation ---\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot Random Ablation with Std Dev\n",
    "plt.plot(ABLATION_STEPS, mean_random, marker='^', linestyle=':', linewidth=2, label='Random Ablation')\n",
    "plt.fill_between(ABLATION_STEPS, mean_random - std_random, mean_random + std_random, alpha=0.2)\n",
    "\n",
    "# Plot Selective Ablation (Coherent) with Std Dev\n",
    "plt.plot(ABLATION_STEPS, mean_gen_coh, marker='o', linestyle='--', linewidth=2, label='Selective Ablation (Coherent)')\n",
    "plt.fill_between(ABLATION_STEPS, mean_gen_coh - std_gen_coh, mean_gen_coh + std_gen_coh, alpha=0.2)\n",
    "\n",
    "# Plot Selective Ablation (Multi) with Std Dev\n",
    "plt.plot(ABLATION_STEPS, mean_gen_multi, marker='s', linestyle='-', linewidth=2, label='Selective Ablation (Multi)')\n",
    "plt.fill_between(ABLATION_STEPS, mean_gen_multi - std_gen_multi, mean_gen_multi + std_gen_multi, alpha=0.2)\n",
    "\n",
    "plt.title(f\"Impact of Ablating {', '.join(ABLATED_MODALITIES).upper()} (Avg. of {N_EXPERIMENT_REPEATS} Runs)\", fontsize=16)\n",
    "plt.xlabel('Ratio of Samples with Ablated Modalities', fontsize=12)\n",
    "plt.ylabel('Stage Prediction F1-Score', fontsize=12)\n",
    "plt.xticks(ABLATION_STEPS, [f\"{x:.0%}\" for x in ABLATION_STEPS], rotation=45)\n",
    "plt.xlim(-0.02, 1.02)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Plot 2: Inverted (Prioritization) ---\n",
    "plt.figure(figsize=(14, 8))\n",
    "inverted_steps = 1 - ABLATION_STEPS\n",
    "\n",
    "# Plot Random Prioritization with Std Dev\n",
    "plt.plot(inverted_steps, mean_random, marker='^', linestyle=':', linewidth=2, label='Random Prioritization')\n",
    "plt.fill_between(inverted_steps, mean_random - std_random, mean_random + std_random, alpha=0.2)\n",
    "\n",
    "# Plot Informed Prioritization (Coherent) with Std Dev\n",
    "plt.plot(inverted_steps, mean_gen_coh, marker='o', linestyle='--', linewidth=2, label='Informed Prioritization (Coherent)')\n",
    "plt.fill_between(inverted_steps, mean_gen_coh - std_gen_coh, mean_gen_coh + std_gen_coh, alpha=0.2)\n",
    "\n",
    "# Plot Informed Prioritization (Multi) with Std Dev\n",
    "plt.plot(inverted_steps, mean_gen_multi, marker='s', linestyle='-', linewidth=2, label='Informed Prioritization (Multi)')\n",
    "plt.fill_between(inverted_steps, mean_gen_multi - std_gen_multi, mean_gen_multi + std_gen_multi, alpha=0.2)\n",
    "\n",
    "plt.title(f\"Impact of Observing {', '.join(ABLATED_MODALITIES).upper()} - Random Prioritization vs. Counterfactual Inference\", fontsize=16)\n",
    "plt.xlabel('Ratio of Samples with Observed Modalities', fontsize=12)\n",
    "plt.ylabel('Stage Prediction F1-Score', fontsize=12)\n",
    "plt.xticks(inverted_steps, [f\"{x:.0%}\" for x in inverted_steps], rotation=45)\n",
    "plt.xlim(1.02, -0.02)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f19095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot 2: Inverted (Prioritization) ---\n",
    "plt.figure(figsize=(14, 8))\n",
    "inverted_steps = 1 - ABLATION_STEPS\n",
    "\n",
    "# Plot Random Prioritization with Std Dev\n",
    "plt.plot(inverted_steps, mean_random, marker='^', linestyle=':', linewidth=2, label='Random Prioritization')\n",
    "plt.fill_between(inverted_steps, mean_random - std_random, mean_random + std_random, alpha=0.2)\n",
    "\n",
    "# Plot Informed Prioritization (Coherent) with Std Dev\n",
    "plt.plot(inverted_steps, mean_gen_coh, marker='o', linestyle='--', linewidth=2, label='Informed Prioritization (Coherent)')\n",
    "plt.fill_between(inverted_steps, mean_gen_coh - std_gen_coh, mean_gen_coh + std_gen_coh, alpha=0.2)\n",
    "\n",
    "# Plot Informed Prioritization (Multi) with Std Dev\n",
    "plt.plot(inverted_steps, mean_gen_multi, marker='s', linestyle='-', linewidth=2, label='Informed Prioritization (Multi)')\n",
    "plt.fill_between(inverted_steps, mean_gen_multi - std_gen_multi, mean_gen_multi + std_gen_multi, alpha=0.2)\n",
    "\n",
    "plt.title(f\"Impact of Observing {', '.join(ABLATED_MODALITIES).upper()} - Random Prioritization vs. Counterfactual Inference\", fontsize=16)\n",
    "plt.xlabel('Ratio of Samples with Observed Modalities', fontsize=12)\n",
    "plt.ylabel('Stage Prediction F1-Score', fontsize=12)\n",
    "plt.xticks(inverted_steps, [f\"{x:.0%}\" for x in inverted_steps], rotation=45)\n",
    "plt.xlim(1.02, -0.02)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8292c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "def plot_prioritization_impact_polished(\n",
    "    ablation_steps: np.ndarray,\n",
    "    mean_random: np.ndarray,\n",
    "    std_random: np.ndarray,\n",
    "    mean_gen_coh: np.ndarray,\n",
    "    std_gen_coh: np.ndarray,\n",
    "    mean_gen_multi: np.ndarray,\n",
    "    std_gen_multi: np.ndarray,\n",
    "    ablated_modalities: List[str],\n",
    "    color_map: Optional[Dict[str, str]] = None,\n",
    "    legend_labels: Optional[Dict[str, str]] = None,\n",
    "    figsize: Tuple[float, float] = (14, 8),\n",
    "    title: Optional[str] = None,\n",
    "    xlabel: str = 'Ratio of Samples with Observed Modalities',\n",
    "    ylabel: str = 'Stage Prediction F1-Score',\n",
    "    savepath: Optional[str] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a polished line plot to show the impact of observing modalities.\n",
    "\n",
    "    This function is adapted from a bar chart plotting style to a line plot,\n",
    "    maintaining a high-quality, publication-ready aesthetic. It visualizes\n",
    "    the performance of different prioritization strategies as more modalities\n",
    "    are observed.\n",
    "\n",
    "    Args:\n",
    "        ablation_steps: Steps of ablation (e.g., from 0.0 to 1.0).\n",
    "        mean_random: Mean performance for random prioritization.\n",
    "        std_random: Standard deviation for random prioritization.\n",
    "        mean_gen_coh: Mean performance for informed (coherent) prioritization.\n",
    "        std_gen_coh: Standard deviation for informed (coherent) prioritization.\n",
    "        mean_gen_multi: Mean performance for informed (multi) prioritization.\n",
    "        std_gen_multi: Standard deviation for informed (multi) prioritization.\n",
    "        ablated_modalities: List of names of the modalities being ablated.\n",
    "        color_map: Optional dictionary to override default colors.\n",
    "        legend_labels: Optional dictionary to override default legend labels.\n",
    "        figsize: The size of the figure.\n",
    "        title: The main title of the plot.\n",
    "        xlabel: The label for the x-axis.\n",
    "        ylabel: The label for the y-axis.\n",
    "        savepath: Optional path to save the figure.\n",
    "    \"\"\"\n",
    "    # --- 1. AESTHETIC DEFAULTS & SETUP ---\n",
    "    if color_map is None:\n",
    "        color_map = {\n",
    "            'random': '#9c2409',        # Muted Red\n",
    "            'coherent': '#56b4e9',      # Sky Blue\n",
    "            'multi': '#0072b2',         # Deeper Blue\n",
    "        }\n",
    "\n",
    "    if legend_labels is None:\n",
    "        legend_labels = {\n",
    "            'random': 'Random Prioritization',\n",
    "            'coherent': 'Informed Prioritization (Coherent)',\n",
    "            'multi': 'Informed Prioritization (Multi)'\n",
    "        }\n",
    "\n",
    "    if title is None:\n",
    "        title = f\"Impact of Observing {', '.join(ablated_modalities).upper()} - Random Prioritization vs. Counterfactual Inference\"\n",
    "\n",
    "    # --- 2. DATA PREPARATION ---\n",
    "    # The x-axis is the ratio of observed data, which is 1 minus the ablation ratio\n",
    "    inverted_steps = 1 - ablation_steps\n",
    "\n",
    "    # --- 3. PLOTTING ---\n",
    "    plt.style.use('seaborn-v0_8-white')\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Plot Random Prioritization\n",
    "    ax.plot(inverted_steps, mean_random, marker='o', linestyle='-', linewidth=2,\n",
    "            label=legend_labels['random'], color=color_map['random'], zorder=10)\n",
    "    ax.fill_between(inverted_steps, mean_random - std_random, mean_random + std_random,\n",
    "                    alpha=0.15, color=color_map['random'], zorder=5)\n",
    "\n",
    "    # Plot Informed Prioritization (Coherent)\n",
    "    ax.plot(inverted_steps, mean_gen_coh, marker='s', linestyle='--', linewidth=2,\n",
    "            label=legend_labels['coherent'], color=color_map['coherent'], zorder=10)\n",
    "    ax.fill_between(inverted_steps, mean_gen_coh - std_gen_coh, mean_gen_coh + std_gen_coh,\n",
    "                    alpha=0.15, color=color_map['coherent'], zorder=5)\n",
    "\n",
    "    # Plot Informed Prioritization (Multi)\n",
    "    ax.plot(inverted_steps, mean_gen_multi, marker='^', linestyle='--', linewidth=2,\n",
    "            label=legend_labels['multi'], color=color_map['multi'], zorder=10)\n",
    "    ax.fill_between(inverted_steps, mean_gen_multi - std_gen_multi, mean_gen_multi + std_gen_multi,\n",
    "                    alpha=0.15, color=color_map['multi'], zorder=5)\n",
    "\n",
    "\n",
    "    # --- 4. VISUAL REFINEMENTS ---\n",
    "\n",
    "    # \"Classy\" horizontal grid\n",
    "    ax.yaxis.grid(True, linewidth=0.7, color=\"#CDCCCC\", zorder=0)\n",
    "    ax.xaxis.grid(True, linewidth=0.7, color=\"#CDCCCC\", zorder=0)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    # Less prominent axes and ticks\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_color('#B0B0B0')\n",
    "    ax.tick_params(axis='x', colors='#505050', length=0)\n",
    "    ax.tick_params(axis='y', colors='#505050', length=0)\n",
    "    ax.xaxis.label.set_color('#303030')\n",
    "    ax.yaxis.label.set_color('#303030')\n",
    "\n",
    "    # X-axis ticks and limits (inverted)\n",
    "    new_ticks = np.arange(0, 1.1, 0.1)\n",
    "    ax.set_xticks(new_ticks)\n",
    "    ax.set_xticklabels([f\"{x:.1f}\" for x in new_ticks], rotation=0)\n",
    "    ax.set_xlim(1.02, -0.02) # Invert the axis from 100% down to 0%\n",
    "\n",
    "    # Y-axis limits adjusted to data range for readability\n",
    "    all_mins = np.concatenate([\n",
    "        mean_random - std_random,\n",
    "        mean_gen_coh - std_gen_coh,\n",
    "        mean_gen_multi - std_gen_multi\n",
    "    ])\n",
    "    all_maxs = np.concatenate([\n",
    "        mean_random + std_random,\n",
    "        mean_gen_coh + std_gen_coh,\n",
    "        mean_gen_multi + std_gen_multi\n",
    "    ])\n",
    "    plot_min, plot_max = all_mins.min(), all_maxs.max()\n",
    "    padding = (plot_max - plot_min) * 0.05\n",
    "    ax.set_ylim(plot_min - padding, plot_max + padding)\n",
    "\n",
    "    # Final labels and title\n",
    "    ax.set_xlabel(xlabel, fontsize=12, labelpad=15)\n",
    "    ax.set_ylabel(ylabel, fontsize=12, labelpad=15)\n",
    "    ax.set_title(title, fontsize=16, pad=20, weight='bold')\n",
    "\n",
    "    # Legend on the right\n",
    "    ax.legend(\n",
    "        title='Prioritization Strategy',\n",
    "        loc='center left',\n",
    "        bbox_to_anchor=(1.02, 0.5),\n",
    "        frameon=False,\n",
    "        fontsize=11,\n",
    "        title_fontsize=12\n",
    "    )\n",
    "    \n",
    "    # --- 5. FINAL LAYOUT ADJUSTMENTS ---\n",
    "    fig.subplots_adjust(\n",
    "        left=0.07,\n",
    "        right=0.82, # Make space for the legend\n",
    "        bottom=0.1,\n",
    "        top=0.9\n",
    "    )\n",
    "\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Call the polished plotting function\n",
    "plot_prioritization_impact_polished(\n",
    "    ablation_steps=ABLATION_STEPS,\n",
    "    mean_random=mean_random,\n",
    "    std_random=std_random,\n",
    "    mean_gen_coh=mean_gen_coh,\n",
    "    std_gen_coh=std_gen_coh,\n",
    "    mean_gen_multi=mean_gen_multi,\n",
    "    std_gen_multi=std_gen_multi,\n",
    "    ablated_modalities=ABLATED_MODALITIES,\n",
    "    savepath=f\"../../results/downstream/task_07_counterfactual/{'_'.join(ABLATED_MODALITIES)}_prioritization_impact_plot.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99a2e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "def plot_prioritization_impact_polished(\n",
    "    ablation_steps: np.ndarray,\n",
    "    mean_random: np.ndarray,\n",
    "    std_random: np.ndarray,\n",
    "    mean_gen_coh: np.ndarray,\n",
    "    std_gen_coh: np.ndarray,\n",
    "    mean_gen_multi: np.ndarray,\n",
    "    std_gen_multi: np.ndarray,\n",
    "    ablated_modalities: List[str],\n",
    "    color_map: Optional[Dict[str, str]] = None,\n",
    "    legend_labels: Optional[Dict[str, str]] = None,\n",
    "    figsize: Tuple[float, float] = (14, 8),\n",
    "    title: Optional[str] = None,\n",
    "    xlabel: str = 'Ratio of Samples with Observed Modalities',\n",
    "    ylabel: str = 'Stage Prediction F1-Score',\n",
    "    savepath: Optional[str] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a polished line plot to show the impact of observing modalities.\n",
    "\n",
    "    This function is adapted from a bar chart plotting style to a line plot,\n",
    "    maintaining a high-quality, publication-ready aesthetic. It visualizes\n",
    "    the performance of different prioritization strategies as more modalities\n",
    "    are observed.\n",
    "\n",
    "    Args:\n",
    "        ablation_steps: Steps of ablation (e.g., from 0.0 to 1.0).\n",
    "        mean_random: Mean performance for random prioritization.\n",
    "        std_random: Standard deviation for random prioritization.\n",
    "        mean_gen_coh: Mean performance for informed (coherent) prioritization.\n",
    "        std_gen_coh: Standard deviation for informed (coherent) prioritization.\n",
    "        mean_gen_multi: Mean performance for informed (multi) prioritization.\n",
    "        std_gen_multi: Standard deviation for informed (multi) prioritization.\n",
    "        ablated_modalities: List of names of the modalities being ablated.\n",
    "        color_map: Optional dictionary to override default colors.\n",
    "        legend_labels: Optional dictionary to override default legend labels.\n",
    "        figsize: The size of the figure.\n",
    "        title: The main title of the plot.\n",
    "        xlabel: The label for the x-axis.\n",
    "        ylabel: The label for the y-axis.\n",
    "        savepath: Optional path to save the figure.\n",
    "    \"\"\"\n",
    "    # --- 1. AESTHETIC DEFAULTS & SETUP ---\n",
    "    if color_map is None:\n",
    "        color_map = {\n",
    "            'random': '#9c2409',        # Muted Red\n",
    "            'coherent': '#56b4e9',      # Sky Blue\n",
    "            'multi': '#0072b2',         # Deeper Blue\n",
    "        }\n",
    "\n",
    "    if legend_labels is None:\n",
    "        legend_labels = {\n",
    "            'random': 'Random Prioritization',\n",
    "            'coherent': 'Informed Prioritization (Coherent)',\n",
    "            'multi': 'Informed Prioritization (Multi)'\n",
    "        }\n",
    "\n",
    "    if title is None:\n",
    "        title = f\"Impact of Observing {', '.join(ablated_modalities).upper()} - Random Prioritization vs. Counterfactual Inference\"\n",
    "\n",
    "    # --- 2. DATA PREPARATION ---\n",
    "    # The x-axis is the ratio of observed data, which is 1 minus the ablation ratio\n",
    "    inverted_steps = 1 - ablation_steps\n",
    "\n",
    "    # --- 3. PLOTTING ---\n",
    "    plt.style.use('seaborn-v0_8-white')\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Plot Random Prioritization with error bars\n",
    "    ax.errorbar(inverted_steps, mean_random, yerr=std_random, marker='o', linestyle='-',\n",
    "                linewidth=2, label=legend_labels['random'], color=color_map['random'],\n",
    "                zorder=10, capsize=5)\n",
    "\n",
    "    # Plot Informed Prioritization (Coherent) with error bars\n",
    "    ax.errorbar(inverted_steps, mean_gen_coh, yerr=std_gen_coh, marker='s', linestyle='--',\n",
    "                linewidth=2, label=legend_labels['coherent'], color=color_map['coherent'],\n",
    "                zorder=10, capsize=5)\n",
    "\n",
    "    # Plot Informed Prioritization (Multi) with error bars\n",
    "    ax.errorbar(inverted_steps, mean_gen_multi, yerr=std_gen_multi, marker='^', linestyle='--',\n",
    "            linewidth=2, label=legend_labels['multi'], color=color_map['multi'],\n",
    "            zorder=10, capsize=5)\n",
    "\n",
    "\n",
    "    # --- 4. VISUAL REFINEMENTS ---\n",
    "\n",
    "    # \"Classy\" horizontal grid\n",
    "    ax.yaxis.grid(True, linewidth=0.7, color=\"#CDCCCC\", zorder=0)\n",
    "    ax.xaxis.grid(True, linewidth=0.7, color=\"#CDCCCC\", zorder=0)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    # Less prominent axes and ticks\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_color('#B0B0B0')\n",
    "    ax.tick_params(axis='x', colors='#505050', length=0)\n",
    "    ax.tick_params(axis='y', colors='#505050', length=0)\n",
    "    ax.xaxis.label.set_color('#303030')\n",
    "    ax.yaxis.label.set_color('#303030')\n",
    "\n",
    "    # X-axis ticks and limits (inverted)\n",
    "    new_ticks = np.arange(0, 1.1, 0.1)\n",
    "    ax.set_xticks(new_ticks)\n",
    "    ax.set_xticklabels([f\"{x:.1f}\" for x in new_ticks], rotation=0)\n",
    "    ax.set_xlim(1.02, -0.02) # Invert the axis from 100% down to 0%\n",
    "\n",
    "    # Y-axis limits adjusted to data range for readability\n",
    "    all_mins = np.concatenate([\n",
    "        mean_random - std_random,\n",
    "        mean_gen_coh - std_gen_coh,\n",
    "        mean_gen_multi - std_gen_multi\n",
    "    ])\n",
    "    all_maxs = np.concatenate([\n",
    "        mean_random + std_random,\n",
    "        mean_gen_coh + std_gen_coh,\n",
    "        mean_gen_multi + std_gen_multi\n",
    "    ])\n",
    "    plot_min, plot_max = all_mins.min(), all_maxs.max()\n",
    "    padding = (plot_max - plot_min) * 0.05\n",
    "    ax.set_ylim(plot_min - padding, plot_max + padding)\n",
    "\n",
    "    # Final labels and title\n",
    "    ax.set_xlabel(xlabel, fontsize=12, labelpad=15)\n",
    "    ax.set_ylabel(ylabel, fontsize=12, labelpad=15)\n",
    "    ax.set_title(title, fontsize=16, pad=20, weight='bold')\n",
    "\n",
    "    # Legend on the right\n",
    "    ax.legend(\n",
    "        title='Prioritization Strategy',\n",
    "        loc='center left',\n",
    "        bbox_to_anchor=(1.02, 0.5),\n",
    "        frameon=False,\n",
    "        fontsize=11,\n",
    "        title_fontsize=12\n",
    "    )\n",
    "    \n",
    "    # --- 5. FINAL LAYOUT ADJUSTMENTS ---\n",
    "    fig.subplots_adjust(\n",
    "        left=0.07,\n",
    "        right=0.82, # Make space for the legend\n",
    "        bottom=0.1,\n",
    "        top=0.9\n",
    "    )\n",
    "\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Call the polished plotting function\n",
    "plot_prioritization_impact_polished(\n",
    "    ablation_steps=ABLATION_STEPS,\n",
    "    mean_random=mean_random,\n",
    "    std_random=std_random,\n",
    "    mean_gen_coh=mean_gen_coh,\n",
    "    std_gen_coh=std_gen_coh,\n",
    "    mean_gen_multi=mean_gen_multi,\n",
    "    std_gen_multi=std_gen_multi,\n",
    "    ablated_modalities=ABLATED_MODALITIES,\n",
    "    savepath=f\"../../results/downstream/task_07_counterfactual/{'_'.join(ABLATED_MODALITIES)}_prioritization_impact_plot_err.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccbc311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e51b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8db3608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CONFIGURATION\n",
    "# =============================================================================\n",
    "# Define all modalities available in the dataset\n",
    "ALL_MODALITIES = ['cna', 'rna', 'rppa', 'wsi']\n",
    "\n",
    "# --- Main Setting ---\n",
    "# Define which modalities to treat as \"missing\" or \"ablated\" for the analysis.\n",
    "ABLATED_MODALITIES = ('wsi',)\n",
    "\n",
    "# Mapping from the ablated modalities tuple to the corresponding generated data file.\n",
    "gen_path = '../../results/32/'\n",
    "\n",
    "GENERATED_DATA_MAPPING_coh = {\n",
    "    ('rna',): f'{gen_path}rnaseq_from_coherent/test/generated_samples_from_cna_rppa_wsi_best_mse.csv',\n",
    "    ('wsi',): f'{gen_path}wsi_from_coherent/test/generated_samples_from_cna_rnaseq_rppa_best_mse.csv',\n",
    "}\n",
    "\n",
    "GENERATED_DATA_MAPPING_multi = {\n",
    "    ('rna',): f'{gen_path}rnaseq_from_multi/test/generated_samples_from_cna_rppa_wsi_best_mse.csv',\n",
    "    ('wsi',): f'{gen_path}wsi_from_multi/test/generated_samples_from_cna_rnaseq_rppa_best_mse.csv',\n",
    "}\n",
    "\n",
    "# --- Experiment Parameters ---\n",
    "# MODIFICATION: Number of full experiment repeats to calculate standard deviation\n",
    "N_EXPERIMENT_REPEATS = 10 \n",
    "# Number of iterations for the random ablation baseline (within each experiment)\n",
    "N_ITERATIONS = 30\n",
    "# Steps for the progressive ablation plot (from 0% to 100% of samples ablated)\n",
    "ABLATION_STEPS = np.arange(0, 1.05, 0.05)\n",
    "# Number of neighbors for the k-NN baseline\n",
    "K_NEIGHBORS = 10\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. DATA LOADING AND PREPARATION\n",
    "# =============================================================================\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# Load raw training and testing data using your specified paths\n",
    "train_path = '../../datasets_TCGA/07_normalized/32/'\n",
    "train_raw = {\n",
    "    'cna': pd.read_csv(f'{train_path}cna_train.csv', sep=','),\n",
    "    'rna': pd.read_csv(f'{train_path}rnaseq_train.csv', sep=','),\n",
    "    'rppa': pd.read_csv(f'{train_path}rppa_train.csv', sep=','),\n",
    "    'wsi': pd.read_csv(f'{train_path}wsi_train.csv', sep=','),\n",
    "}\n",
    "\n",
    "test_path = '../../datasets_TCGA/07_normalized/32/'\n",
    "test_raw = {\n",
    "    'cna': pd.read_csv(f'{train_path}cna_test.csv', sep=','),\n",
    "    'rna': pd.read_csv(f'{train_path}rnaseq_test.csv', sep=','),\n",
    "    'rppa': pd.read_csv(f'{train_path}rppa_test.csv', sep=','),\n",
    "    'wsi': pd.read_csv(f'{train_path}wsi_test.csv', sep=','),\n",
    "}\n",
    "\n",
    "labels_path = '../../datasets_TCGA/downstream_labels/'\n",
    "train_stage = pd.read_csv(f'{labels_path}train_stage.csv')\n",
    "test_stage = pd.read_csv(f'{labels_path}test_stage.csv')\n",
    "\n",
    "\n",
    "def clean_and_unify_tables(df_dict, modalities):\n",
    "    \"\"\"\n",
    "    Unifies multiple modality-specific dataframes into a single dataframe.\n",
    "    \"\"\"\n",
    "    sample_ids = df_dict[modalities[0]]['sample_id'].values\n",
    "    for m in modalities:\n",
    "        assert np.all(df_dict[m]['sample_id'].values == sample_ids), f\"Sample IDs for {m} do not match.\"\n",
    "\n",
    "    processed_dfs = []\n",
    "    for m in modalities:\n",
    "        df = df_dict[m].drop(columns=['sample_id'])\n",
    "        df.columns = [f'{m}_{i+1}' for i in range(df.shape[1])]\n",
    "        processed_dfs.append(df)\n",
    "        \n",
    "    return pd.concat(processed_dfs, axis=1)\n",
    "\n",
    "print(\"Processing and unifying tables...\")\n",
    "train_full = clean_and_unify_tables(train_raw, ALL_MODALITIES)\n",
    "test_full = clean_and_unify_tables(test_raw, ALL_MODALITIES)\n",
    "\n",
    "print(f\"Train data shape: {train_full.shape}\")\n",
    "print(f\"Test data shape: {test_full.shape}\")\n",
    "\n",
    "# Data filtering and label encoding (done once before the main loop)\n",
    "train_mask = ~train_stage['stage'].isna()\n",
    "train_data = train_full[train_mask]\n",
    "train_labels_filtered = train_stage['stage'][train_mask]\n",
    "\n",
    "test_mask = ~test_stage['stage'].isna()\n",
    "test_data_full = test_full[test_mask].reset_index(drop=True)\n",
    "test_labels_filtered = test_stage['stage'][test_mask].reset_index(drop=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_labels = le.fit_transform(train_labels_filtered)\n",
    "test_labels = le.transform(test_labels_filtered)\n",
    "\n",
    "# This section for loading generated data is kept as is from your original code\n",
    "generated_file_key = ABLATED_MODALITIES\n",
    "if generated_file_key not in GENERATED_DATA_MAPPING_coh:\n",
    "    raise ValueError(f\"No generated data file specified for the modality combination: {generated_file_key}\")\n",
    "\n",
    "generated_file_name_coh = GENERATED_DATA_MAPPING_coh[generated_file_key]\n",
    "generated_file_name_multi = GENERATED_DATA_MAPPING_multi[generated_file_key]\n",
    "\n",
    "try:\n",
    "    gen_data_long_coh = {mod: pd.read_csv(generated_file_name_coh, sep=',') for mod in ABLATED_MODALITIES}\n",
    "    gen_data_long_multi = {mod: pd.read_csv(generated_file_name_multi, sep=',') for mod in ABLATED_MODALITIES}\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: A generated data file was not found. Please check paths.\")\n",
    "    exit()\n",
    "\n",
    "# =============================================================================\n",
    "# 3. FULL EXPERIMENT LOOP\n",
    "# =============================================================================\n",
    "# MODIFICATION: Create master lists to store results from all runs\n",
    "all_runs_gen_coh = []\n",
    "all_runs_gen_multi = []\n",
    "all_runs_random = []\n",
    "\n",
    "for run in range(N_EXPERIMENT_REPEATS):\n",
    "    print(f\"\\n{'='*20} STARTING EXPERIMENT RUN {run + 1}/{N_EXPERIMENT_REPEATS} {'='*20}\")\n",
    "    \n",
    "    # --- 3a. Model Training (inside the loop) ---\n",
    "    # MODIFICATION: A new model is trained in each run with a different random_state\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42 + run, oob_score=True)\n",
    "    print(f\"Run {run+1}: Training Random Forest model with random_state={42+run}...\")\n",
    "    rf.fit(train_data.values, train_labels)\n",
    "\n",
    "    # --- 3b. Progressive Ablation Analysis (inside the loop) ---\n",
    "    print(f\"Run {run+1}: Calculating progressive ablation scores...\")\n",
    "    \n",
    "    # Use a clean copy of the test data for each run\n",
    "    test_data = test_data_full.copy()\n",
    "    ablated_cols = [c for c in test_data.columns if c.split('_')[0] in ABLATED_MODALITIES]\n",
    "    \n",
    "    # The variance of predictions now depends on the specific model trained in this run.\n",
    "    # Therefore, this calculation must be inside the loop.\n",
    "    print(f\"Run {run+1}: Calculating selective ablation variances...\")\n",
    "    \n",
    "    # The logic for reshaping generated data and getting candidates is kept from your code\n",
    "    n_test_samples = len(test_full)\n",
    "    generated_candidates_coh = {mod: [] for mod in ABLATED_MODALITIES}\n",
    "    generated_candidates_multi = {mod: [] for mod in ABLATED_MODALITIES}\n",
    "    for mod in ABLATED_MODALITIES:\n",
    "        for i in range(n_test_samples):\n",
    "            gather_indices = np.arange(K_NEIGHBORS) * n_test_samples + i\n",
    "            generated_candidates_coh[mod].append(gen_data_long_coh[mod].iloc[gather_indices])\n",
    "            generated_candidates_multi[mod].append(gen_data_long_multi[mod].iloc[gather_indices])\n",
    "    \n",
    "    original_indices = test_mask[test_mask].index\n",
    "    filtered_gen_candidates_coh = {mod: [generated_candidates_coh[mod][i] for i in original_indices] for mod in ABLATED_MODALITIES}\n",
    "    filtered_gen_candidates_multi = {mod: [generated_candidates_multi[mod][i] for i in original_indices] for mod in ABLATED_MODALITIES}\n",
    "    \n",
    "    # Re-calculate prediction variances for the current model\n",
    "    prediction_variances_gen_coh, prediction_variances_gen_multi = [], []\n",
    "    for i in range(len(test_data)):\n",
    "        original_sample = test_data.iloc[[i]]\n",
    "        ablated_sample = original_sample.copy()\n",
    "        ablated_sample[ablated_cols] = np.nan\n",
    "        ablated_prediction = rf.predict(ablated_sample.values)[0]\n",
    "        \n",
    "        prediction_input_coh = pd.concat([original_sample] * K_NEIGHBORS, ignore_index=True)\n",
    "        prediction_input_multi = pd.concat([original_sample] * K_NEIGHBORS, ignore_index=True)\n",
    "        for mod in ABLATED_MODALITIES:\n",
    "            mod_cols = [c for c in test_data.columns if c.startswith(f'{mod}_')]\n",
    "            prediction_input_coh[mod_cols] = filtered_gen_candidates_coh[mod][i].values\n",
    "            prediction_input_multi[mod_cols] = filtered_gen_candidates_multi[mod][i].values\n",
    "            \n",
    "        generated_predictions_coh = rf.predict(prediction_input_coh.values)\n",
    "        generated_predictions_multi = rf.predict(prediction_input_multi.values)\n",
    "        prediction_variances_gen_coh.append(np.mean((generated_predictions_coh != ablated_prediction)))\n",
    "        prediction_variances_gen_multi.append(np.mean((generated_predictions_multi != ablated_prediction)))\n",
    "        \n",
    "    variance_df_gen_coh = pd.DataFrame({'variance': prediction_variances_gen_coh, 'original_index': test_data.index}).sort_values(by='variance', ascending=True)\n",
    "    variance_df_gen_multi = pd.DataFrame({'variance': prediction_variances_gen_multi, 'original_index': test_data.index}).sort_values(by='variance', ascending=True)\n",
    "\n",
    "    # Calculate F1 scores for all methods for the current model\n",
    "    gen_selective_f1_scores_coh, gen_selective_f1_scores_multi, random_ablation_f1_scores = [], [], []\n",
    "\n",
    "    for ratio in ABLATION_STEPS:\n",
    "        # Selective Ablation (Coherent)\n",
    "        data_for_pred_coh = test_data.copy()\n",
    "        n_to_ablate_coh = int(len(data_for_pred_coh) * ratio)\n",
    "        ablation_indices_coh = variance_df_gen_coh.head(n_to_ablate_coh)['original_index'].values\n",
    "        if len(ablation_indices_coh) > 0:\n",
    "            data_for_pred_coh.loc[ablation_indices_coh, ablated_cols] = np.nan\n",
    "        preds_coh = rf.predict(data_for_pred_coh.values)\n",
    "        gen_selective_f1_scores_coh.append(f1_score(test_labels, preds_coh, average='weighted', zero_division=0))\n",
    "\n",
    "        # Selective Ablation (Multi)\n",
    "        data_for_pred_multi = test_data.copy()\n",
    "        n_to_ablate_multi = int(len(data_for_pred_multi) * ratio)\n",
    "        ablation_indices_multi = variance_df_gen_multi.head(n_to_ablate_multi)['original_index'].values\n",
    "        if len(ablation_indices_multi) > 0:\n",
    "            data_for_pred_multi.loc[ablation_indices_multi, ablated_cols] = np.nan\n",
    "        preds_multi = rf.predict(data_for_pred_multi.values)\n",
    "        gen_selective_f1_scores_multi.append(f1_score(test_labels, preds_multi, average='weighted', zero_division=0))\n",
    "\n",
    "        # Random Ablation\n",
    "        iter_scores = []\n",
    "        for _ in range(N_ITERATIONS):\n",
    "            data_for_pred_rand = test_data.copy()\n",
    "            n_to_ablate_rand = int(len(data_for_pred_rand) * ratio)\n",
    "            ablation_indices_rand = np.random.choice(data_for_pred_rand.index, size=n_to_ablate_rand, replace=False)\n",
    "            if len(ablation_indices_rand) > 0:\n",
    "                data_for_pred_rand.loc[ablation_indices_rand, ablated_cols] = np.nan\n",
    "            preds_rand = rf.predict(data_for_pred_rand.values)\n",
    "            iter_scores.append(f1_score(test_labels, preds_rand, average='weighted', zero_division=0))\n",
    "        random_ablation_f1_scores.append(np.mean(iter_scores))\n",
    "\n",
    "    # --- Store the results of the current run ---\n",
    "    all_runs_gen_coh.append(gen_selective_f1_scores_coh)\n",
    "    all_runs_gen_multi.append(gen_selective_f1_scores_multi)\n",
    "    all_runs_random.append(random_ablation_f1_scores)\n",
    "\n",
    "print(f\"\\n{'='*20} ALL EXPERIMENT RUNS COMPLETED {'='*20}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. AGGREGATE RESULTS AND CALCULATE STATISTICS\n",
    "# =============================================================================\n",
    "print(\"\\nAggregating results and calculating statistics...\")\n",
    "\n",
    "# Calculate mean and standard deviation across the experiment runs (axis=0)\n",
    "mean_gen_coh = np.mean(all_runs_gen_coh, axis=0)\n",
    "std_gen_coh = np.std(all_runs_gen_coh, axis=0)\n",
    "\n",
    "mean_gen_multi = np.mean(all_runs_gen_multi, axis=0)\n",
    "std_gen_multi = np.std(all_runs_gen_multi, axis=0)\n",
    "\n",
    "mean_random = np.mean(all_runs_random, axis=0)\n",
    "std_random = np.std(all_runs_random, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2820aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "def plot_prioritization_impact_polished(\n",
    "    ablation_steps: np.ndarray,\n",
    "    mean_random: np.ndarray,\n",
    "    std_random: np.ndarray,\n",
    "    mean_gen_coh: np.ndarray,\n",
    "    std_gen_coh: np.ndarray,\n",
    "    mean_gen_multi: np.ndarray,\n",
    "    std_gen_multi: np.ndarray,\n",
    "    ablated_modalities: List[str],\n",
    "    color_map: Optional[Dict[str, str]] = None,\n",
    "    legend_labels: Optional[Dict[str, str]] = None,\n",
    "    figsize: Tuple[float, float] = (14, 8),\n",
    "    title: Optional[str] = None,\n",
    "    xlabel: str = 'Ratio of Samples with Observed Modalities',\n",
    "    ylabel: str = 'Stage Prediction F1-Score',\n",
    "    savepath: Optional[str] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a polished line plot to show the impact of observing modalities.\n",
    "\n",
    "    This function is adapted from a bar chart plotting style to a line plot,\n",
    "    maintaining a high-quality, publication-ready aesthetic. It visualizes\n",
    "    the performance of different prioritization strategies as more modalities\n",
    "    are observed.\n",
    "\n",
    "    Args:\n",
    "        ablation_steps: Steps of ablation (e.g., from 0.0 to 1.0).\n",
    "        mean_random: Mean performance for random prioritization.\n",
    "        std_random: Standard deviation for random prioritization.\n",
    "        mean_gen_coh: Mean performance for informed (coherent) prioritization.\n",
    "        std_gen_coh: Standard deviation for informed (coherent) prioritization.\n",
    "        mean_gen_multi: Mean performance for informed (multi) prioritization.\n",
    "        std_gen_multi: Standard deviation for informed (multi) prioritization.\n",
    "        ablated_modalities: List of names of the modalities being ablated.\n",
    "        color_map: Optional dictionary to override default colors.\n",
    "        legend_labels: Optional dictionary to override default legend labels.\n",
    "        figsize: The size of the figure.\n",
    "        title: The main title of the plot.\n",
    "        xlabel: The label for the x-axis.\n",
    "        ylabel: The label for the y-axis.\n",
    "        savepath: Optional path to save the figure.\n",
    "    \"\"\"\n",
    "    # --- 1. AESTHETIC DEFAULTS & SETUP ---\n",
    "    if color_map is None:\n",
    "        color_map = {\n",
    "            'random': '#9c2409',        # Muted Red\n",
    "            'coherent': '#56b4e9',      # Sky Blue\n",
    "            'multi': '#0072b2',         # Deeper Blue\n",
    "        }\n",
    "\n",
    "    if legend_labels is None:\n",
    "        legend_labels = {\n",
    "            'random': 'Random Prioritization',\n",
    "            'coherent': 'Informed Prioritization (Coherent)',\n",
    "            'multi': 'Informed Prioritization (Multi)'\n",
    "        }\n",
    "\n",
    "    if title is None:\n",
    "        title = f\"Impact of Observing {', '.join(ablated_modalities).upper()} - Random Prioritization vs. Counterfactual Inference\"\n",
    "\n",
    "    # --- 2. DATA PREPARATION ---\n",
    "    # The x-axis is the ratio of observed data, which is 1 minus the ablation ratio\n",
    "    inverted_steps = 1 - ablation_steps\n",
    "\n",
    "    # --- 3. PLOTTING ---\n",
    "    plt.style.use('seaborn-v0_8-white')\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Plot Random Prioritization\n",
    "    ax.plot(inverted_steps, mean_random, marker='o', linestyle='-', linewidth=2,\n",
    "            label=legend_labels['random'], color=color_map['random'], zorder=10)\n",
    "    ax.fill_between(inverted_steps, mean_random - std_random, mean_random + std_random,\n",
    "                    alpha=0.15, color=color_map['random'], zorder=5)\n",
    "\n",
    "    # Plot Informed Prioritization (Coherent)\n",
    "    ax.plot(inverted_steps, mean_gen_coh, marker='s', linestyle='--', linewidth=2,\n",
    "            label=legend_labels['coherent'], color=color_map['coherent'], zorder=10)\n",
    "    ax.fill_between(inverted_steps, mean_gen_coh - std_gen_coh, mean_gen_coh + std_gen_coh,\n",
    "                    alpha=0.15, color=color_map['coherent'], zorder=5)\n",
    "\n",
    "    # Plot Informed Prioritization (Multi)\n",
    "    ax.plot(inverted_steps, mean_gen_multi, marker='^', linestyle='--', linewidth=2,\n",
    "            label=legend_labels['multi'], color=color_map['multi'], zorder=10)\n",
    "    ax.fill_between(inverted_steps, mean_gen_multi - std_gen_multi, mean_gen_multi + std_gen_multi,\n",
    "                    alpha=0.15, color=color_map['multi'], zorder=5)\n",
    "\n",
    "\n",
    "    # --- 4. VISUAL REFINEMENTS ---\n",
    "\n",
    "    # \"Classy\" horizontal grid\n",
    "    ax.yaxis.grid(True, linewidth=0.7, color=\"#CDCCCC\", zorder=0)\n",
    "    ax.xaxis.grid(True, linewidth=0.7, color=\"#CDCCCC\", zorder=0)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    # Less prominent axes and ticks\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_color('#B0B0B0')\n",
    "    ax.tick_params(axis='x', colors='#505050', length=0)\n",
    "    ax.tick_params(axis='y', colors='#505050', length=0)\n",
    "    ax.xaxis.label.set_color('#303030')\n",
    "    ax.yaxis.label.set_color('#303030')\n",
    "\n",
    "    # X-axis ticks and limits (inverted)\n",
    "    new_ticks = np.arange(0, 1.1, 0.1)\n",
    "    ax.set_xticks(new_ticks)\n",
    "    ax.set_xticklabels([f\"{x:.1f}\" for x in new_ticks], rotation=0)\n",
    "    ax.set_xlim(1.02, -0.02) # Invert the axis from 100% down to 0%\n",
    "\n",
    "    # Y-axis limits adjusted to data range for readability\n",
    "    all_mins = np.concatenate([\n",
    "        mean_random - std_random,\n",
    "        mean_gen_coh - std_gen_coh,\n",
    "        mean_gen_multi - std_gen_multi\n",
    "    ])\n",
    "    all_maxs = np.concatenate([\n",
    "        mean_random + std_random,\n",
    "        mean_gen_coh + std_gen_coh,\n",
    "        mean_gen_multi + std_gen_multi\n",
    "    ])\n",
    "    plot_min, plot_max = all_mins.min(), all_maxs.max()\n",
    "    padding = (plot_max - plot_min) * 0.05\n",
    "    ax.set_ylim(plot_min - padding, plot_max + padding)\n",
    "\n",
    "    # Final labels and title\n",
    "    ax.set_xlabel(xlabel, fontsize=12, labelpad=15)\n",
    "    ax.set_ylabel(ylabel, fontsize=12, labelpad=15)\n",
    "    ax.set_title(title, fontsize=16, pad=20, weight='bold')\n",
    "\n",
    "    # Legend on the right\n",
    "    ax.legend(\n",
    "        title='Prioritization Strategy',\n",
    "        loc='center left',\n",
    "        bbox_to_anchor=(1.02, 0.5),\n",
    "        frameon=False,\n",
    "        fontsize=11,\n",
    "        title_fontsize=12\n",
    "    )\n",
    "    \n",
    "    # --- 5. FINAL LAYOUT ADJUSTMENTS ---\n",
    "    fig.subplots_adjust(\n",
    "        left=0.07,\n",
    "        right=0.82, # Make space for the legend\n",
    "        bottom=0.1,\n",
    "        top=0.9\n",
    "    )\n",
    "\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Call the polished plotting function\n",
    "plot_prioritization_impact_polished(\n",
    "    ablation_steps=ABLATION_STEPS,\n",
    "    mean_random=mean_random,\n",
    "    std_random=std_random,\n",
    "    mean_gen_coh=mean_gen_coh,\n",
    "    std_gen_coh=std_gen_coh,\n",
    "    mean_gen_multi=mean_gen_multi,\n",
    "    std_gen_multi=std_gen_multi,\n",
    "    ablated_modalities=ABLATED_MODALITIES,\n",
    "    savepath=f\"../../results/downstream/task_07_counterfactual/{'_'.join(ABLATED_MODALITIES)}_prioritization_impact_plot.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a268fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa533b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9199d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c8483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import json\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CONFIGURATION\n",
    "# =============================================================================\n",
    "# Define all modalities available in the dataset\n",
    "ALL_MODALITIES = ['cna', 'rna', 'rppa', 'wsi']\n",
    "\n",
    "# --- Experiment Parameters ---\n",
    "# MODIFICATION: Number of full experiment repeats to calculate standard deviation\n",
    "N_EXPERIMENT_REPEATS =  10\n",
    "# Number of iterations for the random ablation baseline (within each experiment)\n",
    "N_ITERATIONS = 30\n",
    "# Steps for the progressive ablation plot (from 0% to 100% of samples ablated)\n",
    "ABLATION_STEPS = np.arange(0, 1.05, 0.05)\n",
    "# Number of neighbors for the k-NN baseline\n",
    "K_NEIGHBORS = 10\n",
    "\n",
    "# --- File Paths ---\n",
    "gen_path = '../../results/32/'\n",
    "train_path = '../../datasets_TCGA/07_normalized/32/'\n",
    "test_path = '../../datasets_TCGA/07_normalized/32/'\n",
    "labels_path = '../../datasets_TCGA/downstream_labels/'\n",
    "\n",
    "# Mapping from the ablated modalities tuple to the corresponding generated data file.\n",
    "GENERATED_DATA_MAPPING_coh = {\n",
    "    ('rna',): f'{gen_path}rnaseq_from_coherent/test/generated_samples_from_cna_rppa_wsi_best_mse.csv',\n",
    "    ('wsi',): f'{gen_path}wsi_from_coherent/test/generated_samples_from_cna_rnaseq_rppa_best_mse.csv',\n",
    "}\n",
    "\n",
    "GENERATED_DATA_MAPPING_multi = {\n",
    "    ('rna',): f'{gen_path}rnaseq_from_multi/test/generated_samples_from_cna_rppa_wsi_best_mse.csv',\n",
    "    ('wsi',): f'{gen_path}wsi_from_multi/test/generated_samples_from_cna_rnaseq_rppa_best_mse.csv',\n",
    "}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "def clean_and_unify_tables(df_dict, modalities):\n",
    "    \"\"\"\n",
    "    Unifies multiple modality-specific dataframes into a single dataframe.\n",
    "    \"\"\"\n",
    "    sample_ids = df_dict[modalities[0]]['sample_id'].values\n",
    "    for m in modalities:\n",
    "        assert np.all(df_dict[m]['sample_id'].values == sample_ids), f\"Sample IDs for {m} do not match.\"\n",
    "\n",
    "    processed_dfs = []\n",
    "    for m in modalities:\n",
    "        df = df_dict[m].drop(columns=['sample_id'])\n",
    "        df.columns = [f'{m}_{i+1}' for i in range(df.shape[1])]\n",
    "        processed_dfs.append(df)\n",
    "        \n",
    "    return pd.concat(processed_dfs, axis=1)\n",
    "\n",
    "# =============================================================================\n",
    "# 3. CORE EXPERIMENT FUNCTION\n",
    "# =============================================================================\n",
    "def run_ablation_experiment(ablated_modalities: Tuple[str, ...]):\n",
    "    \"\"\"\n",
    "    Runs the full progressive ablation experiment for a given set of ablated modalities.\n",
    "    \n",
    "    Args:\n",
    "        ablated_modalities: A tuple containing the names of modalities to treat as missing.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the mean and standard deviation of F1 scores for each method.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*30}\\nRUNNING EXPERIMENT FOR ABLATED MODALITY: {str(ablated_modalities).upper()}\\n{'='*30}\")\n",
    "\n",
    "    # --- 3a. Data Loading and Preparation ---\n",
    "    print(\"Loading datasets...\")\n",
    "    train_raw = {\n",
    "        'cna': pd.read_csv(f'{train_path}cna_train.csv', sep=','),\n",
    "        'rna': pd.read_csv(f'{train_path}rnaseq_train.csv', sep=','),\n",
    "        'rppa': pd.read_csv(f'{train_path}rppa_train.csv', sep=','),\n",
    "        'wsi': pd.read_csv(f'{train_path}wsi_train.csv', sep=','),\n",
    "    }\n",
    "\n",
    "    test_raw = {\n",
    "        'cna': pd.read_csv(f'{test_path}cna_test.csv', sep=','),\n",
    "        'rna': pd.read_csv(f'{test_path}rnaseq_test.csv', sep=','),\n",
    "        'rppa': pd.read_csv(f'{test_path}rppa_test.csv', sep=','),\n",
    "        'wsi': pd.read_csv(f'{test_path}wsi_test.csv', sep=','),\n",
    "    }\n",
    "\n",
    "    train_stage = pd.read_csv(f'{labels_path}train_stage.csv')\n",
    "    test_stage = pd.read_csv(f'{labels_path}test_stage.csv')\n",
    "\n",
    "    print(\"Processing and unifying tables...\")\n",
    "    train_full = clean_and_unify_tables(train_raw, ALL_MODALITIES)\n",
    "    test_full = clean_and_unify_tables(test_raw, ALL_MODALITIES)\n",
    "\n",
    "    train_mask = ~train_stage['stage'].isna()\n",
    "    train_data = train_full[train_mask]\n",
    "    train_labels_filtered = train_stage['stage'][train_mask]\n",
    "\n",
    "    test_mask = ~test_stage['stage'].isna()\n",
    "    test_data_full = test_full[test_mask].reset_index(drop=True)\n",
    "    test_labels_filtered = test_stage['stage'][test_mask].reset_index(drop=True)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    train_labels = le.fit_transform(train_labels_filtered)\n",
    "    test_labels = le.transform(test_labels_filtered)\n",
    "\n",
    "    # Load generated data\n",
    "    generated_file_key = ablated_modalities\n",
    "    if generated_file_key not in GENERATED_DATA_MAPPING_coh:\n",
    "        raise ValueError(f\"No generated data file specified for the modality combination: {generated_file_key}\")\n",
    "\n",
    "    try:\n",
    "        gen_data_long_coh = {mod: pd.read_csv(GENERATED_DATA_MAPPING_coh[generated_file_key], sep=',') for mod in ablated_modalities}\n",
    "        gen_data_long_multi = {mod: pd.read_csv(GENERATED_DATA_MAPPING_multi[generated_file_key], sep=',') for mod in ablated_modalities}\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: A generated data file was not found: {e}. Please check paths.\")\n",
    "        return None\n",
    "\n",
    "    # --- 3b. Full Experiment Loop ---\n",
    "    all_runs_gen_coh, all_runs_gen_multi, all_runs_random = [], [], []\n",
    "\n",
    "    for run in range(N_EXPERIMENT_REPEATS):\n",
    "        print(f\"\\n--- Starting Experiment Run {run + 1}/{N_EXPERIMENT_REPEATS} for {str(ablated_modalities).upper()} ---\")\n",
    "        \n",
    "        # A new model is trained in each run with a different random_state\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=42 + run, oob_score=True, n_jobs=-1)\n",
    "        rf.fit(train_data.values, train_labels)\n",
    "\n",
    "        # Progressive Ablation Analysis\n",
    "        test_data = test_data_full.copy()\n",
    "        ablated_cols = [c for c in test_data.columns if c.split('_')[0] in ablated_modalities]\n",
    "        \n",
    "        # Prepare generated candidates\n",
    "        n_test_samples = len(test_full)\n",
    "        generated_candidates_coh = {mod: [df.iloc[np.arange(K_NEIGHBORS) * n_test_samples + i] for i in range(n_test_samples)] for mod, df in gen_data_long_coh.items()}\n",
    "        generated_candidates_multi = {mod: [df.iloc[np.arange(K_NEIGHBORS) * n_test_samples + i] for i in range(n_test_samples)] for mod, df in gen_data_long_multi.items()}\n",
    "        \n",
    "        original_indices = test_mask[test_mask].index\n",
    "        filtered_gen_candidates_coh = {mod: [generated_candidates_coh[mod][i] for i in original_indices] for mod in ablated_modalities}\n",
    "        filtered_gen_candidates_multi = {mod: [generated_candidates_multi[mod][i] for i in original_indices] for mod in ablated_modalities}\n",
    "        \n",
    "        # Calculate prediction variances\n",
    "        prediction_variances_gen_coh, prediction_variances_gen_multi = [], []\n",
    "        for i in range(len(test_data)):\n",
    "            original_sample = test_data.iloc[[i]]\n",
    "            ablated_sample = original_sample.copy()\n",
    "            ablated_sample[ablated_cols] = 0 # Use 0 for nan to avoid sklearn warning\n",
    "            ablated_prediction = rf.predict(ablated_sample.values)[0]\n",
    "            \n",
    "            prediction_input_coh = pd.concat([original_sample] * K_NEIGHBORS, ignore_index=True)\n",
    "            prediction_input_multi = pd.concat([original_sample] * K_NEIGHBORS, ignore_index=True)\n",
    "            for mod in ablated_modalities:\n",
    "                mod_cols = [c for c in test_data.columns if c.startswith(f'{mod}_')]\n",
    "                prediction_input_coh[mod_cols] = filtered_gen_candidates_coh[mod][i].values\n",
    "                prediction_input_multi[mod_cols] = filtered_gen_candidates_multi[mod][i].values\n",
    "            \n",
    "            generated_predictions_coh = rf.predict(prediction_input_coh.values)\n",
    "            generated_predictions_multi = rf.predict(prediction_input_multi.values)\n",
    "            prediction_variances_gen_coh.append(np.mean((generated_predictions_coh != ablated_prediction)))\n",
    "            prediction_variances_gen_multi.append(np.mean((generated_predictions_multi != ablated_prediction)))\n",
    "\n",
    "        variance_df_gen_coh = pd.DataFrame({'variance': prediction_variances_gen_coh, 'original_index': test_data.index}).sort_values(by='variance', ascending=True)\n",
    "        variance_df_gen_multi = pd.DataFrame({'variance': prediction_variances_gen_multi, 'original_index': test_data.index}).sort_values(by='variance', ascending=True)\n",
    "\n",
    "        # Calculate F1 scores for all methods\n",
    "        gen_selective_f1_scores_coh, gen_selective_f1_scores_multi, random_ablation_f1_scores = [], [], []\n",
    "\n",
    "        for ratio in ABLATION_STEPS:\n",
    "            # Selective Ablation (Coherent)\n",
    "            data_for_pred_coh = test_data.copy()\n",
    "            n_to_ablate = int(len(data_for_pred_coh) * ratio)\n",
    "            ablation_indices = variance_df_gen_coh.head(n_to_ablate)['original_index'].values\n",
    "            if len(ablation_indices) > 0:\n",
    "                data_for_pred_coh.loc[ablation_indices, ablated_cols] = 0\n",
    "            preds_coh = rf.predict(data_for_pred_coh.values)\n",
    "            gen_selective_f1_scores_coh.append(f1_score(test_labels, preds_coh, average='weighted', zero_division=0))\n",
    "\n",
    "            # Selective Ablation (Multi)\n",
    "            data_for_pred_multi = test_data.copy()\n",
    "            ablation_indices = variance_df_gen_multi.head(n_to_ablate)['original_index'].values\n",
    "            if len(ablation_indices) > 0:\n",
    "                data_for_pred_multi.loc[ablation_indices, ablated_cols] = 0\n",
    "            preds_multi = rf.predict(data_for_pred_multi.values)\n",
    "            gen_selective_f1_scores_multi.append(f1_score(test_labels, preds_multi, average='weighted', zero_division=0))\n",
    "\n",
    "            # Random Ablation\n",
    "            iter_scores = []\n",
    "            for _ in range(N_ITERATIONS):\n",
    "                data_for_pred_rand = test_data.copy()\n",
    "                ablation_indices = np.random.choice(data_for_pred_rand.index, size=n_to_ablate, replace=False)\n",
    "                if len(ablation_indices) > 0:\n",
    "                    data_for_pred_rand.loc[ablation_indices, ablated_cols] = 0\n",
    "                preds_rand = rf.predict(data_for_pred_rand.values)\n",
    "                iter_scores.append(f1_score(test_labels, preds_rand, average='weighted', zero_division=0))\n",
    "            random_ablation_f1_scores.append(np.mean(iter_scores))\n",
    "\n",
    "        all_runs_gen_coh.append(gen_selective_f1_scores_coh)\n",
    "        all_runs_gen_multi.append(gen_selective_f1_scores_multi)\n",
    "        all_runs_random.append(random_ablation_f1_scores)\n",
    "\n",
    "    # --- 3c. Aggregate Results ---\n",
    "    print(\"\\nAggregating results...\")\n",
    "    results = {\n",
    "        'mean_random': np.mean(all_runs_random, axis=0),\n",
    "        'std_random': np.std(all_runs_random, axis=0),\n",
    "        'mean_gen_coh': np.mean(all_runs_gen_coh, axis=0),\n",
    "        'std_gen_coh': np.std(all_runs_gen_coh, axis=0),\n",
    "        'mean_gen_multi': np.mean(all_runs_gen_multi, axis=0),\n",
    "        'std_gen_multi': np.std(all_runs_gen_multi, axis=0)\n",
    "    }\n",
    "    return results\n",
    "\n",
    "# =============================================================================\n",
    "# 4. PLOTTING FUNCTION\n",
    "# =============================================================================\n",
    "def plot_multi_panel_prioritization(\n",
    "    results_dict: Dict[str, Dict],\n",
    "    ablation_steps: np.ndarray,\n",
    "    figsize: Tuple[float, float] = (16, 7),\n",
    "    savepath: Optional[str] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a polished multi-panel line plot to compare prioritization impact across different modalities.\n",
    "    \n",
    "    Args:\n",
    "        results_dict: A dictionary where keys are modality names and values are the results from run_ablation_experiment.\n",
    "        ablation_steps: The steps of ablation used in the experiment.\n",
    "        figsize: The overall size of the figure.\n",
    "        savepath: Optional path to save the figure.\n",
    "    \"\"\"\n",
    "    # --- 1. Setup ---\n",
    "    modalities_to_plot = list(results_dict.keys())\n",
    "    n_panels = len(modalities_to_plot)\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, axes = plt.subplots(1, n_panels, figsize=figsize, sharey=True)\n",
    "    if n_panels == 1: # Ensure axes is always a list\n",
    "        axes = [axes]\n",
    "\n",
    "    color_map = {'random': '#9c2409', 'coherent': '#56b4e9', 'multi': '#0072b2'}\n",
    "\n",
    "    legend_labels = {'random': 'Random', 'coherent': 'Informed (Coherent)', 'multi': 'Informed (Multi)'}\n",
    "    #inverted_steps = 1 - ablation_steps\n",
    "    inverted_steps = ablation_steps\n",
    "\n",
    "    # --- 2. Plotting Loop ---\n",
    "    for i, modality_key in enumerate(modalities_to_plot):\n",
    "        ax = axes[i]\n",
    "        results = results_dict[modality_key]\n",
    "        \n",
    "        # Plot each line\n",
    "        for method in ['random', 'coherent', 'multi']:\n",
    "            # Correctly access the keys in the results dictionary\n",
    "            if method == 'random':\n",
    "                mean = results['mean_random']\n",
    "                std = results['std_random']\n",
    "            elif method == 'coherent':\n",
    "                mean = results['mean_gen_coh']\n",
    "                std = results['std_gen_coh']\n",
    "            else: # method == 'multi'\n",
    "                mean = results['mean_gen_multi']\n",
    "                std = results['std_gen_multi']\n",
    "            \n",
    "            ax.plot(inverted_steps, mean, marker='o', linestyle='-', markersize=5,\n",
    "                    label=legend_labels[method], color=color_map[method])\n",
    "            ax.fill_between(inverted_steps, mean - std, mean + std, alpha=0.15, color=color_map[method])\n",
    "\n",
    "        # --- 3. Panel-specific Aesthetics ---\n",
    "        ax.set_title(f\"Impact of Observing {modality_key.upper()}\", fontsize=14, weight='bold')\n",
    "        ax.set_xlabel('Ratio of Samples with Observed Modality', fontsize=12)\n",
    "        #ax.set_xlim(1.02, -0.02) # Invert axis\n",
    "        # \"Classy\" horizontal grid\n",
    "        ax.yaxis.grid(True, linewidth=0.7, color=\"#CDCCCC\", zorder=0)\n",
    "        ax.xaxis.grid(True, linewidth=0.7, color=\"#CDCCCC\", zorder=0)\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        # Less prominent axes and ticks\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.spines['bottom'].set_color('#B0B0B0')\n",
    "        ax.tick_params(axis='x', colors='#505050', length=0)\n",
    "        ax.tick_params(axis='y', colors='#505050', length=0)\n",
    "        ax.xaxis.label.set_color('#303030')\n",
    "        ax.yaxis.label.set_color('#303030')\n",
    "\n",
    "        ax.set_xlim(-0.02, 1.02) # Keep axis from 0 to 1\n",
    "        ax.set_xticks(np.arange(0, 1.1, 0.2))\n",
    "        ax.tick_params(labelsize=10)\n",
    "\n",
    "    # --- 4. Global Aesthetics & Layout ---\n",
    "    axes[0].set_ylabel('Stage Prediction F1-Score', fontsize=12)\n",
    "    \n",
    "    # Create a single legend for the whole figure\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 0.02), ncol=3, fontsize=11, frameon=False, title='Prioritization Strategy')\n",
    "    \n",
    "    fig.suptitle(\"Random Prioritization vs. Counterfactual Inference\", fontsize=18, weight='bold', y=1.0)\n",
    "    fig.tight_layout(rect=[0, 0.05, 1, 0.96]) # Adjust layout to make space for suptitle and legend\n",
    "\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5. MAIN EXECUTION\n",
    "# =============================================================================\n",
    "if __name__ == '__main__':\n",
    "    # Define the experiments to run\n",
    "    modalities_to_test = [('rna',), ('wsi',)]\n",
    "    all_results = {}\n",
    "\n",
    "    for modality_tuple in modalities_to_test:\n",
    "        # Generate a simple key for the results dictionary\n",
    "        key = '_'.join(modality_tuple) \n",
    "        result = run_ablation_experiment(modality_tuple)\n",
    "        if result:\n",
    "            all_results[key] = result\n",
    "    \n",
    "    if all_results:\n",
    "        plot_multi_panel_prioritization(\n",
    "            results_dict=all_results,\n",
    "            ablation_steps=ABLATION_STEPS,\n",
    "            savepath=f\"../../results/downstream/task_07_counterfactual/multi_panel_prioritization_impact.png\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"\\nNo experiments were successfully completed. Plotting skipped.\")\n",
    "    \n",
    "    with open(\"../../results/downstream/task_07_counterfactual/rna_wsi_results.json\", \"w\") as f:\n",
    "        json.dump(all_results, f, indent=2, default=lambda x: x.tolist() if hasattr(x, \"tolist\") else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e37756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../../results/downstream/task_07_counterfactual/rna_wsi_results.json\", \"w\") as f:\n",
    "    json.dump(all_results, f, indent=2, default=lambda x: x.tolist() if hasattr(x, \"tolist\") else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf8467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple, Optional\n",
    "\n",
    "\n",
    "\n",
    "def plot_multi_panel_prioritization(\n",
    "    results_dict: Dict[str, Dict],\n",
    "    ablation_steps: np.ndarray,\n",
    "    figsize: Tuple[float, float] = (16, 7),\n",
    "    savepath: Optional[str] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a polished multi-panel line plot to compare prioritization impact across different modalities.\n",
    "    Uses separate y-axes for each subplot.\n",
    "    \"\"\"\n",
    "    modalities_to_plot = list(results_dict.keys())\n",
    "    n_panels = len(modalities_to_plot)\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, axes = plt.subplots(1, n_panels, figsize=figsize, sharey=False)\n",
    "    if n_panels == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    color_map = {'random': '#9c2409', 'coherent': '#56b4e9', 'multi': '#0072b2'}\n",
    "    legend_labels = {'random': 'Random', 'coherent': 'Informed (Coherent Denoising)', 'multi': 'Informed (Multi-condition)'}\n",
    "    inverted_steps = 1- ablation_steps\n",
    "\n",
    "    for i, modality_key in enumerate(modalities_to_plot):\n",
    "        ax = axes[i]\n",
    "        results = results_dict[modality_key]\n",
    "        for method in ['random', 'coherent', 'multi']:\n",
    "            if method == 'random':\n",
    "                mean = np.array(results['mean_random'])\n",
    "                std = np.array(results['std_random'])\n",
    "            elif method == 'coherent':\n",
    "                mean = np.array(results['mean_gen_coh'])\n",
    "                std = np.array(results['std_gen_coh'])\n",
    "            else:\n",
    "                mean = np.array(results['mean_gen_multi'])\n",
    "                std = np.array(results['std_gen_multi'])\n",
    "\n",
    "            ax.plot(inverted_steps, mean, marker='o', linestyle='--', markersize=5,\n",
    "                    label=legend_labels[method], color=color_map[method])\n",
    "            ax.fill_between(inverted_steps, mean - std, mean + std, alpha=0.15, color=color_map[method])\n",
    "\n",
    "        ax.set_title(f\"Impact of Observing {modality_key.upper()}\", fontsize=16, weight='bold')\n",
    "        ax.set_xlabel('Ratio of Samples with Observed Modality', fontsize=14)\n",
    "        ax.yaxis.grid(True, linewidth=0.7, color=\"#CDCCCC\", zorder=0)\n",
    "        ax.xaxis.grid(True, linewidth=0.7, color=\"#CDCCCC\", zorder=0)\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.spines['bottom'].set_color('#B0B0B0')\n",
    "        ax.tick_params(axis='x', colors='#505050', length=0)\n",
    "        ax.tick_params(axis='y', colors='#505050', length=0)\n",
    "        ax.xaxis.label.set_color('#303030')\n",
    "        ax.yaxis.label.set_color('#303030')\n",
    "        ax.set_xlim(-0.02, 1.02)\n",
    "        ax.set_xticks(np.arange(0, 1.1, 0.2))\n",
    "        ax.tick_params(labelsize=10)\n",
    "        ax.set_ylabel('Stage Prediction F1-Score', fontsize=14)\n",
    "\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    legend = fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 0.02), ncol=3, fontsize=12, frameon=False, title='Prioritization Strategy')\n",
    "    if legend.get_title() is not None:\n",
    "        legend.get_title().set_fontsize(14)\n",
    "\n",
    "    fig.suptitle(\"Random Prioritization vs. Counterfactual Inference\", fontsize=18, weight='bold', y=1.0)\n",
    "    fig.tight_layout(rect=[0, 0.05, 1, 0.96], w_pad=5)  # Add horizontal space with w_pad\n",
    "\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# read all_results from the JSON file\n",
    "import json\n",
    "with open(\"../../results/downstream/task_07_counterfactual/rna_wsi_results.json\", \"r\") as f:\n",
    "    all_results = json.load(f)\n",
    "\n",
    "ABLATION_STEPS = np.arange(0, 1.05, 0.05)\n",
    "\n",
    "plot_multi_panel_prioritization(\n",
    "    results_dict=all_results,\n",
    "    ablation_steps=ABLATION_STEPS,\n",
    "    savepath=f\"../../results/downstream/task_07_counterfactual/counterfactual_rna_wsi.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8844e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
