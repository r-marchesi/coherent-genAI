{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cebd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "import json\n",
    "import pathlib\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from lib.read_data import read_data\n",
    "from lib.get_models import get_diffusion_model\n",
    "from lib.diffusion_models import GaussianDiffusion\n",
    "from lib.sampling import coherent_sample, sample\n",
    "from lib.config import modalities_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbbbb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "mode = 'multi'             # 'multi' or 'coherent'\n",
    "test_iterations = 1        # number of generation repeats\n",
    "dim = '32'                 # your chosen dimension\n",
    "\n",
    "\n",
    "results_path = '../../results'    \n",
    "data_dir = '../../datasets_TCGA/07_normalized/'\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1b7428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "print(\"Loading data...\")\n",
    "# Load modality data\n",
    "modalities_map = read_data(\n",
    "    modalities=modalities_list,\n",
    "    splits=['train'],\n",
    "    data_dir=data_dir,\n",
    "    dim=dim,\n",
    "    mask_train_path=f'../../datasets_TCGA/06_masked/{dim}/masks_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac34c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {}\n",
    "diffusion = GaussianDiffusion(num_timesteps=1000).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd1c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in modalities_map.keys():\n",
    "    conds = [m for m in modalities_map.keys() if m != target]\n",
    "    if mode == 'multi':\n",
    "        # load the multi-conditioning model (trained on all other modalities jointly)\n",
    "        ckpt_path = f\"../../results/{dim}/{target}_from_multi/train/best_by_mse.pth\"\n",
    "        ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "        cfg = ckpt['config']\n",
    "        state = ckpt['best_model_mse']\n",
    "        x_dim = modalities_map[target]['train'].shape[1]\n",
    "        cond_dims = [modalities_map[c]['train'].shape[1] for c in conds]\n",
    "        model = get_diffusion_model(\n",
    "            cfg['architecture'], diffusion, SimpleNamespace(**cfg),\n",
    "            x_dim=x_dim, cond_dims=cond_dims\n",
    "        ).to(device)\n",
    "        model.load_state_dict(state)\n",
    "        model.eval()\n",
    "        models_dict[target] = {'models': [model], 'diffusion': diffusion, 'conds': conds}\n",
    "    else:\n",
    "        # coherent: load one single-conditioning model per conditioning modality\n",
    "        models = []\n",
    "        for c in conds:\n",
    "            ckpt_path = f\"../../results/{dim}/{target}_from_{c}/train/best_by_mse.pth\"\n",
    "            ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "            cfg = ckpt['config']\n",
    "            state = ckpt['best_model_mse']\n",
    "            x_dim = modalities_map[target]['train'].shape[1]\n",
    "            cond_dim = modalities_map[c]['train'].shape[1]\n",
    "            mdl = get_diffusion_model(\n",
    "                cfg['architecture'], diffusion, SimpleNamespace(**cfg),\n",
    "                x_dim=x_dim, cond_dims=cond_dim\n",
    "            ).to(device)\n",
    "            mdl.load_state_dict(state)\n",
    "            mdl.eval()\n",
    "            models.append(mdl)\n",
    "        models_dict[target] = {'models': models, 'diffusion': diffusion, 'conds': conds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a159e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict['cna'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dac091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(target, cond_batches, present):\n",
    "    \"\"\"\n",
    "    target: modality name\n",
    "    cond_batches: list of np.ndarray for present modalities, in the order of `present`\n",
    "    present: tuple of present modality names\n",
    "    \"\"\"\n",
    "    entry = models_dict[target]\n",
    "    diff = diffusion\n",
    "    full_conds = entry['conds']  # list of all cond modality names\n",
    "\n",
    "    if mode == 'multi':\n",
    "        # build full cond list in order entry['conds'], zero for missing\n",
    "        cond_ts = []\n",
    "        mask_arr = []\n",
    "        for cm in full_conds:\n",
    "            if cm in present:\n",
    "                # find index in present to grab batch\n",
    "                idx = present.index(cm)\n",
    "                arr = cond_batches[idx]\n",
    "                mask_arr.append(np.ones(arr.shape[0]))\n",
    "            else:\n",
    "                # zero batch\n",
    "                arr = np.zeros((len(cond_batches[0]), modalities_map[cm]['train'].shape[1]), dtype=np.float32)\n",
    "                mask_arr.append(np.zeros(arr.shape[0]))\n",
    "            cond_ts.append(torch.tensor(arr, dtype=torch.float32, device=device))\n",
    "        # mask_tensor shape: (num_conditions, batch_size)\n",
    "        mask_tensor = torch.tensor(np.stack(mask_arr, axis=0), dtype=torch.float32, device=device)\n",
    "        gen = sample(\n",
    "            model=entry['models'][0],\n",
    "            diffusion=diff,\n",
    "            cond=cond_ts,\n",
    "            num_features=modalities_map[target]['train'].shape[1],\n",
    "            mask=mask_tensor,\n",
    "            device=device\n",
    "        )\n",
    "    else:\n",
    "        # coherent: only use available modalities and corresponding models\n",
    "        cond_ts = []\n",
    "        models = []\n",
    "        for mdl, cm in zip(entry['models'], full_conds):\n",
    "            if cm in present:\n",
    "                cond_ts.append(torch.tensor(cond_batches[present.index(cm)], dtype=torch.float32, device=device))\n",
    "                models.append(mdl)\n",
    "        gen = coherent_sample(\n",
    "            models=models,\n",
    "            diffusion=diff,\n",
    "            num_samples=cond_ts[0].shape[0],\n",
    "            num_features=modalities_map[target]['train'].shape[1],\n",
    "            conds=cond_ts,\n",
    "            device=device\n",
    "        )\n",
    "    return gen.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babeb822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify groups: key = (tuple(present), tuple(missing))\n",
    "groups = {}\n",
    "for idx in modalities_map[next(iter(modalities_map))]['train'].index:\n",
    "    mask = {m: modalities_map[m]['mask_train'].loc[idx] for m in modalities_map}\n",
    "    missing = tuple(sorted([m for m, v in mask.items() if v == 0]))\n",
    "    present = tuple(sorted([m for m in modalities_map if m not in missing]))\n",
    "    if not missing or len(present) < 2:\n",
    "        continue\n",
    "    groups.setdefault((present, missing), []).append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffcb04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(groups.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983002a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process one-missing groups in batch\n",
    "imputed = {}\n",
    "for (present, missing), idxs in groups.items():\n",
    "    if len(missing) == 1:\n",
    "        tgt = missing[0]\n",
    "        # collect cond arrays per present modality\n",
    "        cond_batches = [np.vstack([modalities_map[c]['train'].loc[idx].values for idx in idxs]) for c in present]\n",
    "        # generate batch\n",
    "        gen_batch = generate_batch(tgt, cond_batches, present)\n",
    "        # store results\n",
    "        for i, idx in enumerate(idxs):\n",
    "            rec = {c: modalities_map[c]['train'].loc[idx].values for c in present}\n",
    "            rec[tgt] = gen_batch[i]\n",
    "            imputed[idx] = rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0dd121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process two-missing groups in batch, per order\n",
    "for (present, missing), idxs in groups.items():\n",
    "    if len(missing) == 2:\n",
    "        a, b = missing\n",
    "        # collect cond arrays once for batch\n",
    "        cond_batches = {c: np.vstack([modalities_map[c]['train'].loc[idx].values for idx in idxs]) for c in present}\n",
    "        # generate each missing modality independently\n",
    "        gen_a = generate_batch(a, [cond_batches[c] for c in present], present)\n",
    "        gen_b = generate_batch(b, [cond_batches[c] for c in present], present)\n",
    "        # combine into single imputed record per sample\n",
    "        for i, idx in enumerate(idxs):\n",
    "            rec = {c: modalities_map[c]['train'].loc[idx].values for c in present}\n",
    "            rec[a] = gen_a[i]\n",
    "            rec[b] = gen_b[i]\n",
    "            imputed[idx] = rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22f295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append imputed to modalities_map\n",
    "\n",
    "for mod in modalities_map:\n",
    "    orig = modalities_map[mod]['train']\n",
    "    new_data = {idx: rec[mod] for idx, rec in imputed.items()}\n",
    "    if not new_data:\n",
    "        continue\n",
    "    df_new = pd.DataFrame.from_dict(new_data, orient='index', columns=orig.columns)\n",
    "    modalities_map[mod]['train'] = pd.concat([orig, df_new])\n",
    "    # update mask\n",
    "    mask_orig = modalities_map[mod]['mask_train']\n",
    "    mask_new = pd.Series(1, index=df_new.index)\n",
    "    modalities_map[mod]['mask_train'] = pd.concat([mask_orig, mask_new])\n",
    "\n",
    "print(f\"Batched imputation complete: {len(imputed)} records generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
