{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a261c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_rel\n",
    "import sys\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import statsmodels\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    print(\"statsmodels not found. Installing...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"statsmodels\"])\n",
    "    import statsmodels\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "def analyze_vs_ablation(combined_df: pd.DataFrame, metric: str = 'c_index'):\n",
    "    \"\"\"Performs statistical analysis comparing all imputation methods against the ablation baseline.\"\"\"\n",
    "    statistical_results = []\n",
    "    # Exclude non-ablation baselines from this specific analysis\n",
    "    test_conditions = [c for c in combined_df['test_condition'].unique() if c not in ['full_data', 'cancer_label_only']]\n",
    "\n",
    "    for condition in test_conditions:\n",
    "        condition_df = combined_df[combined_df['test_condition'] == condition]\n",
    "        try:\n",
    "            scores_ablation = condition_df[condition_df['test_type'] == 'ablation'][metric].dropna()\n",
    "            imputation_types = [t for t in condition_df['test_type'].unique() if 'imputed' in t]\n",
    "            for imp_type in imputation_types:\n",
    "                scores_imputed = condition_df[condition_df['test_type'] == imp_type][metric].dropna()\n",
    "                if len(scores_imputed) != len(scores_ablation) or len(scores_imputed) < 2: continue\n",
    "                mean_gain = scores_imputed.mean() - scores_ablation.mean()\n",
    "                stat, p_value = ttest_rel(scores_imputed, scores_ablation, alternative='greater')\n",
    "                statistical_results.append({\n",
    "                    'test_condition': condition,\n",
    "                    'comparison': f\"{imp_type} vs. ablation\",\n",
    "                    'mean_gain': mean_gain,\n",
    "                    'p_value': p_value\n",
    "                })\n",
    "        except (KeyError, ValueError):\n",
    "            continue\n",
    "\n",
    "    if not statistical_results: return None\n",
    "    stats_df = pd.DataFrame(statistical_results)\n",
    "    reject, p_adj, _, _ = multipletests(stats_df['p_value'], alpha=0.05, method='fdr_bh')\n",
    "    stats_df['p_adj_fdr'] = p_adj\n",
    "    stats_df['significant_gain'] = reject\n",
    "    return stats_df\n",
    "\n",
    "def analyze_generative_vs_standard(combined_df: pd.DataFrame, metric: str = 'c_index'):\n",
    "    \"\"\"Performs statistical analysis comparing generative models against standard imputation methods.\"\"\"\n",
    "    statistical_results = []\n",
    "    test_conditions = [c for c in combined_df['test_condition'].unique() if c not in ['full_data', 'cancer_label_only']]\n",
    "\n",
    "    for condition in test_conditions:\n",
    "        condition_df = combined_df[combined_df['test_condition'] == condition]\n",
    "        try:\n",
    "            scores_mean = condition_df[condition_df['test_type'] == 'imputed_mean'][metric].dropna()\n",
    "            scores_knn = condition_df[condition_df['test_type'] == 'imputed_knn'][metric].dropna()\n",
    "            scores_multi = condition_df[condition_df['test_type'] == 'imputed_multi'][metric].dropna()\n",
    "            scores_coherent = condition_df[condition_df['test_type'] == 'imputed_coherent'][metric].dropna()\n",
    "        except KeyError: continue\n",
    "        \n",
    "        standard_models = {'mean': scores_mean, 'knn': scores_knn}\n",
    "        generative_models = {'multi': scores_multi, 'coherent': scores_coherent}\n",
    "\n",
    "        for gen_name, gen_scores in generative_models.items():\n",
    "            for std_name, std_scores in standard_models.items():\n",
    "                if len(gen_scores) != len(std_scores) or len(gen_scores) < 2: continue\n",
    "                mean_gain = gen_scores.mean() - std_scores.mean()\n",
    "                stat, p_value = ttest_rel(gen_scores, std_scores, alternative='greater')\n",
    "                statistical_results.append({\n",
    "                    'test_condition': condition,\n",
    "                    'comparison': f\"imputed_{gen_name} vs. imputed_{std_name}\",\n",
    "                    'mean_gain': mean_gain,\n",
    "                    'p_value': p_value\n",
    "                })\n",
    "                \n",
    "    if not statistical_results: return None\n",
    "    stats_df = pd.DataFrame(statistical_results)\n",
    "    reject, p_adj, _, _ = multipletests(stats_df['p_value'], alpha=0.05, method='fdr_bh')\n",
    "    stats_df['p_adj_fdr'] = p_adj\n",
    "    stats_df['significant_gain'] = reject\n",
    "    return stats_df\n",
    "\n",
    "# --- NEW: Focused plotting function ---\n",
    "def create_generative_focused_plot(data: pd.DataFrame, metric: str, title: str, save_path: str):\n",
    "    \"\"\"\n",
    "    Creates a comparison plot focusing only on the generative models vs. baselines.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Generating focused plot for: {metric} ---\")\n",
    "    \n",
    "    # Define the methods we want to show in this plot\n",
    "    methods_to_show = ['full_data', 'ablation', 'imputed_multi', 'imputed_coherent']\n",
    "    plot_data = data[data['test_type'].isin(methods_to_show)].copy()\n",
    "\n",
    "    # Exclude imputation results for the 'cancer_label_only' case\n",
    "    condition_to_exclude = (plot_data['test_condition'] == 'cancer_label_only') & (plot_data['test_type'] != 'ablation')\n",
    "    plot_data = plot_data[~condition_to_exclude]\n",
    "\n",
    "    # Define a logical order for the plot conditions on the x-axis\n",
    "    plot_data['n_removed'] = plot_data['test_condition'].apply(\n",
    "        lambda x: 0 if x == 'full_data' else (99 if x == 'cancer_label_only' else x.count('_') + 1)\n",
    "    )\n",
    "    plot_order = plot_data.sort_values(by=['n_removed', 'test_condition']).test_condition.unique()\n",
    "    \n",
    "    # Use a focused color palette\n",
    "    palette = {\n",
    "        'full_data': '#4C72B0', \n",
    "        'ablation': '#A9A9A9',\n",
    "        'imputed_multi': '#FFB6C1',\n",
    "        'imputed_coherent': '#DC143C'\n",
    "    }\n",
    "    hue_order = [h for h in ['full_data', 'ablation', 'imputed_multi', 'imputed_coherent'] if h in plot_data['test_type'].unique()]\n",
    "    \n",
    "    g = sns.catplot(\n",
    "        data=plot_data, x='test_condition', y=metric, hue='test_type',\n",
    "        order=plot_order, hue_order=hue_order, kind='bar', height=7, aspect=2.2,\n",
    "        palette=palette, errorbar='sd'\n",
    "    )\n",
    "    \n",
    "    sns.move_legend(g, \"center right\", bbox_to_anchor=(1.1, 0.5), frameon=True, title='Test Type')\n",
    "    g.fig.suptitle(title, y=1.03, fontsize=18)\n",
    "    g.set_axis_labels(\"Test Condition (Modalities Removed)\", f\"Mean {metric.replace('_', ' ').title()}\", fontsize=14)\n",
    "    g.set_xticklabels(rotation=45, ha='right')\n",
    "\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close(g.fig)\n",
    "    print(f\"Plot saved to: {save_path}\")\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == '__main__':\n",
    "    # We will analyze the results from the more complex \"long_rf\" experiment\n",
    "    results_file = '../../results/downstream/task_06_imputing_test_set_surv/all_imputations_results_long_rf.csv'\n",
    "    plots_dir = '../../results/downstream/task_06_imputing_test_set_surv'\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        final_results = pd.read_csv(results_file)\n",
    "        print(f\"Successfully loaded final results from '{results_file}'\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The results file '{results_file}' was not found.\")\n",
    "        print(\"Please run the previous experiment script first to generate the results.\")\n",
    "        exit()\n",
    "\n",
    "    # --- Run and Print Statistical Analyses ---\n",
    "    print(\"\\n\\n===== Analysis 1: Significance of Gain vs. Ablation (C-Index) =====\")\n",
    "    significance_vs_ablation = analyze_vs_ablation(final_results)\n",
    "    if significance_vs_ablation is not None:\n",
    "        print(significance_vs_ablation.sort_values(by=['significant_gain', 'p_adj_fdr'], ascending=[False, True]).to_string())\n",
    "    \n",
    "    print(\"\\n\\n===== Analysis 2: Significance of Gain for Generative vs. Standard Methods (C-Index) =====\")\n",
    "    significance_gen_vs_std = analyze_generative_vs_standard(final_results)\n",
    "    if significance_gen_vs_std is not None:\n",
    "        print(significance_gen_vs_std.sort_values(by=['significant_gain', 'p_adj_fdr'], ascending=[False, True]).to_string())\n",
    "    \n",
    "    # --- Create the new, focused plot ---\n",
    "    final_plot_path = os.path.join(plots_dir, 'generative_model_comparison.png')\n",
    "    create_generative_focused_plot(\n",
    "        final_results, \n",
    "        metric='c_index',\n",
    "        title='Generative Models for Survival Analysis',\n",
    "        save_path=final_plot_path\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
