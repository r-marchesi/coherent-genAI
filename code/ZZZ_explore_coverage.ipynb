{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b7309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import torch\n",
    "\n",
    "from lib.test import coherent_test_cos_rejection, test_model\n",
    "from lib.config import modalities_list\n",
    "from lib.read_data import read_data\n",
    "from lib.get_models import get_diffusion_model\n",
    "from lib.diffusion_models import GaussianDiffusion\n",
    "from lib.metrics import calculate_PED_balanced, compute_prdc\n",
    "\n",
    "# parameters\n",
    "dim = 32    \n",
    "test_repeats = 10\n",
    "\n",
    "results_path = '../results'    \n",
    "labels_dir = \"../datasets_TCGA/downstream_labels/\"\n",
    "data_dir = '../datasets_TCGA/07_normalized/'\n",
    "\n",
    "device = torch.device(f\"cuda:{torch.cuda.current_device()}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# list the four modalities you want to run\n",
    "modalities_to_run = modalities_list  \n",
    "\n",
    "# read all data once\n",
    "modalities_map = read_data(\n",
    "    modalities=modalities_list,\n",
    "    splits=['train','test'],\n",
    "    data_dir=data_dir,\n",
    "    dim=dim,\n",
    ")\n",
    "\n",
    "# store a summary of metrics if desired\n",
    "summary = []\n",
    "\n",
    "def compute_all_metrics(real_arr, gen_arr, test_repeats):\n",
    "    \"\"\"Compute all metrics for a given real/generated array pair.\"\"\"\n",
    "    metrics = {name: np.zeros(test_repeats) for name in \n",
    "               ['prec', 'rec', 'f1', 'g_ped', 'g_ed', 'l_ped', 'l_ed', 'b_ped', 'b_ed']}\n",
    "    \n",
    "    for i in range(test_repeats):\n",
    "        # PRDC\n",
    "        p, r = compute_prdc(real_arr[i], gen_arr[i], nearest_k=10, only_pr=True)\n",
    "        metrics['prec'][i], metrics['rec'][i] = p, r\n",
    "        metrics['f1'][i] = 2 * (p * r) / (p + r + 1e-8)\n",
    "        \n",
    "        # PED/ED metrics\n",
    "        (metrics['g_ped'][i], metrics['g_ed'][i], \n",
    "         metrics['l_ped'][i], metrics['l_ed'][i],\n",
    "         metrics['b_ped'][i], metrics['b_ed'][i]) = calculate_PED_balanced(\n",
    "            real_arr[i], gen_arr[i], metric='l2')\n",
    "    \n",
    "    return {k: (v.mean(), v.std()) for k, v in metrics.items()}\n",
    "\n",
    "def print_metrics(label, metrics):\n",
    "    \"\"\"Print metrics in a compact format.\"\"\"\n",
    "    m = {k: v[0] for k, v in metrics.items()}  # extract means\n",
    "    print(f\"{label:<8} Precision: {m['prec']:.2f}, Recall: {m['rec']:.2f}, F1: {m['f1']:.2f}\"\n",
    "          f\"   ED_G: {m['g_ed']:.2f}, ED_L: {m['l_ed']:.2f}, ED_B: {m['b_ed']:.2f}\"\n",
    "          f\"   PED_G: {m['g_ped']:.2f}, PED_L: {m['l_ped']:.2f}, PED_B: {m['b_ped']:.2f}\")\n",
    "\n",
    "def create_summary_entry(modality, uncond_metrics, cond_metrics, train_test_metrics, train_cond_metrics):\n",
    "    \"\"\"Create a summary dictionary entry.\"\"\"\n",
    "    entry = {'modality': modality}\n",
    "    for condition, metrics in [\n",
    "        ('uncond', uncond_metrics),\n",
    "        ('cond', cond_metrics),\n",
    "        ('train_vs_test', train_test_metrics),\n",
    "        ('train_vs_cond', train_cond_metrics)\n",
    "    ]:\n",
    "        for metric, (mean, std) in metrics.items():\n",
    "            entry[f'{metric}_{condition}'] = mean\n",
    "            entry[f'{metric}_{condition}_std'] = std\n",
    "    return entry\n",
    "\n",
    "for modality in modalities_to_run:\n",
    "    print(f\"\\n=== Running modality: {modality} ===\")\n",
    "    \n",
    "    # Setup paths and load model\n",
    "    test_real = modalities_map[modality]['test']\n",
    "    train_real = modalities_map[modality]['train']\n",
    "    train_real = train_real.dropna()\n",
    "    n_samples, n_feats = test_real.shape\n",
    "    base_dir = pathlib.Path(f\"{results_path}/{dim}/{modality}_from_multi\")\n",
    "    ckpt_path = base_dir / 'train' / 'best_by_mse.pth'\n",
    "    \n",
    "    # Load and setup model\n",
    "    ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "    config = SimpleNamespace(**ckpt['config'])\n",
    "    \n",
    "    cond_datatypes = [m for m in modalities_map.keys() if m != modality]\n",
    "    cond_dim_list = [modalities_map[c]['test'].shape[1] for c in cond_datatypes]\n",
    "    \n",
    "    diffusion = GaussianDiffusion(num_timesteps=1000).to(device)\n",
    "    model = get_diffusion_model(config.architecture, diffusion, config, \n",
    "                               x_dim=n_feats, cond_dims=cond_dim_list).to(device)\n",
    "    model.load_state_dict(ckpt['best_model_mse'])\n",
    "    model.eval()\n",
    "    \n",
    "    # Generate unconditional samples\n",
    "    cond_test_list = [pd.DataFrame(np.zeros_like(modalities_map[c]['test']), \n",
    "                                  columns=modalities_map[c]['test'].columns) \n",
    "                     for c in cond_datatypes]\n",
    "    masks = [np.zeros(n_samples) for _ in cond_datatypes]\n",
    "    \n",
    "    _, uncond_generated_data = test_model(test_real, cond_test_list, model, diffusion,\n",
    "                                         test_iterations=test_repeats, device=device, masks=masks)\n",
    "    \n",
    "    # Load conditional samples\n",
    "    conditioning_string = '_'.join(cond_datatypes)\n",
    "    synth_path = base_dir / 'test' / f'generated_samples_from_{conditioning_string}_best_mse.csv'\n",
    "    cond_generated_data = pd.read_csv(synth_path)\n",
    "    \n",
    "    # Reshape arrays\n",
    "    uncond_arr = uncond_generated_data.values.reshape(test_repeats, n_samples, n_feats)\n",
    "    cond_arr = cond_generated_data.values.reshape(test_repeats, n_samples, n_feats)\n",
    "    real_arr = np.tile(test_real.values[np.newaxis], (test_repeats, 1, 1))\n",
    "    \n",
    "    # Create random subsets of training data for each repeat\n",
    "    train_real_arr = np.zeros((test_repeats, n_samples, n_feats))\n",
    "    for i in range(test_repeats):\n",
    "        idx = np.random.choice(len(train_real), size=n_samples, replace=False)\n",
    "        train_real_arr[i] = train_real.values[idx]\n",
    "    \n",
    "    # Compute metrics\n",
    "    uncond_metrics = compute_all_metrics(real_arr, uncond_arr, test_repeats)\n",
    "    cond_metrics = compute_all_metrics(real_arr, cond_arr, test_repeats)\n",
    "    train_test_metrics = compute_all_metrics(train_real_arr, uncond_arr, test_repeats)\n",
    "    train_cond_metrics = compute_all_metrics(train_real_arr, cond_arr, test_repeats)\n",
    "    \n",
    "    # Print results\n",
    "    print_metrics(\"Uncond\", uncond_metrics)\n",
    "    print_metrics(\"Cond\", cond_metrics)\n",
    "    print_metrics(\"Train vs Test\", train_test_metrics)\n",
    "    print_metrics(\"Train vs Cond\", train_cond_metrics)\n",
    "    \n",
    "    # Add to summary\n",
    "    summary.append(create_summary_entry(modality, uncond_metrics, cond_metrics, train_test_metrics, train_cond_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0005a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import torch\n",
    "\n",
    "from lib.test import coherent_test_cos_rejection, test_model\n",
    "from lib.config import modalities_list\n",
    "from lib.read_data import read_data\n",
    "from lib.get_models import get_diffusion_model\n",
    "from lib.diffusion_models import GaussianDiffusion\n",
    "from lib.metrics import calculate_PED_balanced, compute_prdc\n",
    "\n",
    "# parameters\n",
    "dim = 32    \n",
    "test_repeats = 10\n",
    "\n",
    "results_path = '../results'    \n",
    "labels_dir = \"../datasets_TCGA/downstream_labels/\"\n",
    "data_dir = '../datasets_TCGA/07_normalized/'\n",
    "\n",
    "device = torch.device(f\"cuda:{torch.cuda.current_device()}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# list the four modalities you want to run\n",
    "modalities_to_run = modalities_list  \n",
    "\n",
    "# read all data once\n",
    "modalities_map = read_data(\n",
    "    modalities=modalities_list,\n",
    "    splits=['train','test'],\n",
    "    data_dir=data_dir,\n",
    "    dim=dim,\n",
    ")\n",
    "\n",
    "# store a summary of metrics if desired\n",
    "summary = []\n",
    "\n",
    "def compute_all_metrics(real_arr, gen_arr, test_repeats):\n",
    "    \"\"\"Compute all metrics for a given real/generated array pair.\"\"\"\n",
    "    metrics = {name: np.zeros(test_repeats) for name in \n",
    "               ['prec', 'rec', 'f1', 'g_ped', 'g_ed', 'l_ped', 'l_ed', 'b_ped', 'b_ed']}\n",
    "    \n",
    "    for i in range(test_repeats):\n",
    "        # PRDC\n",
    "        p, r = compute_prdc(real_arr[i], gen_arr[i], nearest_k=10, only_pr=True)\n",
    "        metrics['prec'][i], metrics['rec'][i] = p, r\n",
    "        metrics['f1'][i] = 2 * (p * r) / (p + r + 1e-8)\n",
    "        \n",
    "        # PED/ED metrics\n",
    "        (metrics['g_ped'][i], metrics['g_ed'][i], \n",
    "         metrics['l_ped'][i], metrics['l_ed'][i],\n",
    "         metrics['b_ped'][i], metrics['b_ed'][i]) = calculate_PED_balanced(\n",
    "            real_arr[i], gen_arr[i], metric='l2')\n",
    "    \n",
    "    return {k: (v.mean(), v.std()) for k, v in metrics.items()}\n",
    "\n",
    "def print_metrics(label, metrics):\n",
    "    \"\"\"Print metrics in a compact format.\"\"\"\n",
    "    m = {k: v[0] for k, v in metrics.items()}  # extract means\n",
    "    print(f\"{label:<8} Precision: {m['prec']:.2f}, Recall: {m['rec']:.2f}, F1: {m['f1']:.2f}\"\n",
    "          f\"   ED_G: {m['g_ed']:.2f}, ED_L: {m['l_ed']:.2f}, ED_B: {m['b_ed']:.2f}\"\n",
    "          f\"   PED_G: {m['g_ped']:.2f}, PED_L: {m['l_ped']:.2f}, PED_B: {m['b_ped']:.2f}\")\n",
    "\n",
    "def create_summary_entry(modality, uncond_metrics, cond_metrics, train_test_metrics, train_cond_metrics):\n",
    "    \"\"\"Create a summary dictionary entry.\"\"\"\n",
    "    entry = {'modality': modality}\n",
    "    for condition, metrics in [\n",
    "        ('uncond', uncond_metrics),\n",
    "        ('cond', cond_metrics),\n",
    "        ('train_vs_test', train_test_metrics),\n",
    "        ('train_vs_cond', train_cond_metrics)\n",
    "    ]:\n",
    "        for metric, (mean, std) in metrics.items():\n",
    "            entry[f'{metric}_{condition}'] = mean\n",
    "            entry[f'{metric}_{condition}_std'] = std\n",
    "    return entry\n",
    "\n",
    "for modality in modalities_to_run:\n",
    "    print(f\"\\n=== Running modality: {modality} ===\")\n",
    "    \n",
    "    # Setup paths and load model\n",
    "    test_real = modalities_map[modality]['test']\n",
    "    train_real = modalities_map[modality]['train']\n",
    "    train_real = train_real.dropna()\n",
    "    n_samples, n_feats = test_real.shape\n",
    "    base_dir = pathlib.Path(f\"{results_path}/{dim}/{modality}_from_multi_masked\")\n",
    "    ckpt_path = base_dir / 'train' / 'best_by_mse.pth'\n",
    "    \n",
    "    # Load and setup model\n",
    "    ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "    config = SimpleNamespace(**ckpt['config'])\n",
    "    \n",
    "    cond_datatypes = [m for m in modalities_map.keys() if m != modality]\n",
    "    cond_dim_list = [modalities_map[c]['test'].shape[1] for c in cond_datatypes]\n",
    "    \n",
    "    diffusion = GaussianDiffusion(num_timesteps=1000).to(device)\n",
    "    model = get_diffusion_model(config.architecture, diffusion, config, \n",
    "                               x_dim=n_feats, cond_dims=cond_dim_list).to(device)\n",
    "    model.load_state_dict(ckpt['best_model_mse'])\n",
    "    model.eval()\n",
    "    \n",
    "    # Generate unconditional samples\n",
    "    cond_test_list = [pd.DataFrame(np.zeros_like(modalities_map[c]['test']), \n",
    "                                  columns=modalities_map[c]['test'].columns) \n",
    "                     for c in cond_datatypes]\n",
    "    masks = [np.zeros(n_samples) for _ in cond_datatypes]\n",
    "    \n",
    "    _, uncond_generated_data = test_model(test_real, cond_test_list, model, diffusion,\n",
    "                                         test_iterations=test_repeats, device=device, masks=masks)\n",
    "    \n",
    "    # Load conditional samples\n",
    "    conditioning_string = '_'.join(cond_datatypes)\n",
    "    synth_path = base_dir / 'test' / f'generated_samples_from_{conditioning_string}_best_mse.csv'\n",
    "    cond_generated_data = pd.read_csv(synth_path)\n",
    "    \n",
    "    # Reshape arrays\n",
    "    uncond_arr = uncond_generated_data.values.reshape(test_repeats, n_samples, n_feats)\n",
    "    cond_arr = cond_generated_data.values.reshape(test_repeats, n_samples, n_feats)\n",
    "    real_arr = np.tile(test_real.values[np.newaxis], (test_repeats, 1, 1))\n",
    "    \n",
    "    # Create random subsets of training data for each repeat\n",
    "    train_real_arr = np.zeros((test_repeats, n_samples, n_feats))\n",
    "    for i in range(test_repeats):\n",
    "        idx = np.random.choice(len(train_real), size=n_samples, replace=False)\n",
    "        train_real_arr[i] = train_real.values[idx]\n",
    "    \n",
    "    # Compute metrics\n",
    "    uncond_metrics = compute_all_metrics(real_arr, uncond_arr, test_repeats)\n",
    "    cond_metrics = compute_all_metrics(real_arr, cond_arr, test_repeats)\n",
    "    train_test_metrics = compute_all_metrics(train_real_arr, uncond_arr, test_repeats)\n",
    "    train_cond_metrics = compute_all_metrics(train_real_arr, cond_arr, test_repeats)\n",
    "    \n",
    "    # Print results\n",
    "    print_metrics(\"Uncond\", uncond_metrics)\n",
    "    print_metrics(\"Cond\", cond_metrics)\n",
    "    print_metrics(\"Train vs Test\", train_test_metrics)\n",
    "    print_metrics(\"Train vs Cond\", train_cond_metrics)\n",
    "    \n",
    "    # Add to summary\n",
    "    summary.append(create_summary_entry(modality, uncond_metrics, cond_metrics, train_test_metrics, train_cond_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from types import SimpleNamespace\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "\n",
    "# Assuming lib functions are in the correct PYTHONPATH\n",
    "from lib.test import coherent_test_cos_rejection, test_model\n",
    "from lib.config import modalities_list\n",
    "from lib.read_data import read_data\n",
    "from lib.get_models import get_diffusion_model\n",
    "from lib.diffusion_models import GaussianDiffusion\n",
    "from lib.metrics import calculate_PED_balanced, compute_prdc\n",
    "\n",
    "# --- Parameters ---\n",
    "dim = '32'\n",
    "test_repeats = 10\n",
    "metric_to_use = 'mse' # The metric used to select the best model checkpoint\n",
    "\n",
    "# Note: The 'folder' argument from your generation script is represented here as 'results_path'\n",
    "results_path = '../results'\n",
    "data_dir = '../datasets_TCGA/07_normalized/'\n",
    "\n",
    "device = torch.device(f\"cuda:{torch.cuda.current_device()}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# List the four modalities you want to run\n",
    "modalities_to_run = modalities_list\n",
    "\n",
    "# Read all data once\n",
    "modalities_map = read_data(\n",
    "    modalities=modalities_list,\n",
    "    splits=['train','test'],\n",
    "    data_dir=data_dir,\n",
    "    dim=dim,\n",
    ")\n",
    "\n",
    "# Store a summary of metrics\n",
    "summary = []\n",
    "\n",
    "def compute_all_metrics(real_arr, gen_arr, test_repeats):\n",
    "    \"\"\"Compute all metrics for a given real/generated array pair.\"\"\"\n",
    "    valid_repeats = gen_arr.shape[0]\n",
    "    metrics = {name: np.zeros(valid_repeats) for name in\n",
    "               ['prec', 'rec', 'f1', 'g_ped', 'g_ed', 'l_ped', 'l_ed', 'b_ped', 'b_ed']}\n",
    "\n",
    "    for i in range(valid_repeats):\n",
    "        p, r = compute_prdc(real_arr[i], gen_arr[i], nearest_k=10, only_pr=True)\n",
    "        metrics['prec'][i], metrics['rec'][i] = p, r\n",
    "        metrics['f1'][i] = 2 * (p * r) / (p + r + 1e-8) if (p + r) > 1e-8 else 0.0\n",
    "        (metrics['g_ped'][i], metrics['g_ed'][i],\n",
    "         metrics['l_ped'][i], metrics['l_ed'][i],\n",
    "         metrics['b_ped'][i], metrics['b_ed'][i]) = calculate_PED_balanced(\n",
    "             real_arr[i], gen_arr[i], metric='l2')\n",
    "\n",
    "    return {k: (v.mean(), v.std()) for k, v in metrics.items()}\n",
    "\n",
    "def print_metrics(label, metrics):\n",
    "    \"\"\"Print metrics in a compact format.\"\"\"\n",
    "    m = {k: v[0] for k, v in metrics.items()}\n",
    "    print(f\"{label:<15} Precision: {m['prec']:.2f}, Recall: {m['rec']:.2f}, F1: {m['f1']:.2f}\"\n",
    "          f\"  |  ED_G: {m['g_ed']:.2f}, ED_L: {m['l_ed']:.2f}, ED_B: {m['b_ed']:.2f}\"\n",
    "          f\"  |  PED_G: {m['g_ped']:.2f}, PED_L: {m['l_ped']:.2f}, PED_B: {m['b_ped']:.2f}\")\n",
    "\n",
    "def create_summary_entry(modality, uncond_metrics, cond_metrics, train_test_metrics, train_cond_metrics):\n",
    "    \"\"\"Create a summary dictionary entry.\"\"\"\n",
    "    entry = {'modality': modality}\n",
    "    for condition, metrics in [('uncond', uncond_metrics), ('cond', cond_metrics), ('train_vs_uncond', train_test_metrics), ('train_vs_cond', train_cond_metrics)]:\n",
    "        if metrics:\n",
    "            for metric, (mean, std) in metrics.items():\n",
    "                entry[f'{metric}_{condition}'] = mean\n",
    "                entry[f'{metric}_{condition}_std'] = std\n",
    "    return entry\n",
    "\n",
    "# --- Main Evaluation Loop ---\n",
    "for modality in modalities_to_run:\n",
    "    print(f\"\\n=== Running modality: {modality} ===\")\n",
    "\n",
    "    test_real = modalities_map[modality]['test']\n",
    "    train_real = modalities_map[modality]['train'].dropna()\n",
    "    n_samples, n_feats = test_real.shape\n",
    "\n",
    "    cond_datatypes = [m for m in modalities_map.keys() if m != modality]\n",
    "    diffusion = GaussianDiffusion(num_timesteps=1000).to(device)\n",
    "\n",
    "    # --- Part 1: Generate Unconditional Samples using Coherent Ensemble ---\n",
    "    print(\"Generating unconditional samples using coherent ensemble...\")\n",
    "    models_for_uncond = []\n",
    "    weights_for_uncond = []\n",
    "    zero_cond_list = []\n",
    "    all_models_found = True\n",
    "\n",
    "    for c in cond_datatypes:\n",
    "        ckpt_path = pathlib.Path(f\"{results_path}/{dim}/{modality}_from_{c}/train/best_by_{metric_to_use}.pth\")\n",
    "        if not ckpt_path.exists():\n",
    "            print(f\"WARNING: Checkpoint not found for model {modality}_from_{c}. Cannot generate unconditional samples.\")\n",
    "            print(f\"Path: {ckpt_path}\")\n",
    "            all_models_found = False\n",
    "            break\n",
    "\n",
    "        ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "        config_c = SimpleNamespace(**ckpt['config'])\n",
    "        state_dict = ckpt[f'best_model_{metric_to_use}']\n",
    "        weights_for_uncond.append(ckpt['best_loss'])\n",
    "\n",
    "        cond_dim = modalities_map[c]['test'].shape[1]\n",
    "        model_c = get_diffusion_model(\n",
    "            config_c.architecture, diffusion, config_c,\n",
    "            x_dim=n_feats, cond_dims=cond_dim\n",
    "        ).to(device)\n",
    "        model_c.load_state_dict(state_dict)\n",
    "        model_c.eval()\n",
    "        models_for_uncond.append(model_c)\n",
    "\n",
    "        # Create a zeroed-out DataFrame for this condition\n",
    "        shape = modalities_map[c]['test'].shape\n",
    "        zero_cond_list.append(pd.DataFrame(np.zeros(shape), columns=modalities_map[c]['test'].columns))\n",
    "\n",
    "    uncond_generated_data = None\n",
    "    if all_models_found:\n",
    "        _, uncond_generated_data, _ = coherent_test_cos_rejection(\n",
    "            test_real,\n",
    "            zero_cond_list,\n",
    "            models_for_uncond,\n",
    "            diffusion,\n",
    "            test_iterations=test_repeats,\n",
    "            max_retries= 10,\n",
    "            device=device,\n",
    "            weights_list=weights_for_uncond\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Skipping unconditional evaluation for {modality}.\")\n",
    "\n",
    "    # --- Part 2: Load Pre-Generated Conditional Samples ---\n",
    "    print(\"Loading conditional samples...\")\n",
    "    base_dir_coherent = pathlib.Path(f\"{results_path}/{dim}/{modality}_from_coherent\")\n",
    "    conditioning_string = '_'.join(cond_datatypes)\n",
    "    synth_path = base_dir_coherent / 'test' / f'generated_samples_from_{conditioning_string}_best_{metric_to_use}.csv'\n",
    "\n",
    "    cond_generated_data = None\n",
    "    if not synth_path.exists():\n",
    "        print(f\"WARNING: Coherent conditional file not found, skipping cond eval for {modality}.\")\n",
    "        print(f\"Path: {synth_path}\")\n",
    "    else:\n",
    "        cond_generated_data = pd.read_csv(synth_path)\n",
    "\n",
    "    # --- Part 3: Reshape Arrays and Compute Metrics ---\n",
    "    real_arr = np.tile(test_real.values[np.newaxis], (test_repeats, 1, 1))\n",
    "    \n",
    "    train_real_arr = np.zeros((test_repeats, n_samples, n_feats))\n",
    "    for i in range(test_repeats):\n",
    "        idx = np.random.choice(len(train_real), size=n_samples, replace=False)\n",
    "        train_real_arr[i] = train_real.values[idx]\n",
    "\n",
    "    uncond_metrics, cond_metrics, train_uncond_metrics, train_cond_metrics = {}, {}, {}, {}\n",
    "\n",
    "    if uncond_generated_data is not None:\n",
    "        uncond_arr = uncond_generated_data.values.reshape(-1, n_samples, n_feats)\n",
    "        uncond_metrics = compute_all_metrics(real_arr, uncond_arr, test_repeats)\n",
    "        train_uncond_metrics = compute_all_metrics(train_real_arr, uncond_arr, test_repeats)\n",
    "        print_metrics(\"Uncond vs Real\", uncond_metrics)\n",
    "        print_metrics(\"Uncond vs Train\", train_uncond_metrics)\n",
    "\n",
    "    if cond_generated_data is not None:\n",
    "        cond_arr = cond_generated_data.values.reshape(-1, n_samples, n_feats)\n",
    "        cond_metrics = compute_all_metrics(real_arr, cond_arr, test_repeats)\n",
    "        train_cond_metrics = compute_all_metrics(train_real_arr, cond_arr, test_repeats)\n",
    "        print_metrics(\"Cond vs Real\", cond_metrics)\n",
    "        print_metrics(\"Cond vs Train\", train_cond_metrics)\n",
    "\n",
    "    summary.append(create_summary_entry(modality, uncond_metrics, cond_metrics, train_uncond_metrics, train_cond_metrics))\n",
    "\n",
    "\n",
    "# --- Final Summary ---\n",
    "if summary:\n",
    "    summary_df = pd.DataFrame(summary)\n",
    "    print(\"\\n\\n--- Evaluation Summary (Coherent Method) ---\")\n",
    "    print(summary_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29260c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from types import SimpleNamespace\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import torch\n",
    "\n",
    "# Assuming lib functions are in the correct PYTHONPATH\n",
    "from lib.test import coherent_test_cos_rejection, test_model\n",
    "from lib.config import modalities_list\n",
    "from lib.read_data import read_data\n",
    "from lib.get_models import get_diffusion_model\n",
    "from lib.diffusion_models import GaussianDiffusion\n",
    "from lib.metrics import calculate_PED_balanced, compute_prdc\n",
    "\n",
    "# --- Global Parameters & Setup ---\n",
    "DEVICE = torch.device(f\"cuda:{torch.cuda.current_device()}\" if torch.cuda.is_available() else \"cpu\")\n",
    "METRIC_TO_USE = 'mse'\n",
    "\n",
    "# =============================================================================\n",
    "# 1. HELPER FUNCTIONS (UNCHANGED CORE LOGIC)\n",
    "# =============================================================================\n",
    "\n",
    "def compute_all_metrics(real_arr, gen_arr):\n",
    "    \"\"\"Compute all metrics for a given real/generated array pair.\"\"\"\n",
    "    valid_repeats = gen_arr.shape[0]\n",
    "    metrics = {name: np.zeros(valid_repeats) for name in\n",
    "               ['prec', 'rec', 'f1', 'g_ped', 'g_ed', 'l_ped', 'l_ed', 'b_ped', 'b_ed']}\n",
    "\n",
    "    for i in range(valid_repeats):\n",
    "        p, r = compute_prdc(real_arr[i], gen_arr[i], nearest_k=10, only_pr=True)\n",
    "        metrics['prec'][i], metrics['rec'][i] = p, r\n",
    "        metrics['f1'][i] = 2 * (p * r) / (p + r + 1e-8) if (p + r) > 1e-8 else 0.0\n",
    "        (metrics['g_ped'][i], metrics['g_ed'][i],\n",
    "         metrics['l_ped'][i], metrics['l_ed'][i],\n",
    "         metrics['b_ped'][i], metrics['b_ed'][i]) = calculate_PED_balanced(\n",
    "             real_arr[i], gen_arr[i], metric='l2')\n",
    "\n",
    "    return {k: (v.mean(), v.std()) for k, v in metrics.items()}\n",
    "\n",
    "# =============================================================================\n",
    "# 2. STRATEGY CLASSES (CORE OF THE REFACTOR)\n",
    "# =============================================================================\n",
    "\n",
    "class EvaluationStrategy(ABC):\n",
    "    \"\"\"Abstract base class for an evaluation strategy.\"\"\"\n",
    "    def __init__(self, method_name, results_path, dim):\n",
    "        self.method_name = method_name\n",
    "        self.results_path = results_path\n",
    "        self.dim = dim\n",
    "\n",
    "    def get_base_dir(self, modality):\n",
    "        return pathlib.Path(f\"{self.results_path}/{self.dim}/{modality}_from_{self.method_name}\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def generate_unconditional(self, modality, modalities_map, n_feats, test_repeats):\n",
    "        \"\"\"Generates unconditional samples for a given modality.\"\"\"\n",
    "        pass\n",
    "\n",
    "class MultiModelStrategy(EvaluationStrategy):\n",
    "    \"\"\"Strategy for 'multi' and 'multi_masked' models.\"\"\"\n",
    "    def generate_unconditional(self, modality, modalities_map, n_feats, test_repeats):\n",
    "        print(f\"  Generating unconditional samples using '{self.method_name}' strategy...\")\n",
    "        base_dir = self.get_base_dir(modality)\n",
    "        ckpt_path = base_dir / 'train' / f'best_by_{METRIC_TO_USE}.pth'\n",
    "        if not ckpt_path.exists():\n",
    "            print(f\"  WARNING: Checkpoint not found at {ckpt_path}. Skipping.\")\n",
    "            return None\n",
    "\n",
    "        ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "        config = SimpleNamespace(**ckpt['config'])\n",
    "        cond_datatypes = [m for m in modalities_map.keys() if m != modality]\n",
    "        cond_dim_list = [modalities_map[c]['test'].shape[1] for c in cond_datatypes]\n",
    "        \n",
    "        diffusion = GaussianDiffusion(num_timesteps=1000).to(DEVICE)\n",
    "        model = get_diffusion_model(config.architecture, diffusion, config,\n",
    "                                    x_dim=n_feats, cond_dims=cond_dim_list).to(DEVICE)\n",
    "        model.load_state_dict(ckpt[f'best_model_{METRIC_TO_USE}'])\n",
    "        model.eval()\n",
    "\n",
    "        n_samples = len(modalities_map[modality]['test'])\n",
    "        zero_conds = [pd.DataFrame(np.zeros_like(modalities_map[c]['test'])) for c in cond_datatypes]\n",
    "        masks = [np.zeros(n_samples) for _ in cond_datatypes]\n",
    "        \n",
    "        _, uncond_data = test_model(\n",
    "            modalities_map[modality]['test'], zero_conds, model, diffusion,\n",
    "            test_iterations=test_repeats, device=DEVICE, masks=masks\n",
    "        )\n",
    "        return uncond_data\n",
    "\n",
    "class CoherentStrategy(EvaluationStrategy):\n",
    "    \"\"\"Strategy for the 'coherent' ensemble model.\"\"\"\n",
    "    def __init__(self, method_name, results_path, dim):\n",
    "        super().__init__(method_name, results_path, dim)\n",
    "\n",
    "    def get_base_dir(self, modality):\n",
    "        # The coherent results are stored in a differently named folder\n",
    "        return pathlib.Path(f\"{self.results_path}/{self.dim}/{modality}_from_coherent\")\n",
    "\n",
    "    def generate_unconditional(self, modality, modalities_map, n_feats, test_repeats):\n",
    "        print(\"  Generating unconditional samples using 'coherent' strategy...\")\n",
    "        cond_datatypes = [m for m in modalities_map.keys() if m != modality]\n",
    "        diffusion = GaussianDiffusion(num_timesteps=1000).to(DEVICE)\n",
    "\n",
    "        models, weights, zero_conds = [], [], []\n",
    "        for c in cond_datatypes:\n",
    "            # Coherent method relies on single-pair models\n",
    "            ckpt_path = pathlib.Path(f\"{self.results_path}/{self.dim}/{modality}_from_{c}/train/best_by_{METRIC_TO_USE}.pth\")\n",
    "            if not ckpt_path.exists():\n",
    "                print(f\"  WARNING: Coherent dependency not found at {ckpt_path}. Skipping.\")\n",
    "                return None\n",
    "\n",
    "            ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "            config_c = SimpleNamespace(**ckpt['config'])\n",
    "            model_c = get_diffusion_model(\n",
    "                config_c.architecture, diffusion, config_c,\n",
    "                x_dim=n_feats, cond_dims=modalities_map[c]['test'].shape[1]\n",
    "            ).to(DEVICE)\n",
    "            model_c.load_state_dict(ckpt[f'best_model_{METRIC_TO_USE}'])\n",
    "            model_c.eval()\n",
    "\n",
    "            models.append(model_c)\n",
    "            weights.append(ckpt['best_loss'])\n",
    "            zero_conds.append(pd.DataFrame(np.zeros_like(modalities_map[c]['test'])))\n",
    "\n",
    "        _, uncond_data, _ = coherent_test_cos_rejection(\n",
    "            modalities_map[modality]['test'], zero_conds, models, diffusion,\n",
    "            test_iterations=test_repeats, max_retries=10, device=DEVICE, weights_list=weights\n",
    "        )\n",
    "        return uncond_data\n",
    "\n",
    "# =============================================================================\n",
    "# 3. MAIN EVALUATION SCRIPT\n",
    "# =============================================================================\n",
    "\n",
    "def run_evaluation(args):\n",
    "    \"\"\"Main function to run the evaluation for specified methods.\"\"\"\n",
    "    \n",
    "    # Load data once\n",
    "    modalities_map = read_data(\n",
    "        modalities=modalities_list,\n",
    "        splits=['train', 'test'],\n",
    "        data_dir=args.data_dir,\n",
    "        dim=args.dim,\n",
    "    )\n",
    "\n",
    "    # Instantiate all available strategies\n",
    "    all_strategies = {\n",
    "        'multi': MultiModelStrategy('multi', args.results_path, args.dim),\n",
    "        'multi_masked': MultiModelStrategy('multi_masked', args.results_path, args.dim),\n",
    "        'coherent': CoherentStrategy('coherent', args.results_path, args.dim),\n",
    "    }\n",
    "\n",
    "    # Filter strategies based on user input\n",
    "    methods_to_run = args.methods if 'all' not in args.methods else all_strategies.keys()\n",
    "    strategies_to_run = {name: strat for name, strat in all_strategies.items() if name in methods_to_run}\n",
    "\n",
    "    if not strategies_to_run:\n",
    "        print(\"No valid methods selected. Available methods are: 'multi', 'multi_masked', 'coherent', 'all'\")\n",
    "        return\n",
    "\n",
    "    summary_rows = []\n",
    "    for method_name, strategy in strategies_to_run.items():\n",
    "        print(f\"\\n{'='*20} Evaluating Method: {method_name.upper()} {'='*20}\")\n",
    "        \n",
    "        for modality in modalities_list:\n",
    "            print(f\"\\n--- Running modality: {modality} ---\")\n",
    "            \n",
    "            # --- a) Prepare data ---\n",
    "            test_real_df = modalities_map[modality]['test']\n",
    "            train_real_df = modalities_map[modality]['train'].dropna()\n",
    "            n_samples, n_feats = test_real_df.shape\n",
    "            \n",
    "            # --- b) Generate/Load Samples ---\n",
    "            uncond_gen_df = strategy.generate_unconditional(modality, modalities_map, n_feats, args.test_repeats)\n",
    "            \n",
    "            cond_datatypes = [m for m in modalities_map.keys() if m != modality]\n",
    "            cond_string = '_'.join(cond_datatypes)\n",
    "            cond_path = strategy.get_base_dir(modality) / 'test' / f'generated_samples_from_{cond_string}_best_{METRIC_TO_USE}.csv'\n",
    "            \n",
    "            cond_gen_df = None\n",
    "            if cond_path.exists():\n",
    "                cond_gen_df = pd.read_csv(cond_path)\n",
    "            else:\n",
    "                print(f\"  WARNING: Conditional data not found at {cond_path}. Skipping.\")\n",
    "\n",
    "            # --- c) Compute Metrics ---\n",
    "            real_arr = np.tile(test_real_df.values[np.newaxis], (args.test_repeats, 1, 1))\n",
    "            train_arr = np.array([train_real_df.sample(n=n_samples).values for _ in range(args.test_repeats)])\n",
    "            \n",
    "            # Process and print metrics for this modality and method\n",
    "            modality_results = {'method': method_name, 'modality': modality}\n",
    "\n",
    "            if uncond_gen_df is not None:\n",
    "                uncond_arr = uncond_gen_df.values.reshape(args.test_repeats, n_samples, n_feats)\n",
    "                modality_results['uncond_vs_test'] = compute_all_metrics(real_arr, uncond_arr)\n",
    "                modality_results['uncond_vs_train'] = compute_all_metrics(train_arr, uncond_arr)\n",
    "                print(\"\\n  -- Unconditional Metrics --\")\n",
    "                print_metrics(\"vs Test\", modality_results['uncond_vs_test'])\n",
    "                print_metrics(\"vs Train\", modality_results['uncond_vs_train'])\n",
    "                \n",
    "            if cond_gen_df is not None:\n",
    "                cond_arr = cond_gen_df.values.reshape(args.test_repeats, n_samples, n_feats)\n",
    "                modality_results['cond_vs_test'] = compute_all_metrics(real_arr, cond_arr)\n",
    "                modality_results['cond_vs_train'] = compute_all_metrics(train_arr, cond_arr)\n",
    "                print(\"\\n  -- Conditional Metrics --\")\n",
    "                print_metrics(\"vs Test\", modality_results['cond_vs_test'])\n",
    "                print_metrics(\"vs Train\", modality_results['cond_vs_train'])\n",
    "\n",
    "            # --- d) Format for Summary ---\n",
    "            flat_summary_row = {'method': method_name, 'modality': modality}\n",
    "            for eval_type, metrics_dict in modality_results.items():\n",
    "                if isinstance(metrics_dict, dict):\n",
    "                    for metric_name, (mean, std) in metrics_dict.items():\n",
    "                        flat_summary_row[f'{eval_type}_{metric_name}_mean'] = mean\n",
    "                        flat_summary_row[f'{eval_type}_{metric_name}_std'] = std\n",
    "            summary_rows.append(flat_summary_row)\n",
    "\n",
    "    # --- Final Summary ---\n",
    "    if summary_rows:\n",
    "        summary_df = pd.DataFrame(summary_rows)\n",
    "        output_path = f'{args.results_path}/{args.dim}/distributions_coverage.csv'\n",
    "        summary_df.to_csv(output_path, index=False)\n",
    "        print(f\"\\n\\n{'='*25} FULL SUMMARY {'='*25}\")\n",
    "        print(summary_df.to_string())\n",
    "        print(f\"\\nComplete summary saved to: {output_path}\")\n",
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Hardcoded Parameters ---\n",
    "    # Create a 'SimpleNamespace' object to mimic the 'args' object created by argparse.\n",
    "    # This allows you to pass the parameters to the run_evaluation function without changing its internal logic.\n",
    "    args = SimpleNamespace(\n",
    "        dim=32,\n",
    "        test_repeats=10,\n",
    "        results_path='../results',\n",
    "        data_dir='../datasets_TCGA/07_normalized/',\n",
    "        methods=['all']  # This will run 'multi', 'multi_masked', and 'coherent'\n",
    "    )\n",
    "    \n",
    "    # Call the main evaluation function with the hardcoded parameters\n",
    "    run_evaluation(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e69d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from types import SimpleNamespace\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# --- Global Parameters & Setup ---\n",
    "DEVICE = torch.device(f\"cuda:{torch.cuda.current_device()}\" if torch.cuda.is_available() else \"cpu\")\n",
    "METRIC_TO_USE = 'mse'\n",
    "\n",
    "\n",
    "def plot_distributions(real_df, uncond_df, cond_df, method_name, modality):\n",
    "    \"\"\"\n",
    "    Creates and displays a comprehensive 2D embedding plot (PCA & UMAP) comparing\n",
    "    real, unconditional, and conditional data distributions.\n",
    "    \"\"\"\n",
    "    print(f\"  Generating plots for {modality} using {method_name}...\")\n",
    "\n",
    "    datasets = {'Real': real_df, 'Unconditional': uncond_df}\n",
    "    if cond_df is not None:\n",
    "        datasets['Conditional'] = cond_df\n",
    "\n",
    "    # Combine all data for a single, consistent embedding\n",
    "    all_data = pd.concat(datasets.values(), ignore_index=True)\n",
    "    labels = np.concatenate([np.full(len(df), name) for name, df in datasets.items()])\n",
    "\n",
    "    # --- Fit Embeddings ONCE on all data ---\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    embedding_pca = pca.fit_transform(all_data)\n",
    "\n",
    "    reducer = umap.UMAP(n_components=2, n_neighbors=30, min_dist=0.1, random_state=42)\n",
    "    embedding_umap = reducer.fit_transform(all_data)\n",
    "\n",
    "    # --- Create the Plot ---\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    fig.suptitle(f'Distribution Embeddings: {modality.upper()} (Method: {method_name.capitalize()})', fontsize=20)\n",
    "\n",
    "    plot_styles = {\n",
    "        'Real':          {'color': \"#405d72\", 'alpha': 0.6, 's': 5, 'zorder': 1},\n",
    "        'Unconditional': {'color': \"#ff0efb\", 'alpha': 0.4, 's': 5, 'zorder': 2},\n",
    "        'Conditional':   {'color': \"#2dd42d\", 'alpha': 0.4, 's': 5, 'zorder': 3}\n",
    "    }\n",
    "\n",
    "    # Plot PCA\n",
    "    axes[0].set_title('PCA Projection', fontsize=14)\n",
    "    for label, style in plot_styles.items():\n",
    "        if label in datasets:\n",
    "            idx = labels == label\n",
    "            axes[0].scatter(embedding_pca[idx, 0], embedding_pca[idx, 1], label=label, **style)\n",
    "    axes[0].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Plot UMAP\n",
    "    axes[1].set_title('UMAP Projection', fontsize=14)\n",
    "    for label, style in plot_styles.items():\n",
    "        if label in datasets:\n",
    "            idx = labels == label\n",
    "            axes[1].scatter(embedding_umap[idx, 0], embedding_umap[idx, 1], label=label, **style)\n",
    "    axes[1].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper right', bbox_to_anchor=(0.99, 0.95), fontsize=12)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "    # --- Show the plot interactively ---\n",
    "    # This will pause the script until you close the plot window.\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_plotting(args):\n",
    "    \"\"\"Main function to run the plotting for specified methods.\"\"\"\n",
    "\n",
    "    modalities_map = read_data(\n",
    "        modalities=modalities_list,\n",
    "        splits=['train', 'test'],\n",
    "        data_dir=args.data_dir,\n",
    "        dim=args.dim,\n",
    "    )\n",
    "\n",
    "    all_strategies = {\n",
    "        'multi': MultiModelStrategy('multi', args.results_path, args.dim),\n",
    "        'multi_masked': MultiModelStrategy('multi_masked', args.results_path, args.dim),\n",
    "        'coherent': CoherentStrategy('coherent', args.results_path, args.dim),\n",
    "    }\n",
    "\n",
    "    methods_to_run = args.methods if 'all' not in args.methods else all_strategies.keys()\n",
    "    strategies_to_run = {name: strat for name, strat in all_strategies.items() if name in methods_to_run}\n",
    "\n",
    "    if not strategies_to_run:\n",
    "        print(\"No valid methods selected.\")\n",
    "        return\n",
    "\n",
    "    for method_name, strategy in strategies_to_run.items():\n",
    "        print(f\"\\n{'='*20} Plotting for Method: {method_name.upper()} {'='*20}\")\n",
    "\n",
    "        for modality in modalities_list:\n",
    "            print(f\"\\n--- Processing modality: {modality} ---\")\n",
    "\n",
    "            test_real_df = modalities_map[modality]['test']\n",
    "            n_samples, n_feats = test_real_df.shape\n",
    "\n",
    "            uncond_gen_df = strategy.generate_unconditional(modality, modalities_map, n_feats, 1)\n",
    "\n",
    "            cond_datatypes = [m for m in modalities_map.keys() if m != modality]\n",
    "            cond_string = '_'.join(cond_datatypes)\n",
    "            cond_path = strategy.get_base_dir(modality) / 'test' / f'generated_samples_from_{cond_string}_best_{METRIC_TO_USE}.csv'\n",
    "\n",
    "            cond_gen_df = pd.read_csv(cond_path) if cond_path.exists() else None\n",
    "            if cond_gen_df is not None:\n",
    "                cond_gen_df = cond_gen_df.head(n_samples)\n",
    "\n",
    "            if uncond_gen_df is None:\n",
    "                print(f\"  Skipping plots for {modality} as unconditional data could not be generated.\")\n",
    "                continue\n",
    "\n",
    "            plot_distributions(\n",
    "                real_df=test_real_df,\n",
    "                uncond_df=uncond_gen_df,\n",
    "                cond_df=cond_gen_df,\n",
    "                method_name=method_name,\n",
    "                modality=modality\n",
    "            )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create a SimpleNamespace object with hardcoded parameters to run everything.\n",
    "    # This replaces the command-line parser.\n",
    "    args = SimpleNamespace(\n",
    "        dim=32,\n",
    "        results_path='../results',\n",
    "        data_dir='../datasets_TCGA/07_normalized/',\n",
    "        methods=['all']  # Instructs the script to run all available strategies\n",
    "    )\n",
    "\n",
    "    run_plotting(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f98076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from types import SimpleNamespace\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Global Parameters & Setup ---\n",
    "DEVICE = torch.device(f\"cuda:{torch.cuda.current_device()}\" if torch.cuda.is_available() else \"cpu\")\n",
    "METRIC_TO_USE = 'mse'\n",
    "\n",
    "\n",
    "def plot_combined_distributions(real_df, uncond_df, cond_df, method_name):\n",
    "    \"\"\"\n",
    "    Creates and displays a 2x2 embedding plot, fitting PCA/UMAP on real data only\n",
    "    and then transforming all data into that space.\n",
    "    \"\"\"\n",
    "    print(f\"  Generating combined plot for method '{method_name}'...\")\n",
    "\n",
    "    # --- Data Preparation ---\n",
    "    datasets = {'Real': real_df, 'Unconditional': uncond_df}\n",
    "    has_conditional = cond_df is not None\n",
    "    if has_conditional:\n",
    "        datasets['Conditional'] = cond_df\n",
    "\n",
    "    # --- MODIFIED: Fit Embeddings ONLY on REAL data, then transform all ---\n",
    "    print(\"    Fitting PCA and UMAP on REAL data only...\")\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    pca.fit(real_df)  # Fit only on the real data\n",
    "    # Transform each dataset into the learned space\n",
    "    pca_embeddings = {name: pca.transform(df) for name, df in datasets.items()}\n",
    "\n",
    "    # UMAP\n",
    "    reducer = umap.UMAP(n_components=2, n_neighbors=30, min_dist=0.1, random_state=42)\n",
    "    reducer.fit(real_df) # Fit only on the real data\n",
    "    # Transform each dataset into the learned space\n",
    "    umap_embeddings = {name: reducer.transform(df) for name, df in datasets.items()}\n",
    "    print(\"    Transformation complete.\")\n",
    "\n",
    "\n",
    "    # --- Create the 2x2 Plot ---\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 18))\n",
    "    fig.suptitle(f'Combined Distribution Embeddings (Method: {method_name.capitalize()})', fontsize=22)\n",
    "\n",
    "    plot_styles = {\n",
    "        'Real':          {'color': \"#3a7cac\", 'alpha': 0.9, 's': 6, 'zorder': 1, 'label': 'Real'},\n",
    "        'Unconditional': {'color': \"#e01122\", 'alpha': 0.6, 's': 6, 'zorder': 2, 'label': 'Unconditional'},\n",
    "        'Conditional':   {'color': \"#f2991b\", 'alpha': 0.6, 's': 6, 'zorder': 2, 'label': 'Conditional'}\n",
    "    }\n",
    "\n",
    "    # --- Helper function for plotting on a subplot ---\n",
    "    def plot_on_ax(ax, embedding_dict, labels_to_plot):\n",
    "        for label in labels_to_plot:\n",
    "            if label in embedding_dict:\n",
    "                embedding = embedding_dict[label]\n",
    "                ax.scatter(embedding[:, 0], embedding[:, 1], **plot_styles[label])\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # --- Populate the subplots ---\n",
    "    # Top-Left: PCA Real vs Unconditional\n",
    "    axes[0, 0].set_title('PCA: Real vs. Unconditional', fontsize=16)\n",
    "    plot_on_ax(axes[0, 0], pca_embeddings, ['Real', 'Unconditional'])\n",
    "\n",
    "    # Top-Right: PCA Real vs Conditional\n",
    "    axes[0, 1].set_title('PCA: Real vs. Conditional', fontsize=16)\n",
    "    if has_conditional:\n",
    "        plot_on_ax(axes[0, 1], pca_embeddings, ['Real', 'Conditional'])\n",
    "    else:\n",
    "        axes[0, 1].text(0.5, 0.5, 'Conditional Data\\nNot Available', ha='center', va='center', transform=axes[0, 1].transAxes, alpha=0.5, fontsize=14)\n",
    "        axes[0, 1].tick_params(left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "\n",
    "\n",
    "    # Bottom-Left: UMAP Real vs Unconditional\n",
    "    axes[1, 0].set_title('UMAP: Real vs. Unconditional', fontsize=16)\n",
    "    plot_on_ax(axes[1, 0], umap_embeddings, ['Real', 'Unconditional'])\n",
    "\n",
    "    # Bottom-Right: UMAP Real vs Conditional\n",
    "    axes[1, 1].set_title('UMAP: Real vs. Conditional', fontsize=16)\n",
    "    if has_conditional:\n",
    "        plot_on_ax(axes[1, 1], umap_embeddings, ['Real', 'Conditional'])\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'Conditional Data\\nNot Available', ha='center', va='center', transform=axes[1, 1].transAxes, alpha=0.5, fontsize=14)\n",
    "        axes[1, 1].tick_params(left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "\n",
    "    # --- Create a single, unified legend for the figure ---\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color='w', label=style['label'],\n",
    "                          markerfacecolor=style['color'], markersize=12, alpha=0.8)\n",
    "               for label, style in plot_styles.items() if label in datasets]\n",
    "    fig.legend(handles=handles, loc='upper right', bbox_to_anchor=(0.98, 0.96), fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_plotting(args):\n",
    "    \"\"\"Main function to run the plotting for specified methods.\"\"\"\n",
    "\n",
    "    modalities_map = read_data(\n",
    "        modalities=modalities_list,\n",
    "        splits=['train', 'test'],\n",
    "        data_dir=args.data_dir,\n",
    "        dim=args.dim,\n",
    "    )\n",
    "\n",
    "    all_strategies = {\n",
    "        'multi': MultiModelStrategy('multi', args.results_path, args.dim),\n",
    "        'multi_masked': MultiModelStrategy('multi_masked', args.results_path, args.dim),\n",
    "        'coherent': CoherentStrategy('coherent', args.results_path, args.dim),\n",
    "    }\n",
    "\n",
    "    methods_to_run = args.methods if 'all' not in args.methods else all_strategies.keys()\n",
    "    strategies_to_run = {name: strat for name, strat in all_strategies.items() if name in methods_to_run}\n",
    "\n",
    "    if not strategies_to_run:\n",
    "        print(\"No valid methods selected.\")\n",
    "        return\n",
    "\n",
    "    for method_name, strategy in strategies_to_run.items():\n",
    "        print(f\"\\n{'='*20} Processing Method: {method_name.upper()} {'='*20}\")\n",
    "\n",
    "        real_dfs, uncond_dfs, cond_dfs = [], [], []\n",
    "        \n",
    "        for modality in modalities_list:\n",
    "            print(f\"--- Generating data for modality: {modality} ---\")\n",
    "\n",
    "            test_real_df = modalities_map[modality]['test']\n",
    "            n_samples, n_feats = test_real_df.shape\n",
    "\n",
    "            uncond_gen_df = strategy.generate_unconditional(modality, modalities_map, n_feats, 1)\n",
    "\n",
    "            if uncond_gen_df is None:\n",
    "                print(f\"  Skipping modality {modality} for method {method_name} due to generation failure.\")\n",
    "                continue\n",
    "\n",
    "            cond_datatypes = [m for m in modalities_map.keys() if m != modality]\n",
    "            cond_string = '_'.join(cond_datatypes)\n",
    "            cond_path = strategy.get_base_dir(modality) / 'test' / f'generated_samples_from_{cond_string}_best_{METRIC_TO_USE}.csv'\n",
    "\n",
    "            cond_gen_df = pd.read_csv(cond_path) if cond_path.exists() else None\n",
    "            if cond_gen_df is not None:\n",
    "                cond_gen_df = cond_gen_df.head(n_samples)\n",
    "                cond_dfs.append(cond_gen_df)\n",
    "\n",
    "            real_dfs.append(test_real_df)\n",
    "            uncond_dfs.append(uncond_gen_df)\n",
    "\n",
    "        if not real_dfs:\n",
    "            print(f\"No data was successfully generated for method '{method_name}'. Skipping plot.\")\n",
    "            continue\n",
    "\n",
    "        final_real_df = pd.concat(real_dfs, axis=1)\n",
    "        final_uncond_df = pd.concat(uncond_dfs, axis=1)\n",
    "        final_cond_df = pd.concat(cond_dfs, axis=1) if len(cond_dfs) == len(real_dfs) else None\n",
    "\n",
    "        plot_combined_distributions(\n",
    "            real_df=final_real_df,\n",
    "            uncond_df=final_uncond_df,\n",
    "            cond_df=final_cond_df,\n",
    "            method_name=method_name\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = SimpleNamespace(\n",
    "        dim=32,\n",
    "        results_path='../results',\n",
    "        data_dir='../datasets_TCGA/07_normalized/',\n",
    "        methods=['all']\n",
    "    )\n",
    "    run_plotting(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7035c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from types import SimpleNamespace\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# --- Global Parameters & Setup ---\n",
    "DEVICE = torch.device(f\"cuda:{torch.cuda.current_device()}\" if torch.cuda.is_available() else \"cpu\")\n",
    "METRIC_TO_USE = 'mse'\n",
    "\n",
    "\n",
    "def plot_combined_distributions(real_df, uncond_df, cond_df, method_name):\n",
    "    \"\"\"\n",
    "    Creates and displays a 2x2 embedding plot, fitting PCA/UMAP on real data only\n",
    "    and then transforming all data into that space.\n",
    "    \"\"\"\n",
    "    print(f\"  Generating combined plot for method '{method_name}'...\")\n",
    "\n",
    "    # --- Data Preparation ---\n",
    "    # The 'Real' label will now correspond to the Training Set sample\n",
    "    datasets = {'Training Set': real_df, 'Unconditional': uncond_df}\n",
    "    has_conditional = cond_df is not None\n",
    "    if has_conditional:\n",
    "        datasets['Conditional'] = cond_df\n",
    "\n",
    "    # --- Fit Embeddings ONLY on REAL (Training) data, then transform all ---\n",
    "    print(\"    Fitting PCA and UMAP on REAL (Training) data only...\")\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    pca.fit(real_df)\n",
    "    pca_embeddings = {name: pca.transform(df) for name, df in datasets.items()}\n",
    "\n",
    "    # UMAP\n",
    "    # reducer = umap.UMAP(n_components=2, n_neighbors=30, min_dist=0.1, random_state=42)\n",
    "    reducer = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.5, random_state=42)\n",
    "    reducer.fit(real_df)\n",
    "    umap_embeddings = {name: reducer.transform(df) for name, df in datasets.items()}\n",
    "    print(\"    Transformation complete.\")\n",
    "\n",
    "    # --- Create the 2x2 Plot ---\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 18))\n",
    "    fig.suptitle(f'Generated vs. Training Set Distributions (Method: {method_name.capitalize()})', fontsize=22)\n",
    "\n",
    "    plot_styles = {\n",
    "        'Training Set':  {'color': \"#3a7cac\", 'alpha': 0.9, 's': 6, 'zorder': 1},\n",
    "        'Unconditional': {'color': \"#e01122\", 'alpha': 0.6, 's': 6, 'zorder': 2},\n",
    "        'Conditional':   {'color': \"#f2991b\", 'alpha': 0.6, 's': 6, 'zorder': 2}\n",
    "    }\n",
    "\n",
    "    # Helper function for plotting on a subplot\n",
    "    def plot_on_ax(ax, embedding_dict, labels_to_plot):\n",
    "        for label in labels_to_plot:\n",
    "            if label in embedding_dict:\n",
    "                embedding = embedding_dict[label]\n",
    "                ax.scatter(embedding[:, 0], embedding[:, 1], label=label, **plot_styles[label])\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # --- Populate the subplots ---\n",
    "    axes[0, 0].set_title('PCA: Training Set vs. Unconditional', fontsize=16)\n",
    "    plot_on_ax(axes[0, 0], pca_embeddings, ['Training Set', 'Unconditional'])\n",
    "\n",
    "    axes[0, 1].set_title('PCA: Training Set vs. Conditional', fontsize=16)\n",
    "    if has_conditional:\n",
    "        plot_on_ax(axes[0, 1], pca_embeddings, ['Training Set', 'Conditional'])\n",
    "    else:\n",
    "        axes[0, 1].text(0.5, 0.5, 'Conditional Data\\nNot Available', ha='center', va='center', transform=axes[0, 1].transAxes, alpha=0.5, fontsize=14)\n",
    "        axes[0, 1].tick_params(left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "\n",
    "    axes[1, 0].set_title('UMAP: Training Set vs. Unconditional', fontsize=16)\n",
    "    plot_on_ax(axes[1, 0], umap_embeddings, ['Training Set', 'Unconditional'])\n",
    "\n",
    "    axes[1, 1].set_title('UMAP: Training Set vs. Conditional', fontsize=16)\n",
    "    if has_conditional:\n",
    "        plot_on_ax(axes[1, 1], umap_embeddings, ['Training Set', 'Conditional'])\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'Conditional Data\\nNot Available', ha='center', va='center', transform=axes[1, 1].transAxes, alpha=0.5, fontsize=14)\n",
    "        axes[1, 1].tick_params(left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "\n",
    "    # --- Create a single, unified legend for the figure ---\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color='w', label=label,\n",
    "                          markerfacecolor=style['color'], markersize=12, alpha=0.8)\n",
    "               for label, style in plot_styles.items() if label in datasets]\n",
    "    fig.legend(handles=handles, loc='upper right', bbox_to_anchor=(0.98, 0.96), fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def run_plotting(args):\n",
    "    \"\"\"Main function to run the plotting for specified methods.\"\"\"\n",
    "\n",
    "    modalities_map = read_data(\n",
    "        modalities=modalities_list,\n",
    "        splits=['train', 'test'],\n",
    "        data_dir=args.data_dir,\n",
    "        dim=args.dim,\n",
    "    )\n",
    "\n",
    "    # --- NEW: Pre-process training data to find common, complete samples ---\n",
    "    print(\"Finding common samples with no missing values across all training modalities...\")\n",
    "    all_train_dfs = [modalities_map[modality]['train'] for modality in modalities_list]\n",
    "    combined_train_df = pd.concat(all_train_dfs, axis=1)\n",
    "    \n",
    "    # Drop any row that has a NaN in ANY of the modalities\n",
    "    complete_train_df = combined_train_df.dropna()\n",
    "    print(f\"Found {len(complete_train_df)} complete samples common to all modalities.\")\n",
    "\n",
    "    if complete_train_df.empty:\n",
    "        print(\"Error: No common samples found across all modalities after dropping NaNs. Cannot proceed.\")\n",
    "        return\n",
    "\n",
    "    # Create a new map of the clean, common training data for each modality\n",
    "    complete_train_data_map = {}\n",
    "    start_col = 0\n",
    "    for modality in modalities_list:\n",
    "        num_feats = modalities_map[modality]['train'].shape[1]\n",
    "        modality_df = complete_train_df.iloc[:, start_col : start_col + num_feats]\n",
    "        modality_df.columns = modalities_map[modality]['train'].columns # Restore original column names\n",
    "        complete_train_data_map[modality] = modality_df\n",
    "        start_col += num_feats\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    all_strategies = {\n",
    "        'multi': MultiModelStrategy('multi', args.results_path, args.dim),\n",
    "        'multi_masked': MultiModelStrategy('multi_masked', args.results_path, args.dim),\n",
    "        'coherent': CoherentStrategy('coherent', args.results_path, args.dim),\n",
    "    }\n",
    "\n",
    "    methods_to_run = args.methods if 'all' not in args.methods else all_strategies.keys()\n",
    "    strategies_to_run = {name: strat for name, strat in all_strategies.items() if name in methods_to_run}\n",
    "\n",
    "    if not strategies_to_run:\n",
    "        print(\"No valid methods selected.\")\n",
    "        return\n",
    "\n",
    "    for method_name, strategy in strategies_to_run.items():\n",
    "        print(f\"\\n{'='*20} Processing Method: {method_name.upper()} {'='*20}\")\n",
    "\n",
    "        real_data_for_plotting_dfs, uncond_dfs, cond_dfs = [], [], []\n",
    "\n",
    "        for modality in modalities_list:\n",
    "            print(f\"--- Generating data for modality: {modality} ---\")\n",
    "\n",
    "            test_real_df = modalities_map[modality]['test']\n",
    "            # MODIFIED: Use the pre-cleaned training data\n",
    "            train_real_df = complete_train_data_map[modality]\n",
    "            \n",
    "            n_samples_from_test = len(test_real_df)\n",
    "            \n",
    "            # Ensure we don't try to sample more than we have\n",
    "            n_samples = min(n_samples_from_test, len(train_real_df))\n",
    "            if n_samples < n_samples_from_test:\n",
    "                 print(f\"  Warning: Only {len(train_real_df)} complete training samples available. Using this smaller size for comparison.\")\n",
    "\n",
    "\n",
    "            _, n_feats = test_real_df.shape\n",
    "            uncond_gen_df = strategy.generate_unconditional(modality, modalities_map, n_feats, 1)\n",
    "\n",
    "            if uncond_gen_df is None:\n",
    "                print(f\"  Skipping modality {modality} for method {method_name} due to generation failure.\")\n",
    "                continue\n",
    "\n",
    "            cond_datatypes = [m for m in modalities_map.keys() if m != modality]\n",
    "            cond_string = '_'.join(cond_datatypes)\n",
    "            cond_path = strategy.get_base_dir(modality) / 'test' / f'generated_samples_from_{cond_string}_best_{METRIC_TO_USE}.csv'\n",
    "\n",
    "            cond_gen_df = pd.read_csv(cond_path) if cond_path.exists() else None\n",
    "            if cond_gen_df is not None:\n",
    "                cond_gen_df = cond_gen_df.head(n_samples)\n",
    "                cond_dfs.append(cond_gen_df)\n",
    "\n",
    "            train_sample_df = train_real_df.sample(n=n_samples, random_state=42, replace=False)\n",
    "            real_data_for_plotting_dfs.append(train_sample_df)\n",
    "            uncond_dfs.append(uncond_gen_df.head(n_samples))\n",
    "\n",
    "        if not real_data_for_plotting_dfs:\n",
    "            print(f\"No data was successfully generated for method '{method_name}'. Skipping plot.\")\n",
    "            continue\n",
    "\n",
    "        final_real_df_for_plot = pd.concat(real_data_for_plotting_dfs, axis=1)\n",
    "        final_uncond_df = pd.concat(uncond_dfs, axis=1)\n",
    "        final_cond_df = pd.concat(cond_dfs, axis=1) if len(cond_dfs) == len(real_data_for_plotting_dfs) else None\n",
    "\n",
    "        plot_combined_distributions(\n",
    "            real_df=final_real_df_for_plot,\n",
    "            uncond_df=final_uncond_df,\n",
    "            cond_df=final_cond_df,\n",
    "            method_name=method_name\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = SimpleNamespace(\n",
    "        dim=32,\n",
    "        results_path='../results',\n",
    "        data_dir='../datasets_TCGA/07_normalized/',\n",
    "        methods=['all']\n",
    "    )\n",
    "    run_plotting(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cb46f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bc66d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d800b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd2e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735cc151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from types import SimpleNamespace\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import torch\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# Assuming lib functions are in your PYTHONPATH\n",
    "from lib.test import coherent_test_cos_rejection, test_model\n",
    "from lib.config import modalities_list\n",
    "from lib.read_data import read_data\n",
    "from lib.get_models import get_diffusion_model\n",
    "from lib.diffusion_models import GaussianDiffusion\n",
    "\n",
    "# =============================================================================\n",
    "# 1. STRATEGY CLASSES (WITH CORRECTED SIGNATURES)\n",
    "# =============================================================================\n",
    "\n",
    "class EvaluationStrategy(ABC):\n",
    "    \"\"\"Abstract base class for an evaluation strategy.\"\"\"\n",
    "    def __init__(self, method_name, results_path, dim):\n",
    "        self.method_name = method_name\n",
    "        self.results_path = results_path\n",
    "        self.dim = dim\n",
    "\n",
    "    def get_base_dir(self, modality):\n",
    "        return pathlib.Path(f\"{self.results_path}/{self.dim}/{modality}_from_{self.method_name}\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def generate_unconditional(self, modality, modalities_map, n_feats, test_repeats):\n",
    "        \"\"\"Generates unconditional samples for a given modality.\"\"\"\n",
    "        pass\n",
    "\n",
    "class MultiModelStrategy(EvaluationStrategy):\n",
    "    \"\"\"Strategy for 'multi' and 'multi_masked' models.\"\"\"\n",
    "    def generate_unconditional(self, modality, modalities_map, n_feats, test_repeats):\n",
    "        print(f\"  Generating unconditional samples using '{self.method_name}' for '{modality}'...\")\n",
    "        base_dir = self.get_base_dir(modality)\n",
    "        ckpt_path = base_dir / 'train' / 'best_by_mse.pth'\n",
    "        if not ckpt_path.exists():\n",
    "            print(f\"  WARNING: Checkpoint not found at {ckpt_path}. Skipping.\")\n",
    "            return None\n",
    "\n",
    "        ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "        config = SimpleNamespace(**ckpt['config'])\n",
    "        \n",
    "        cond_datatypes = [m for m in modalities_map.keys() if m != modality]\n",
    "        cond_dim_list = [modalities_map[c]['test'].shape[1] for c in cond_datatypes]\n",
    "\n",
    "        diffusion = GaussianDiffusion(num_timesteps=1000).to(DEVICE)\n",
    "        \n",
    "        # --- THE FIX: Use n_feats passed from the main loop ---\n",
    "        model = get_diffusion_model(\n",
    "            config.architecture, diffusion, config,\n",
    "            x_dim=n_feats, \n",
    "            cond_dims=cond_dim_list\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        model.load_state_dict(ckpt['best_model_mse'])\n",
    "        model.eval()\n",
    "\n",
    "        n_samples = len(modalities_map[modality]['test'])\n",
    "        zero_conds = [pd.DataFrame(np.zeros_like(modalities_map[c]['test'])) for c in cond_datatypes]\n",
    "        masks = [np.zeros(n_samples) for _ in cond_datatypes]\n",
    "        \n",
    "        _, uncond_data = test_model(\n",
    "            modalities_map[modality]['test'], zero_conds, model, diffusion,\n",
    "            test_iterations=test_repeats, device=DEVICE, masks=masks\n",
    "        )\n",
    "        return uncond_data.iloc[:n_samples]\n",
    "\n",
    "class CoherentStrategy(EvaluationStrategy):\n",
    "    \"\"\"Strategy for the 'coherent' ensemble model.\"\"\"\n",
    "    def generate_unconditional(self, modality, modalities_map, n_feats, test_repeats):\n",
    "        print(f\"  Generating unconditional samples using 'coherent' for '{modality}'...\")\n",
    "        cond_datatypes = [m for m in modalities_map.keys() if m != modality]\n",
    "        diffusion = GaussianDiffusion(num_timesteps=1000).to(DEVICE)\n",
    "\n",
    "        models, weights, zero_conds = [], [], []\n",
    "        for c in cond_datatypes:\n",
    "            ckpt_path = pathlib.Path(f\"{self.results_path}/{self.dim}/{modality}_from_{c}/train/best_by_mse.pth\")\n",
    "            if not ckpt_path.exists():\n",
    "                print(f\"  WARNING: Coherent dependency not found at {ckpt_path}. Skipping.\")\n",
    "                return None\n",
    "\n",
    "            ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "            config_c = SimpleNamespace(**ckpt['config'])\n",
    "            \n",
    "            # --- THE FIX: Use n_feats passed from the main loop ---\n",
    "            model_c = get_diffusion_model(\n",
    "                config_c.architecture, diffusion, config_c,\n",
    "                x_dim=n_feats, \n",
    "                cond_dims=modalities_map[c]['test'].shape[1]\n",
    "            ).to(DEVICE)\n",
    "            \n",
    "            model_c.load_state_dict(ckpt['best_model_mse'])\n",
    "            model_c.eval()\n",
    "            models.append(model_c)\n",
    "            weights.append(ckpt['best_loss'])\n",
    "            zero_conds.append(pd.DataFrame(np.zeros_like(modalities_map[c]['test'])))\n",
    "\n",
    "        _, uncond_data, _ = coherent_test_cos_rejection(\n",
    "            modalities_map[modality]['test'], zero_conds, models, diffusion,\n",
    "            test_iterations=test_repeats, max_retries=10, device=DEVICE, weights_list=weights\n",
    "        )\n",
    "        n_samples = len(modalities_map[modality]['test'])\n",
    "        return uncond_data.iloc[:n_samples]\n",
    "\n",
    "# =============================================================================\n",
    "# 2. PLOTTING FUNCTION (No changes needed here)\n",
    "# =============================================================================\n",
    "def plot_unconditional_comparison(train_df, uncond_coherent_df, uncond_multi_df, save_path=None):\n",
    "    # This function is correct and remains the same as the last working version\n",
    "    print(\"\\n>>> Generating final 2-panel UMAP plot...\")\n",
    "    plt.style.use('seaborn-v0_8-white')\n",
    "    # ... (rest of the plotting function is omitted for brevity but is unchanged) ...\n",
    "    plot_styles = {\n",
    "        'Training Set': {'color': '#0072b2', 'alpha': 0.7, 's': 10, 'label': 'Training Set'},\n",
    "        'Generated':    {'color': '#e66000', 'alpha': 0.7, 's': 10, 'label': 'Generated Unconditional'}\n",
    "    }\n",
    "    print(\"  Fitting UMAP on training data...\")\n",
    "    reducer = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.8, spread=2.0, random_state=42)\n",
    "    train_emb = reducer.fit_transform(train_df)\n",
    "    coherent_emb = reducer.transform(uncond_coherent_df)\n",
    "    multi_emb = reducer.transform(uncond_multi_df)\n",
    "    print(\"  Transformation complete.\")\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    fig.suptitle('UMAP: Training Set vs. Unconditional Generation', fontsize=22, weight='bold')\n",
    "    all_x = np.concatenate([train_emb[:, 0], coherent_emb[:, 0], multi_emb[:, 0]])\n",
    "    all_y = np.concatenate([train_emb[:, 1], coherent_emb[:, 1], multi_emb[:, 1]])\n",
    "    x_range = all_x.max() - all_x.min()\n",
    "    y_range = all_y.max() - all_y.min()\n",
    "    max_range = max(x_range, y_range) * 1.1\n",
    "    x_center = (all_x.max() + all_x.min()) / 2\n",
    "    y_center = (all_y.max() + all_y.min()) / 2\n",
    "    xlims = (x_center - max_range / 2, x_center + max_range / 2)\n",
    "    ylims = (y_center - max_range / 2, y_center + max_range / 2)\n",
    "    axes[0].scatter(train_emb[:, 0], train_emb[:, 1], **plot_styles['Training Set'])\n",
    "    axes[0].scatter(coherent_emb[:, 0], coherent_emb[:, 1], **plot_styles['Generated'])\n",
    "    axes[0].set_title(\"Coherent Denoising\", fontsize=16, pad=15)\n",
    "    axes[1].scatter(train_emb[:, 0], train_emb[:, 1], **plot_styles['Training Set'])\n",
    "    axes[1].scatter(multi_emb[:, 0], multi_emb[:, 1], **plot_styles['Generated'])\n",
    "    axes[1].set_title(\"Multi-Condition\", fontsize=16, pad=15)\n",
    "    for ax in axes:\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        ax.set_xlim(*xlims)\n",
    "        ax.set_ylim(*ylims)\n",
    "        ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "        ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_color('#B0B0B0')\n",
    "        ax.tick_params(axis='both', colors='#505050')\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color='w', label=style['label'],\n",
    "                          markerfacecolor=style['color'], markersize=12, alpha=0.8)\n",
    "               for _, style in plot_styles.items()]\n",
    "    fig.legend(handles=handles, loc='center left', bbox_to_anchor=(0.98, 0.5), fontsize=14)\n",
    "    fig.tight_layout(rect=[0, 0, 0.90, 0.95])\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"   -> Plot saved to {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 3. MAIN SCRIPT LOGIC (WITH CORRECTED PARAMETER PASSING)\n",
    "# =============================================================================\n",
    "\n",
    "def run_analysis_and_plotting(args):\n",
    "    \"\"\"Main function to gather data and run the unconditional comparison plotting.\"\"\"\n",
    "\n",
    "    modalities_map = read_data(\n",
    "        modalities=modalities_list,\n",
    "        splits=['train', 'test'],\n",
    "        data_dir=args.data_dir,\n",
    "        dim=args.dim,\n",
    "    )\n",
    "\n",
    "    print(\"Finding common samples with no missing values across all training modalities...\")\n",
    "    all_train_dfs = [modalities_map[modality]['train'] for modality in modalities_list]\n",
    "    combined_train_df = pd.concat(all_train_dfs, axis=1)\n",
    "    complete_train_df = combined_train_df.dropna()\n",
    "    \n",
    "    n_samples = len(complete_train_df)\n",
    "    print(f\"Found {n_samples} complete samples common to all modalities.\")\n",
    "\n",
    "    if complete_train_df.empty:\n",
    "        print(\"Error: No common samples found. Cannot proceed.\")\n",
    "        return\n",
    "\n",
    "    uncond_coherent_dfs, uncond_multi_dfs = [], []\n",
    "    \n",
    "    coherent_strategy = CoherentStrategy('coherent', args.results_path, args.dim)\n",
    "    multi_strategy = MultiModelStrategy('multi', args.results_path, args.dim)\n",
    "\n",
    "    for modality in modalities_list:\n",
    "        print(f\"\\n--- Processing modality: {modality} ---\")\n",
    "        \n",
    "        # --- THE FIX: Calculate n_feats for the current modality ---\n",
    "        n_feats = modalities_map[modality]['train'].shape[1]\n",
    "        \n",
    "        # --- THE FIX: Pass n_feats to the generation method ---\n",
    "        coherent_df = coherent_strategy.generate_unconditional(modality, modalities_map, n_feats, 1)\n",
    "        if coherent_df is None: \n",
    "            print(f\"Fatal: Could not generate Coherent data for {modality}. Aborting.\"); return\n",
    "        uncond_coherent_dfs.append(coherent_df.head(n_samples))\n",
    "        \n",
    "        # --- THE FIX: Pass n_feats to the generation method ---\n",
    "        multi_df = multi_strategy.generate_unconditional(modality, modalities_map, n_feats, 1)\n",
    "        if multi_df is None: \n",
    "            print(f\"Fatal: Could not generate Multi data for {modality}. Aborting.\"); return\n",
    "        uncond_multi_dfs.append(multi_df.head(n_samples))\n",
    "\n",
    "    # --- Concatenate all modalities for the final plot dataframes ---\n",
    "    final_train_df = complete_train_df\n",
    "    final_uncond_coherent_df = pd.concat(uncond_coherent_dfs, axis=1)\n",
    "    final_uncond_multi_df = pd.concat(uncond_multi_dfs, axis=1)\n",
    "\n",
    "    plot_unconditional_comparison(\n",
    "        train_df=final_train_df,\n",
    "        uncond_coherent_df=final_uncond_coherent_df,\n",
    "        uncond_multi_df=final_uncond_multi_df,\n",
    "        save_path=os.path.join(args.results_path, 'images/unconditional_umap_comparison.png')\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    DEVICE = torch.device(f\"cuda:{torch.cuda.current_device()}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    METRIC_TO_USE = 'mse'\n",
    "\n",
    "    args = SimpleNamespace(\n",
    "        dim=32,\n",
    "        results_path='../results',\n",
    "        data_dir='../datasets_TCGA/07_normalized/',\n",
    "    )\n",
    "    run_analysis_and_plotting(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c466a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from types import SimpleNamespace\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import torch\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# Assuming these are available in your PYTHONPATH\n",
    "from lib.test import coherent_test_cos_rejection, test_model\n",
    "from lib.config import modalities_list\n",
    "from lib.read_data import read_data\n",
    "from lib.get_models import get_diffusion_model\n",
    "from lib.diffusion_models import GaussianDiffusion\n",
    "\n",
    "# =============================================================================\n",
    "# 1. STRATEGY CLASSES (FROM YOUR WORKING SCRIPT)\n",
    "# =============================================================================\n",
    "\n",
    "class EvaluationStrategy(ABC):\n",
    "    \"\"\"Abstract base class for an evaluation strategy.\"\"\"\n",
    "    def __init__(self, method_name, results_path, dim):\n",
    "        self.method_name = method_name\n",
    "        self.results_path = results_path\n",
    "        self.dim = dim\n",
    "\n",
    "    def get_base_dir(self, modality):\n",
    "        return pathlib.Path(f\"{self.results_path}/{self.dim}/{modality}_from_{self.method_name}\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def generate_unconditional(self, modality, modalities_map, n_feats, test_repeats):\n",
    "        \"\"\"Generates unconditional samples for a given modality.\"\"\"\n",
    "        pass\n",
    "\n",
    "class MultiModelStrategy(EvaluationStrategy):\n",
    "    \"\"\"Strategy for 'multi' and 'multi_masked' models.\"\"\"\n",
    "    def generate_unconditional(self, modality, modalities_map, n_feats, test_repeats):\n",
    "        print(f\"  Generating unconditional samples using '{self.method_name}' for '{modality}'...\")\n",
    "        base_dir = self.get_base_dir(modality)\n",
    "        ckpt_path = base_dir / 'train' / 'best_by_mse.pth'\n",
    "        if not ckpt_path.exists():\n",
    "            print(f\"  ERROR: Checkpoint not found at {ckpt_path}. Cannot generate data.\")\n",
    "            return None\n",
    "\n",
    "        ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "        config = SimpleNamespace(**ckpt['config'])\n",
    "        \n",
    "        cond_datatypes = [m for m in modalities_map.keys() if m != modality]\n",
    "        cond_dim_list = [modalities_map[c]['test'].shape[1] for c in cond_datatypes]\n",
    "\n",
    "        diffusion = GaussianDiffusion(num_timesteps=1000).to(DEVICE)\n",
    "        \n",
    "        # This uses the feature dimensions calculated from the data, as you clarified\n",
    "        model = get_diffusion_model(\n",
    "            config.architecture, diffusion, config,\n",
    "            x_dim=n_feats, cond_dims=cond_dim_list\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        model.load_state_dict(ckpt['best_model_mse'])\n",
    "        model.eval()\n",
    "\n",
    "        n_samples = len(modalities_map[modality]['test'])\n",
    "        zero_conds = [pd.DataFrame(np.zeros_like(modalities_map[c]['test'])) for c in cond_datatypes]\n",
    "        masks = [np.zeros(n_samples) for _ in cond_datatypes]\n",
    "        \n",
    "        _, uncond_data = test_model(\n",
    "            modalities_map[modality]['test'], zero_conds, model, diffusion,\n",
    "            test_iterations=test_repeats, device=DEVICE, masks=masks\n",
    "        )\n",
    "        return uncond_data.iloc[:n_samples]\n",
    "\n",
    "class CoherentStrategy(EvaluationStrategy):\n",
    "    \"\"\"Strategy for the 'coherent' ensemble model.\"\"\"\n",
    "    def generate_unconditional(self, modality, modalities_map, n_feats, test_repeats):\n",
    "        print(f\"  Generating unconditional samples using 'coherent' for '{modality}'...\")\n",
    "        cond_datatypes = [m for m in modalities_map.keys() if m != modality]\n",
    "        diffusion = GaussianDiffusion(num_timesteps=1000).to(DEVICE)\n",
    "\n",
    "        models, weights, zero_conds = [], [], []\n",
    "        for c in cond_datatypes:\n",
    "            ckpt_path = pathlib.Path(f\"{self.results_path}/{self.dim}/{modality}_from_{c}/train/best_by_mse.pth\")\n",
    "            if not ckpt_path.exists():\n",
    "                print(f\"  ERROR: Coherent dependency not found at {ckpt_path}. Cannot generate data.\")\n",
    "                return None\n",
    "\n",
    "            ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "            config_c = SimpleNamespace(**ckpt['config'])\n",
    "            \n",
    "            model_c = get_diffusion_model(\n",
    "                config_c.architecture, diffusion, config_c,\n",
    "                x_dim=n_feats, \n",
    "                cond_dims=modalities_map[c]['test'].shape[1]\n",
    "            ).to(DEVICE)\n",
    "            \n",
    "            model_c.load_state_dict(ckpt['best_model_mse'])\n",
    "            model_c.eval()\n",
    "            models.append(model_c)\n",
    "            weights.append(ckpt['best_loss'])\n",
    "            zero_conds.append(pd.DataFrame(np.zeros_like(modalities_map[c]['test'])))\n",
    "\n",
    "        _, uncond_data, _ = coherent_test_cos_rejection(\n",
    "            modalities_map[modality]['test'], zero_conds, models, diffusion,\n",
    "            test_iterations=test_repeats, max_retries=10, device=DEVICE, weights_list=weights\n",
    "        )\n",
    "        n_samples = len(modalities_map[modality]['test'])\n",
    "        return uncond_data.iloc[:n_samples]\n",
    "\n",
    "# =============================================================================\n",
    "# 2. PLOTTING FUNCTION (Unchanged)\n",
    "# =============================================================================\n",
    "\n",
    "def plot_unconditional_comparison(train_df, coherent_df, multi_df, save_path=None):\n",
    "    \"\"\"\n",
    "    Generates a 2-panel UMAP plot comparing train vs. coherent and train vs. multi,\n",
    "    with a polished, paper-ready aesthetic.\n",
    "    \"\"\"\n",
    "    print(\"\\n>>> Generating final 2-panel UMAP plot...\")\n",
    "    plt.style.use('seaborn-v0_8-white')\n",
    "    plot_styles = {\n",
    "        'Training Set':      {'color': \"#c59b7d\", 'alpha': 0.6, 's': 10, 'label': 'Training Set'},\n",
    "        'Coherent Denoising': {'color': '#56b4e9', 'alpha': 0.9, 's': 10, 'label': 'Generated (Coherent Denoising)'},\n",
    "        'Multi-Condition':   {'color': '#0072b2', 'alpha': 0.9, 's': 10, 'label': 'Generated (Multi-condition)'}\n",
    "    }\n",
    "\n",
    "    print(\"  Fitting UMAP on training data and transforming all sets...\")\n",
    "    mapper = umap.UMAP(n_neighbors=15, min_dist=0.8, spread=2, n_components=2, random_state=23)\n",
    "    train_emb = mapper.fit_transform(train_df.values)\n",
    "    \n",
    "    n_train = train_df.shape[0]\n",
    "    coherent_emb = mapper.transform(coherent_df.iloc[:n_train].values)\n",
    "    multi_emb = mapper.transform(multi_df.iloc[:n_train].values)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    fig.suptitle(\"UMAP Comparison: Training Data vs. Unconditional Generation\", fontsize=28, weight='bold', y=0.98)\n",
    "\n",
    "    all_x = np.concatenate([train_emb[:, 0], coherent_emb[:, 0], multi_emb[:, 0]])\n",
    "    all_y = np.concatenate([train_emb[:, 1], coherent_emb[:, 1], multi_emb[:, 1]])\n",
    "    \n",
    "    x_range = all_x.max() - all_x.min()\n",
    "    y_range = all_y.max() - all_y.min()\n",
    "    max_range = max(x_range, y_range) * 1.05\n",
    "    \n",
    "    x_center = (all_x.max() + all_x.min()) / 2\n",
    "    y_center = (all_y.max() + all_y.min()) / 2\n",
    "    \n",
    "    xlims = (x_center - max_range / 2, x_center + max_range / 2)\n",
    "    ylims = (y_center - max_range / 2, y_center + max_range / 2)\n",
    "    \n",
    "    # Panel 1: Train vs Coherent\n",
    "    axs[0].scatter(train_emb[:, 0], train_emb[:, 1], **plot_styles['Training Set'])\n",
    "    axs[0].scatter(coherent_emb[:, 0], coherent_emb[:, 1], **plot_styles['Coherent Denoising'])\n",
    "    axs[0].set_title('Unconditional Coherent Denoising Generation', fontsize=22, weight='bold', pad=20)\n",
    "\n",
    "    # Panel 2: Train vs Multi\n",
    "    axs[1].scatter(train_emb[:, 0], train_emb[:, 1], **plot_styles['Training Set'])\n",
    "    axs[1].scatter(multi_emb[:, 0], multi_emb[:, 1], **plot_styles['Multi-Condition'])\n",
    "    axs[1].set_title('Unconditional Multi-Condition Generation', fontsize=22, weight='bold', pad=20)\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlim(*xlims)\n",
    "        ax.set_ylim(*ylims)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        ax.set_xlabel('UMAP 1', fontsize=12, labelpad=5, color='#303030')\n",
    "        ax.set_ylabel('UMAP 2', fontsize=12, labelpad=5, color='#303030')\n",
    "        ax.tick_params(axis='both', colors='#505050')\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_color('#B0B0B0')\n",
    "        #ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    legend_elems = [plt.Line2D([0], [0], marker='o', color='w',\n",
    "                               markerfacecolor=style['color'], markersize=16,\n",
    "                               label=style['label']) for style in plot_styles.values()]\n",
    "\n",
    "    fig.legend(handles=legend_elems, loc='center left', bbox_to_anchor=(0.96, 0.5),\n",
    "               frameon=False, title='Data Origin', fontsize=16, title_fontsize=18)\n",
    "\n",
    "    fig.subplots_adjust(left=0.05, right=0.98, bottom=0.05, top=0.85, wspace=0.15)\n",
    "    \n",
    "\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 3. MAIN SCRIPT LOGIC\n",
    "# =============================================================================\n",
    "\n",
    "def run_generation_and_plotting(args):\n",
    "    \"\"\"Main function to generate data and then create the comparison plot.\"\"\"\n",
    "\n",
    "    modalities_map = read_data(\n",
    "        modalities=modalities_list,\n",
    "        splits=['train', 'test'],\n",
    "        data_dir=args.data_dir,\n",
    "        dim=args.dim,\n",
    "    )\n",
    "\n",
    "    print(\">>> Finding common samples with no missing values across all training modalities...\")\n",
    "    all_train_dfs = [modalities_map[modality]['train'] for modality in modalities_list]\n",
    "    train_all_raw = pd.concat(all_train_dfs, axis=1)\n",
    "    train_all_complete = train_all_raw.dropna()\n",
    "    n_samples_to_use = len(train_all_complete)\n",
    "    print(f\"Found {n_samples_to_use} complete training samples.\")\n",
    "\n",
    "    if train_all_complete.empty:\n",
    "        print(\"Error: No common samples found. Cannot proceed.\")\n",
    "        return\n",
    "\n",
    "    # --- Generate data from both Coherent and Multi methods ---\n",
    "    print(\"\\n>>> Starting data generation for all modalities...\")\n",
    "    uncond_coherent_dfs, uncond_multi_dfs = [], []\n",
    "    \n",
    "    coherent_strategy = CoherentStrategy('coherent', args.results_path, args.dim)\n",
    "    multi_strategy = MultiModelStrategy('multi', args.results_path, args.dim)\n",
    "\n",
    "    for modality in modalities_list:\n",
    "        n_feats = modalities_map[modality]['train'].shape[1]\n",
    "        \n",
    "        coherent_df = coherent_strategy.generate_unconditional(modality, modalities_map, n_feats, 1)\n",
    "        if coherent_df is None: \n",
    "            print(f\"FATAL: Could not generate Coherent data for {modality}. Aborting.\"); return\n",
    "        uncond_coherent_dfs.append(coherent_df.head(n_samples_to_use))\n",
    "        \n",
    "        multi_df = multi_strategy.generate_unconditional(modality, modalities_map, n_feats, 1)\n",
    "        if multi_df is None: \n",
    "            print(f\"FATAL: Could not generate Multi data for {modality}. Aborting.\"); return\n",
    "        uncond_multi_dfs.append(multi_df.head(n_samples_to_use))\n",
    "\n",
    "    # --- Concatenate all modalities for the final plot dataframes ---\n",
    "    final_uncond_coherent_df = pd.concat(uncond_coherent_dfs, axis=1)\n",
    "    final_uncond_multi_df = pd.concat(uncond_multi_dfs, axis=1)\n",
    "\n",
    "    # --- Call the plotting function ---\n",
    "    plot_unconditional_comparison(\n",
    "        train_df=train_all_complete,\n",
    "        coherent_df=final_uncond_coherent_df,\n",
    "        multi_df=final_uncond_multi_df,\n",
    "        save_path=os.path.join(args.results_path, 'images', 'umap_train_vs_uncond_comparison.png')\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Global Parameters & Setup ---\n",
    "    DEVICE = torch.device(f\"cuda:{torch.cuda.current_device()}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    METRIC_TO_USE = 'mse'\n",
    "\n",
    "    args = SimpleNamespace(\n",
    "        dim=32,\n",
    "        results_path='../results',\n",
    "        data_dir='../datasets_TCGA/07_normalized/',\n",
    "    )\n",
    "    run_generation_and_plotting(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba8aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from types import SimpleNamespace\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA  # <-- IMPORT PCA\n",
    "import torch\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# Assuming these are available in your PYTHONPATH\n",
    "from lib.test import coherent_test_cos_rejection, test_model\n",
    "from lib.config import modalities_list\n",
    "from lib.read_data import read_data\n",
    "from lib.get_models import get_diffusion_model\n",
    "from lib.diffusion_models import GaussianDiffusion\n",
    "\n",
    "# =============================================================================\n",
    "# 1. STRATEGY CLASSES (Unchanged)\n",
    "# =============================================================================\n",
    "\n",
    "class EvaluationStrategy(ABC):\n",
    "    \"\"\"Abstract base class for an evaluation strategy.\"\"\"\n",
    "    def __init__(self, method_name, results_path, dim):\n",
    "        self.method_name = method_name\n",
    "        self.results_path = results_path\n",
    "        self.dim = dim\n",
    "\n",
    "    def get_base_dir(self, modality):\n",
    "        return pathlib.Path(f\"{self.results_path}/{self.dim}/{modality}_from_{self.method_name}\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def generate_unconditional(self, modality, modalities_map, n_feats, test_repeats):\n",
    "        pass\n",
    "\n",
    "class MultiModelStrategy(EvaluationStrategy):\n",
    "    \"\"\"Strategy for 'multi' and 'multi_masked' models.\"\"\"\n",
    "    def generate_unconditional(self, modality, modalities_map, n_feats, test_repeats):\n",
    "        print(f\"  Generating unconditional samples using '{self.method_name}' for '{modality}'...\")\n",
    "        base_dir = self.get_base_dir(modality)\n",
    "        ckpt_path = base_dir / 'train' / 'best_by_mse.pth'\n",
    "        if not ckpt_path.exists():\n",
    "            print(f\"  ERROR: Checkpoint not found at {ckpt_path}. Cannot generate data.\")\n",
    "            return None\n",
    "\n",
    "        ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "        config = SimpleNamespace(**ckpt['config'])\n",
    "        \n",
    "        cond_datatypes = [m for m in modalities_map.keys() if m != modality]\n",
    "        cond_dim_list = [modalities_map[c]['test'].shape[1] for c in cond_datatypes]\n",
    "\n",
    "        diffusion = GaussianDiffusion(num_timesteps=1000).to(DEVICE)\n",
    "        \n",
    "        model = get_diffusion_model(\n",
    "            config.architecture, diffusion, config,\n",
    "            x_dim=n_feats, cond_dims=cond_dim_list\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        model.load_state_dict(ckpt['best_model_mse'])\n",
    "        model.eval()\n",
    "\n",
    "        n_samples = len(modalities_map[modality]['test'])\n",
    "        zero_conds = [pd.DataFrame(np.zeros_like(modalities_map[c]['test'])) for c in cond_datatypes]\n",
    "        masks = [np.zeros(n_samples) for _ in cond_datatypes]\n",
    "        \n",
    "        _, uncond_data = test_model(\n",
    "            modalities_map[modality]['test'], zero_conds, model, diffusion,\n",
    "            test_iterations=test_repeats, device=DEVICE, masks=masks\n",
    "        )\n",
    "        return uncond_data.iloc[:n_samples]\n",
    "\n",
    "class CoherentStrategy(EvaluationStrategy):\n",
    "    \"\"\"Strategy for the 'coherent' ensemble model.\"\"\"\n",
    "    def generate_unconditional(self, modality, modalities_map, n_feats, test_repeats):\n",
    "        print(f\"  Generating unconditional samples using 'coherent' for '{modality}'...\")\n",
    "        cond_datatypes = [m for m in modalities_map.keys() if m != modality]\n",
    "        diffusion = GaussianDiffusion(num_timesteps=1000).to(DEVICE)\n",
    "\n",
    "        models, weights, zero_conds = [], [], []\n",
    "        for c in cond_datatypes:\n",
    "            ckpt_path = pathlib.Path(f\"{self.results_path}/{self.dim}/{modality}_from_{c}/train/best_by_mse.pth\")\n",
    "            if not ckpt_path.exists():\n",
    "                print(f\"  ERROR: Coherent dependency not found at {ckpt_path}. Cannot generate data.\")\n",
    "                return None\n",
    "\n",
    "            ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "            config_c = SimpleNamespace(**ckpt['config'])\n",
    "            \n",
    "            model_c = get_diffusion_model(\n",
    "                config_c.architecture, diffusion, config_c,\n",
    "                x_dim=n_feats, \n",
    "                cond_dims=modalities_map[c]['test'].shape[1]\n",
    "            ).to(DEVICE)\n",
    "            \n",
    "            model_c.load_state_dict(ckpt['best_model_mse'])\n",
    "            model_c.eval()\n",
    "            models.append(model_c)\n",
    "            weights.append(ckpt['best_loss'])\n",
    "            zero_conds.append(pd.DataFrame(np.zeros_like(modalities_map[c]['test'])))\n",
    "\n",
    "        _, uncond_data, _ = coherent_test_cos_rejection(\n",
    "            modalities_map[modality]['test'], zero_conds, models, diffusion,\n",
    "            test_iterations=test_repeats, max_retries=10, device=DEVICE, weights_list=weights\n",
    "        )\n",
    "        n_samples = len(modalities_map[modality]['test'])\n",
    "        return uncond_data.iloc[:n_samples]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. NEW PLOTTING FUNCTION FOR PCA\n",
    "# =============================================================================\n",
    "\n",
    "def plot_unconditional_pca_comparison(train_df, coherent_df, multi_df, save_path=None):\n",
    "    \"\"\"\n",
    "    Generates a 2-panel PCA plot comparing train vs. coherent and train vs. multi,\n",
    "    with a polished, paper-ready aesthetic.\n",
    "    \"\"\"\n",
    "    print(\"\\n>>> Generating final 2-panel PCA plot...\")\n",
    "    plt.style.use('seaborn-v0_8-white')\n",
    "    plot_styles = {\n",
    "        'Training Set':       {'color': \"#c59b7d\", 'alpha': 0.6, 's': 10, 'label': 'Training Set'},\n",
    "        'Coherent Denoising': {'color': '#56b4e9', 'alpha': 0.9, 's': 10, 'label': 'Generated (Coherent Denoising)'},\n",
    "        'Multi-Condition':    {'color': '#0072b2', 'alpha': 0.9, 's': 10, 'label': 'Generated (Multi-condition)'}\n",
    "    }\n",
    "\n",
    "    # --- MODIFIED: Use PCA instead of UMAP ---\n",
    "    print(\"  Fitting PCA on training data and transforming all sets...\")\n",
    "    reducer = PCA(n_components=2, random_state=42)\n",
    "    train_emb = reducer.fit_transform(train_df.values)\n",
    "    \n",
    "    n_train = train_df.shape[0]\n",
    "    coherent_emb = reducer.transform(coherent_df.iloc[:n_train].values)\n",
    "    multi_emb = reducer.transform(multi_df.iloc[:n_train].values)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    # MODIFIED: Title\n",
    "    fig.suptitle(\"PCA Comparison: Training Data vs. Unconditional Generation\", fontsize=28, weight='bold', y=0.98)\n",
    "\n",
    "    all_x = np.concatenate([train_emb[:, 0], coherent_emb[:, 0], multi_emb[:, 0]])\n",
    "    all_y = np.concatenate([train_emb[:, 1], coherent_emb[:, 1], multi_emb[:, 1]])\n",
    "    \n",
    "    x_range = all_x.max() - all_x.min()\n",
    "    y_range = all_y.max() - all_y.min()\n",
    "    max_range = max(x_range, y_range) * 1.05\n",
    "    \n",
    "    x_center = (all_x.max() + all_x.min()) / 2\n",
    "    y_center = (all_y.max() + all_y.min()) / 2\n",
    "    \n",
    "    xlims = (x_center - max_range / 2, x_center + max_range / 2)\n",
    "    ylims = (y_center - max_range / 2, y_center + max_range / 2)\n",
    "    \n",
    "    # Panel 1: Train vs Coherent\n",
    "    axs[0].scatter(train_emb[:, 0], train_emb[:, 1], **plot_styles['Training Set'])\n",
    "    axs[0].scatter(coherent_emb[:, 0], coherent_emb[:, 1], **plot_styles['Coherent Denoising'])\n",
    "    axs[0].set_title('Unconditional Coherent Denoising Generation', fontsize=22, weight='bold', pad=20)\n",
    "\n",
    "    # Panel 2: Train vs Multi\n",
    "    axs[1].scatter(train_emb[:, 0], train_emb[:, 1], **plot_styles['Training Set'])\n",
    "    axs[1].scatter(multi_emb[:, 0], multi_emb[:, 1], **plot_styles['Multi-Condition'])\n",
    "    axs[1].set_title('Unconditional Multi-Condition Generation', fontsize=22, weight='bold', pad=20)\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlim(*xlims)\n",
    "        ax.set_ylim(*ylims)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        # MODIFIED: Axis labels\n",
    "        ax.set_xlabel('Principal Component 1', fontsize=12, labelpad=5, color='#303030')\n",
    "        ax.set_ylabel('Principal Component 2', fontsize=12, labelpad=5, color='#303030')\n",
    "        ax.tick_params(axis='both', colors='#505050')\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_color('#B0B0B0')\n",
    "\n",
    "    legend_elems = [plt.Line2D([0], [0], marker='o', color='w',\n",
    "                               markerfacecolor=style['color'], markersize=16,\n",
    "                               label=style['label']) for style in plot_styles.values()]\n",
    "\n",
    "    fig.legend(handles=legend_elems, loc='center left', bbox_to_anchor=(0.96, 0.5),\n",
    "               frameon=False, title='Data Origin', fontsize=16, title_fontsize=18)\n",
    "\n",
    "    fig.subplots_adjust(left=0.05, right=0.98, bottom=0.05, top=0.85, wspace=0.15)\n",
    "    \n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 3. MAIN SCRIPT LOGIC\n",
    "# =============================================================================\n",
    "\n",
    "def run_generation_and_plotting(args):\n",
    "    \"\"\"Main function to generate data and then create the comparison plot.\"\"\"\n",
    "\n",
    "    modalities_map = read_data(\n",
    "        modalities=modalities_list,\n",
    "        splits=['train', 'test'],\n",
    "        data_dir=args.data_dir,\n",
    "        dim=args.dim,\n",
    "    )\n",
    "\n",
    "    print(\">>> Finding common samples with no missing values across all training modalities...\")\n",
    "    all_train_dfs = [modalities_map[modality]['train'] for modality in modalities_list]\n",
    "    train_all_raw = pd.concat(all_train_dfs, axis=1)\n",
    "    train_all_complete = train_all_raw.dropna()\n",
    "    n_samples_to_use = len(train_all_complete)\n",
    "    print(f\"Found {n_samples_to_use} complete training samples.\")\n",
    "\n",
    "    if train_all_complete.empty:\n",
    "        print(\"Error: No common samples found. Cannot proceed.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n>>> Starting data generation for all modalities...\")\n",
    "    uncond_coherent_dfs, uncond_multi_dfs = [], []\n",
    "    \n",
    "    coherent_strategy = CoherentStrategy('coherent', args.results_path, args.dim)\n",
    "    multi_strategy = MultiModelStrategy('multi', args.results_path, args.dim)\n",
    "\n",
    "    for modality in modalities_list:\n",
    "        n_feats = modalities_map[modality]['train'].shape[1]\n",
    "        \n",
    "        coherent_df = coherent_strategy.generate_unconditional(modality, modalities_map, n_feats, 1)\n",
    "        if coherent_df is None: \n",
    "            print(f\"FATAL: Could not generate Coherent data for {modality}. Aborting.\"); return\n",
    "        uncond_coherent_dfs.append(coherent_df.head(n_samples_to_use))\n",
    "        \n",
    "        multi_df = multi_strategy.generate_unconditional(modality, modalities_map, n_feats, 1)\n",
    "        if multi_df is None: \n",
    "            print(f\"FATAL: Could not generate Multi data for {modality}. Aborting.\"); return\n",
    "        uncond_multi_dfs.append(multi_df.head(n_samples_to_use))\n",
    "\n",
    "    final_uncond_coherent_df = pd.concat(uncond_coherent_dfs, axis=1)\n",
    "    final_uncond_multi_df = pd.concat(uncond_multi_dfs, axis=1)\n",
    "\n",
    "    # --- MODIFIED: Call the new PCA plotting function ---\n",
    "    plot_unconditional_pca_comparison(\n",
    "        train_df=train_all_complete,\n",
    "        coherent_df=final_uncond_coherent_df,\n",
    "        multi_df=final_uncond_multi_df,\n",
    "        # MODIFIED: Updated save path for the new plot\n",
    "        save_path=os.path.join(args.results_path, 'images', 'pca_train_vs_uncond_comparison.png')\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Global Parameters & Setup ---\n",
    "    DEVICE = torch.device(f\"cuda:{torch.cuda.current_device()}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    METRIC_TO_USE = 'mse'\n",
    "\n",
    "    args = SimpleNamespace(\n",
    "        dim=32,\n",
    "        results_path='../results',\n",
    "        data_dir='../datasets_TCGA/07_normalized/',\n",
    "    )\n",
    "    run_generation_and_plotting(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
